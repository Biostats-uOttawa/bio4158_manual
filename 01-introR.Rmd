# Introduction to R

```{r}
#| echo: false
#| message: false
#| warning: false

source("_common.R")
```


After completing this laboratory exercise, you should be able to:

- Open R data files
- Import rectangular data sets
- Export R data to text files
- Verify that data were imported correctly
- Examine the distribution of a variable
- Examine visually and test for normality of a variable
- Calculate descriptive statistics for a variable
- Transform data

## Packages and data needed for the lab {#set-intro}

This labs needs the following:

* R packages:
  * ggplot2
* data files
  * ErablesGatineau.csv
  * sturgeon.csv

## Importing and exporting data

There are multiple format to save data. The 2 most used formats with R are `.csv` and `.Rdata`.

- `.csv` files are used to store data in a simple format and are editable using any text editor (e.g. Word, Writer, atom, ...) and spreadsheets (e.g. MS Excel, LO Calc).
They can be read using the function `read.csv()` and created in R with `write.csv()`.
- `.Rdata` files are used to store not only data but any R object, however, those files can only be used in R. They are created using the `save()` function and read using the `load()` function.

Data for exercises and labs are provides in `.csv`.


### Working directory

::: {.callout-warning}
Potentially the most frequent error when starting with R is link to loading data or reading data from an external file in R.
:::

A typical error message is:

```
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'ou_est_mon_fichier.csv': No such file or directory
```

This type of error simply means that R cannot find the file you specified. By default, when R starts, a folder is defined as the base folder for R. This is the working directory. R by default will save any files in this folder and will start looking for files in this folder. So you need to specify to R where to look for files and where to save your files. This can be done in 3 different ways:

1. `file.choose()`. (not recommended, because not reproducible). This function will open a dialog box allowing you to click on the file you want. This is not recommended and can be long because you will have to do it absolutely every time you use R. 
2. specify the complete path in the function. For example `read.csv("/home/julien/Documents/cours/BIO4558/labo/data/monfichier.csv")`. This is longer to type the first time and a bit tricky to get the correct path but after you can run the line of code and it works every time without trying to remember were you saved that damned file. However, this is specific to your own computer and would not work elsewhere.
3. specify a working directory with `setwd()`. This simplify tells R where to look for files and where to save files. (This is automatically done when using .Rmd files). Just set the working directory to where you want and after that all path will be relative to this working directory. The big advantage is that if you keep a similar folder structure for you R project it will be compatible and reproducible across all computer and OS 

To know which folder is the workind directory simply type `getwd()`

::: {.callout-note}
When opening Rstudio by double-clicking on a file, it will automatically set the working irectory to the folder where this file is located. This can be super handy.
:::

::: {.callout-important}
For all labs, I strongly recommend you to make a folder where you will save all your R scripts and data and use it as your working directory in R. For better organisation I suggest to save your data in a subfolder named `data All R code for data loading in the manual is based on that structure. This is why dat loading or saving code look like `data/my_file.xxx`. If you follow it also all code for data loading can be simply copy-pasted and should work.
:::

### Opening a `.Rdata` file

You can double-click on the file and R/Rstudio should open. Alternatively, you can use `load()` function and specify the names (and path) of the file. For example to load the data `ErablesGatineau.Rdata` in R which is located in the folder `data` in the working directory you can use:

```{r load, eval = FALSE}
load("data/ErablesGatineau.Rdata")
```


### Open a `.csv` file

To import data saved in a `.csv` file, you need to use the `read.csv()` function.
For example, to create a R object named `erables` which contain the data from the file `ErablesGatineau.csv`, you need to use:

```{r erables}
erables <- read.csv("data/ErablesGatineau.csv")
```

::: {.callout-warning}
Beware of the coma. If you are working in adifferent language (other than english), be careful because the decimal symbol might ot be the same.
By default R use the point for the decimal sign. If the dat use the coma for the decimal then R would not be able to read the file correctly. In this case you can use `read.csv2()` or `read.data()` which should solve the problem.
:::

To verify that the data were read and loaded properly, you can list all objects in memory with the `ls()` function, or get a more detailed description with `ls.str()`:

::: {.callout-note}
I do not recommend to use `ls.str()` since it can produce really long R ouputs when you have multiple R object loaded.
I suggest instead to use the combination of `ls()` to get the list of all R objects and then `str()` only for the objects you want to look at.
:::

```{r ls}
ls()
str(erables)
```

R confirms that the object `erables`.
`erables` is a data.frame that contains 100 observations (lines) of 3 variables (columns) : `station` , a variable of type Factor with 2
levels, and `diam` and `biom` that are 2 numeric variables.


### Entering data in R

R is not the ideal environment to input data. It is possible, but the syntax is heavy and makes most people upset. Use your preferred worksheet program instead. It will be more efficient and less frustrating.


### Cleaning up / correcting data

Another operation that can be frustrating in R. Our advice: unless you want to keep track of all corrections made (so that you can go back to the original data), do not change data in R. Return to the original data file (in a worksheet or database), correct the data there, and then reimport into R. It is simple to resubmit the few lines of code to reimport data. Doing things this way will leave you with a single version of your data file that has all corrections, and the code that allows you to repeat the analysis exactly.


### Exporting data from R

You have 2 options: export data in `.csv` or in `.Rdata`

To export in `.Rdata` use the function `save()` to export in `.csv` use `write.csv()`

For example, to save teh object `mydata` in a file `wonderful_data.csv`that will be saved in your working directory you can type:

```{r write, eval =FALSE}
write.csv(mydata, file = "wonderful_data.csv", row.names = FALSE)
```



## Preliminary examination of data

The first step of data analysis is to examine the data at hand. This examination will tell you if the data were correctly imported, whether the numbers are credible, whether all data came in, etc. This initial data examination often will allow you to detect unlikely observations, possibly due to errors at the data entry stage. Finally, the initial plotting of the data will allow you to visualize the major trends that will be confirmed later by your statistical analysis.

The file `sturgeon.csv` contains data on sturgeons from the Saskatchewan River. These data were collected to examine how sturgeon size varies among sexes ( `sex` ), sites ( `location` ), and years( `year` ).

<!-- - Pour recommencer avec une ardoise vide, videz la mémoire de R de tout son contenu en tapant la commande `rm(list=ls())`-->

- Load the data from `sturgeon.csv` in a R object named `sturgeon`.
- use the function `str()` to check that the data was loaded and read correctly.

```{r load-stur}
sturgeon <- read.csv("data/sturgeon.csv")
str(sturgeon)
```

### Summary statistics

To get summary statistics on the contents of the data frame sturgeon, type the command:

```{r sum-stur}
summary(sturgeon)
```

For each variable, R lists:

- the minimum
- the maximum
- the median that is the $50^{th}$ percentile, here the $93^{rd}$ value of the 186 observations ordered in ascending order
- values at the first (25%) and third quartile (75%)
- the number of missing values in the column.

Note that several variables have missing values (NA). Only the variables `fklngth` (fork length), `sex` , `location` , and `year` have 186 observations.

::: {.callout-warning}
**Beware of missing values**

Several R functions are sensitive to missing values and you will frequently have to do your analyses on data subsets without missing data, or by using optional parameters in various commands. We will get back to this, but you should always pay attention and take note of missing data when you do analyses.
:::

### Histogram, empirical probability density, boxplot, and visual assessment of normality

Let’s look more closely at the distribution of `fklngth`.
The command `hist()` will create a histogram. For the histogram of `fklngth` in the `sturgeon` data frame, type the command:

```{r hist-stur, fig.cap= "Histogram of fluke length of sturgeons"}
hist(sturgeon$fklngth)
```

The data appear to be approximately normal. This is good to know.

::: {.callout-note}
Note that this syntax is a bit heavy as you need to prefix variable names by the data frame name `sturgeon$`. You can lighten the syntax by making the variables directly accessible by commands by typing the command `attach()`.
However, I **strongly recommend not to use** it because it can lead to many problems hard to detect compare to the little benfit is provides
:::

This histogram (Fig. \@ref(fig:hist-stur)) is a very classical representation of the distribution. Histograms are not perfect however because their shape partly depends on the number of bins used, more so for small samples. One can do better, especially if you want to visually compare the observed distribution to a normal distribution. But you need to come up with a bit of extra R code based on the `ggplot2` `r emoji::emoji("package")`.

```{r stur-g1, fig.cap = "Distribution of fluke length in sturgeon plotted with ggplot",warning = FALSE, message =  FALSE}
## load ggplot2 if needed
library(ggplot2)

## use "sturgeon" dataframe to make plot called mygraph
# and define x axis as representing fklngth
mygraph <- ggplot(data = sturgeon, aes(x = fklngth))

## add data to the mygraph ggplot
mygraph <- mygraph +
  ## add semitransparent histogram
  geom_histogram(aes(y = ..density..),
    bins = 30, color = "black", alpha = 0.3
  ) +
  ##  add density smooth
  geom_density() +
  ## add observations positions or rug bars
  geom_rug() +
  ## add Gaussian curve adjusted to the data with mean and sd from fklngth
  stat_function(
    fun = dnorm,
    args = list(
      mean = mean(sturgeon$fklngth),
      sd = sd(sturgeon$fklngth)
    ),
    color = "red"
  )

## display graph
mygraph
```

Each observation is represented by a short vertical bar below the x- axis (rug). The red line is the normal distribution with the same mean and standard deviation as the data. The other line is the empirical distribution, smoothed from the observations.

The ggplot object you just created (`mygraph`) can be further manipulated. For example, you can plot the distribution of `fklngth` per `sex` and `year` groups simply by adding a `facet_grid()` statement:

```{r aventure}
mygraph + facet_grid(year ~ sex)
```

Each panel contains the data distribution for one sex that year, and the recurring red curve is the normal distribution for the entire data set. It can serve as a reference to help visually evaluate differences among panels.

Another way to visually assess normality of data is the QQ plot that is
obtained by the pair of commands `qqnorm()` and `qqline()`.

```{r stur-norm}
qqnorm(sturgeon$fklngth)
qqline(sturgeon$fklngth)
```
 Perfectly normal data would follow the straight diagonal line. Here there are deviations in the tails of the distribution and a bit to the right of the center.
 Compare this representation to the two preceding graphs.
 You will probably agree that it is easier to visualize how data deviate from normality by looking at a histogram of an empirical probability density than by looking at the QQ plots.
 However, QQ plots are often automatically produced by various statistical routines and you should be able to interpret them.
 In addition, one can easily run a formal test of normality in R with the command `shapiro.test()` that computes a statistic (`W`) that measures how tightly data fall around the straight diagonal line of the QQ plot. If data fall perfectly on the line, then `W = 1`. If `W` is much less than 1, then data are not normal.

For the `fklngth` data:

```{r shapito-stur}
shapiro.test(sturgeon$fklngth)
```

W is close to 1, but far enough to indicate a statistically significant deviation from normality.

Visual examination of very large data sets is often made difficult by the superposition of data points. Boxplots are an interesting alternative.
The command `boxplot(fklngth~sex, notch=TRUE)` produces a boxplot of `fklngth` for each `sex` , and adds whiskers.

```{r boxplot-stur, fig.cap = "Boxplot of fluke length in strugeon by sex"}
boxplot(fklngth ~ sex, data = sturgeon, notch = TRUE)
```

The slightly thicker line inside the box of figure \@ref(fig:boxplot-stur) indicates the median.
The width of the notch is proportional to the uncertainty around the median estimate.
One can visually assess the approximate statistical significance of differences among medians by looking at the overlap of the notches (here there is no overlap and one could tentatively conclude that the median female size is larger than the median male size).
Boxes extend from the first to third quartile (the 25^th^ to 75^th^ percentile if you prefer).
Bars (whiskers) extend above and below the boxes from the minimum to the maximum observed value or, if there are extreme values, from the smallest to the largest observed value within 1.5x the interquartile range from the median. Observations exceeding the limits of the whiskers (hence further away from the median than 1.5x the interquartile range, the range between the 25^th^ and 75^th^ percentile) are plotted as circles. These are outliers, possibly aberrant data.

### Scatterplots

In addition to histograms and other univariate plots, it is often informative to examine scatter plots.
The command `plot(y~x)` produces a scatter plot of y on the vertical axis (the ordinate) vs x on the horizontal axis (abscissa).

::: {.callout-caution}
# Exercise
 Create a scatterplot of fklngth vs age using the plot() command.
:::

You should obtain:

```{r stur-biv-plot}
plot(fklngth ~ age, data = sturgeon)
```

R has a function to create all pairwise scatterplots rapidly called
`pairs()` . One of `pairs()` options is the addition of a lowess trace on
each plot to that is a smoothed trend in the data.
To get the plot matrix with the lowess smooth for all variables in the
sturgeon data frame, execute the command
`pairs(sturgeon, panel=panel.smooth)`. Howeber given the large number of variable in `sturgeon` we can limit the plot to the first 6 columns in the data.

```{r pairs-stur}
pairs(sturgeon[, 1:6], panel = panel.smooth)
```

## Creating data subsets

You will frequently want to do analyses on some subset of your data.
The command `subset()` is what you need to isolate cases meeting some criteria.
For example, to create a subset of the sturgeon data frame that contains only females caught in 1978, you could write:

```{r stur-subset}
sturgeon_female_1978 <- subset(sturgeon, sex == "FEMALE" & year == "1978")
sturgeon_female_1978
```

::: {.callout-warning}
When using criteria to select cases, be careful of the `==` syntax to mean equal to.
In this context, if you use a single `=`, you will not get what you want.
The following table lists the most common criteria to create expressions and their R syntax.
:::

Operator | Explanation | Operator | Explanation
----------|----------|----------|----------
 ==       | Equal to   | !=       | Not equal to
 \>       | Larger than | <        | Lower than
 \>=      | Larger than or equal to | <= | Lower than or equal to
 \& | And (vectorized) | \| | Or (vectorized)
 \&\& | And (control) | \|\| | Or (control)
 ! | Not | |

::: {.callout-caution}
# Exercise
Using the commands `subset()` and `hist()` , create a histogram for females caught in 1979 and 1980 (hint: `sex=="FEMALE" & (year
=="1979" | year=="1980")`)
:::


::: {.callout-tip}
# Solution

```{r intror-subex, warning = FALSE, message = FALSE, fig.cap = "Distibution of fluke length of female sturgeons in 1979 and 1980"}

sub_female_7980 <- subset(sturgeon, sex == "FEMALE" & (year == "1979" | year == "1980"))
hist(sub_female_7980$fklngth)
```
:::

## Data transformation

You will frequently transform raw data to better satisfy assumptions of statistical tests. R will allow you to do that easily.
The most used functions are probably:

- `log()`
- `sqrt()`
- `ifelse()`

You can use these functions directly within commands, create vector variables, or add columns in data frames.
To do a plot of the decimal log of fklngth vs age, you can simply use the `log10()` function within the plot command:

```{r plot-translog-stur-plot, eval = FALSE}
plot(log10(fklngth)~age, data = sturgeon)
```

To create a vector variable, an orphan variable if you wish, one that is not part of a data frame, called `lfklngth` and corresponding too the decimal log of `fklngth`, simply enter:

```{r translog-stur-orph, eval = FALSE}
logfklngth <- log10(sturgeon$fklngth)
```

If you want this new variable to be added to a data frame, then you must prefix the variable name by the data frame name and the `$` symbol.
For example to add the variable `lfkl` containing the decimal log of `fklngth` to the `sturgeon` data frame, enter:

```{r translog-stur-dat, eval = FALSE}
sturgeon$lfkl <- log10(sturgeon$fklngth)
```

`lfkl` will be added to the data frame `sturgeon` for the R session.
Do not forget to save the modified data frame if you want to keep the modified version. Or better, save you Rscript and do not forget to run the line of code again next time you need it.

For conditional transformations, you can use the function `ifelse()`.
For example, to create a new variable called dummy with a value of 1 for males and 0 for females, you can use:

```{r translog-stur-dummy, eval = FALSE}
sturgeon$dummy <- ifelse(sturgeon$sex == "MALE", 1, 0)
```


## Exercice

The file `salmonella.csv` contains numerical values for the variable
called ratio for two environments (`milieu`: `IN VITRO` or `IN VIVO`)
and for 3 strains (`souche`).
Examine the ratio variable and make a graph to visually assess normality for the wild (SAUVAGE) strain.

::: {.callout-tip}
# Solution
```{r intror-exer, warning = FALSE, message = FALSE, fig.cap = "Distibution of infection ratios by the wild (SAUVAGE) strain of salmonella"}
## load the data
salmonella <- read.csv("data/salmonella.csv")

## create the base for the graph defining data and x
mygraph <- ggplot(subset(salmonella, souche == "SAUVAGE"), aes(x = ratio))
## add graph components
mygraph <- mygraph +
  # density smooth
  geom_density() +
  # obersations positions
  geom_rug() +
  # histogram
  geom_histogram(aes(y = ..density..),
    bins = 30,
    color = "black",
    alpha = 0.3
  ) +
  # ajusted Gaussian distribution
  stat_function(
    fun = dnorm,
    args = list(
      mean = mean(subset(salmonella, souche == "SAUVAGE")$ratio),
      sd = sd(subset(salmonella, souche == "SAUVAGE")$ratio)
    ),
    color = "red"
  )
## plot the graph
mygraph
```
:::


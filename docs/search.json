[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied biostatistics",
    "section": "",
    "text": "Welcome\nThe laboratory exercises outlined in the following pages are designed to allow you to develop some expertise in using statistical software (R) to analyze data. R is powerful statistical software but, like all software, it has its limitations. In particular, it is dumb: it cannot think for you, it cannot tell you whether the analysis you are attempting to do is appropriate or even makes any sense, and it cannot interpret your results. The manual was written with the help of Rmarkfdown Xie (2015).",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#general-points-to-keep-in-mind",
    "href": "index.html#general-points-to-keep-in-mind",
    "title": "Applied biostatistics",
    "section": "General points to keep in mind",
    "text": "General points to keep in mind\n\nBefore attempting any statistical procedure, you must familiarize yourself with what the procedure is actually doing. This does not mean you actually have to know the underlying mathematics (although this certainly helps!), but you should at least understand the principles involved in the analysis. Therefore, before doing a laboratory exercise, read the appropriate section(s) in the lecture notes. Otherwise, the output from your analyses - even if done correctly - will seem like drivel.\nThe laboratories are designed to complement the lectures, and vice versa. Owing to scheduling constraints, it may not be possible to synchronize the two perfectly. But feel free to bring questions about the laboratories to class, or questions about the lectures to the labs.\nWork on the laboratories at your own speed: some can be donemuch more quickly than others, and one laboratory need not correspond to one laboratory session. In fact, for some laboratorieswe have allotted two laboratory sessions. Although you will notbe “graded” on the laboratories per se, be aware that completingthe labs is essential. If you do not complete the labs, it is veryunlikely that you will be able to complete the assignments and thefinal exam/term paper. So take these laboratories seriously!\n\nThe objective of the first lab is to allow you to acquire or reviewthe minimum knowledge required to complete the following laboratory exercises with R. There are always several methods toaccomplish something in R, but you will only find simple ways inthis manual. Those amongst you that want to go further will easilyfind many examples of more detailed and sophisticated methods.In particular, I point you to the following resources:\n\nR for beginners http://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf\nAn introduction to R http://cran.r-project.org/doc/manuals/R-intro.html\nIf you prefer paper books, the CRAN web site has a commented list at : http://www.r-project.org/doc/bib/R-books.html\nExcellent list of R books https://www.bigbookofr.com/\nR reference card by Tom Short http://cran.r-project.org/doc/contrib/Short-refcard.pdf",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#what-is-r-and-why-use-it-in-this-course",
    "href": "index.html#what-is-r-and-why-use-it-in-this-course",
    "title": "Applied biostatistics",
    "section": "What is R and why use it in this course?",
    "text": "What is R and why use it in this course?\nR is multiplatform free software forming a system for statistical computation and graphics. R is also a programming language specially designed for statistical data analysis. It is a dialect of the S language. S- Plus is another dialect of the S language, very similar to R, incorporated into a commercial package. S-Plus has a built-in graphical design intreface that some find convivial.\nR has 2 major advantages for this course. Initially, you will find that it also has one inconvenience. However, this “inconvenience” will rapidly force you to acquire very good working habits. So, I see it as a third advantage.\nThe first advantage is that you can install it freely on you personal computer(s). This is important because it is by doing analyses that you will learn and eventually master biostatistics. This implies that you have easy and unlimited access to a statistical software package. The second advantage is that R can do everything in statistics. R was conceived to be extensible and has become the preferred tool for statisticians around the world. The question is not “Can R do this?” but rather “How can I do this in R?”. And search engine are your friends.\nNo other software package offers you these two advantages.\nThe inconvenience of R is that one has to type commands (or copy and paste code) rather than use a menu and select options. If you do not know what command to use, nothing will happen. It is therefore not that easy when you start. However, it is possible to rapidly learn to make basic operations (open a data file, plot data, and run a simple analysis). And once you understand the operating principle, you can easily find examples on the Web for more complex analyses and graphs for which you can adapt the code.\nThis is exactly what you will do in the first lab to familiarize yourself with R.\nWhy is this inconvenience really an advantage in my mind? Because this way of doing things is more efficient and will save you time on the long run. I guarantee it. Believe me, you will never do an analysis only once. As you’ll proceed through analyses, you will find data entry errors, discover that the analysis must be run separately for subgroups, find extra data, have to rerun the analysis on transformed data, or you will make some analytical error along the way. If you use a graphical interface with menus, redoing an analysis implies that you reclick here, enter values there, select some options, etc. Each of these steps is a potential source of error. If, instead, you use lines of codes, you only have to fix the code and submit to repeat instantaneously the entire analysis. And you can perfectly document what you did, leaving an audit trail for the future. This is how pros work and can document the quality of the results of their analyses.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#software-installation",
    "href": "index.html#software-installation",
    "title": "Applied biostatistics",
    "section": "Software installation",
    "text": "Software installation\nR\nTo install R on a computer, go to http://cran.r-project.org/. You will find compiled versions (binairies) for your preferred operating system (Windows, MacOS, Linux).\nNote : R has already been installed on the lab computers (the version may be slightly different, but this should not matter).\nRstudio or VS code\nRStudio and VS code are integrated development environment software or IDE. RStudio was develop specifically to work with R. VScode is more generela but work extremely well with R. Both are available on Windows, OS X and Linux\n\nRStudio: https://www.rstudio.com/products/rstudio/download/\nVScode: https://code.visualstudio.com/download\nR libraries\nR is essentially unlimited in terms of functions that can be used, because is relies on functions packages that can be added as extra components to use in R.\n\nRmarkdown\ntinytex\n\nThose 2 packages should be installed automatically with RStudio but I recommend to install them manually in case they are not. To do so, just copy-paste the text below in R terminal.\n\ninstall.packages(c(\"rmarkdown\", \"tinytex\"))",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#general-laboratory-instructions",
    "href": "index.html#general-laboratory-instructions",
    "title": "Applied biostatistics",
    "section": "General laboratory instructions",
    "text": "General laboratory instructions\n\nBring a USB key or equivalent so you can save your work. Alternatively, email your results to yourself.\nRead the lab exercise before coming to the lab. Read the R code and come with questions about the code.\nDuring pre-labs, listen to the special instructions\nDo the laboratory exercises at your own rhythm, in teams. Then, I recommend that you start (complete?) the lab assignment so that you can benefit from the presence of the TA or prof.\nDuring your analyses, copy and paste results in a separate document, for example in your preferred word processing program. Annotate abundantly\nEach time you shut down R, save the history of your commands (ex: labo1.1 rHistory, labo1.2.rHistory, etc). You will be able to redo the lab rapidly, get code fragments, or more easily identify errors.\nCreate your own “library” of code fragments (snippets). Annotate it abundantly. You will thank yourself later.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#notes-about-the-manual",
    "href": "index.html#notes-about-the-manual",
    "title": "Applied biostatistics",
    "section": "Notes about the manual",
    "text": "Notes about the manual\nYou will find explanations on the theory, R code and functions, IDE best practice and exercises with R.\nThe manual tries to highlight some part of the text using the following boxes and icons.\n\n\n\n\n\n\nExercises\n\n\n\n\n\n\n\n\n\n\n\n\nSolutions\n\n\n\n\n\n\n\n\n\n\n\n\nwarnings\n\n\n\n\n\n\n\n\n\nimportant points\n\n\n\n\n\n\n\n\n\nnotes\n\n\n\nResources\nThe manual is based on the previous lab manual Findlay, Morin and Rundle, BIO4158 Laboratory manual for BIO4158.\nLicense\nThe document is available follwoing the license License Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International.\n\n\nLicense Creative Commons\n\n\n\n\n\nXie, Y. 2015. Dynamic documents with R and knitr. 2nd edition. Chapman; Hall/CRC, Boca Raton, Florida.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "01-introR.html",
    "href": "01-introR.html",
    "title": "\n1  Introduction to R\n",
    "section": "",
    "text": "1.1 Packages and data needed for the lab\nThis labs needs the following:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-introR.html#set-intro",
    "href": "01-introR.html#set-intro",
    "title": "\n1  Introduction to R\n",
    "section": "",
    "text": "R packages:\n\nggplot2\n\n\ndata files\n\nErablesGatineau.csv\nsturgeon.csv",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-introR.html#importing-and-exporting-data",
    "href": "01-introR.html#importing-and-exporting-data",
    "title": "\n1  Introduction to R\n",
    "section": "\n1.2 Importing and exporting data",
    "text": "1.2 Importing and exporting data\nThere are multiple format to save data. The 2 most used formats with R are .csv and .Rdata.\n\n\n.csv files are used to store data in a simple format and are editable using any text editor (e.g. Word, Writer, atom, …) and spreadsheets (e.g. MS Excel, LO Calc). They can be read using the function read.csv() and created in R with write.csv().\n\n.Rdata files are used to store not only data but any R object, however, those files can only be used in R. They are created using the save() function and read using the load() function.\n\nData for exercises and labs are provides in .csv.\n\n1.2.1 Working directory\n\n\n\n\n\n\nPotentially the most frequent error when starting with R is link to loading data or reading data from an external file in R.\n\n\n\nA typical error message is:\nError in file(file, \"rt\") : cannot open the connection\nIn addition: Warning message:\nIn file(file, \"rt\") :\n  cannot open file 'ou_est_mon_fichier.csv': No such file or directory\nThis type of error simply means that R cannot find the file you specified. By default, when R starts, a folder is defined as the base folder for R. This is the working directory. R by default will save any files in this folder and will start looking for files in this folder. So you need to specify to R where to look for files and where to save your files. This can be done in 3 different ways:\n\n\nfile.choose(). (not recommended, because not reproducible). This function will open a dialog box allowing you to click on the file you want. This is not recommended and can be long because you will have to do it absolutely every time you use R.\nspecify the complete path in the function. For example read.csv(\"/home/julien/Documents/cours/BIO4558/labo/data/monfichier.csv\"). This is longer to type the first time and a bit tricky to get the correct path but after you can run the line of code and it works every time without trying to remember were you saved that damned file. However, this is specific to your own computer and would not work elsewhere.\nspecify a working directory with setwd(). This simplify tells R where to look for files and where to save files. (This is automatically done when using .Rmd files). Just set the working directory to where you want and after that all path will be relative to this working directory. The big advantage is that if you keep a similar folder structure for you R project it will be compatible and reproducible across all computer and OS\n\nTo know which folder is the workind directory simply type getwd()\n\n\n\n\n\n\nWhen opening Rstudio by double-clicking on a file, it will automatically set the working irectory to the folder where this file is located. This can be super handy.\n\n\n\n\n\n\n\n\n\nFor all labs, I strongly recommend you to make a folder where you will save all your R scripts and data and use it as your working directory in R. For better organisation I suggest to save your data in a subfolder named data All R code for data loading in the manual is based on that structure. This is why dat loading or saving code look likedata/my_file.xxx`. If you follow it also all code for data loading can be simply copy-pasted and should work.\n\n\n\n\n1.2.2 Opening a .Rdata file\nYou can double-click on the file and R/Rstudio should open. Alternatively, you can use load() function and specify the names (and path) of the file. For example to load the data ErablesGatineau.Rdata in R which is located in the folder data in the working directory you can use:\n\nload(\"data/ErablesGatineau.Rdata\")\n\n\n1.2.3 Open a .csv file\nTo import data saved in a .csv file, you need to use the read.csv() function. For example, to create a R object named erables which contain the data from the file ErablesGatineau.csv, you need to use:\n\nerables &lt;- read.csv(\"data/ErablesGatineau.csv\")\n\n\n\n\n\n\n\nBeware of the coma. If you are working in adifferent language (other than english), be careful because the decimal symbol might ot be the same. By default R use the point for the decimal sign. If the dat use the coma for the decimal then R would not be able to read the file correctly. In this case you can use read.csv2() or read.data() which should solve the problem.\n\n\n\nTo verify that the data were read and loaded properly, you can list all objects in memory with the ls() function, or get a more detailed description with ls.str():\n\n\n\n\n\n\nI do not recommend to use ls.str() since it can produce really long R ouputs when you have multiple R object loaded. I suggest instead to use the combination of ls() to get the list of all R objects and then str() only for the objects you want to look at.\n\n\n\n\nls()\n\n[1] \"erables\"\n\nstr(erables)\n\n'data.frame':   100 obs. of  3 variables:\n $ station: chr  \"A\" \"A\" \"A\" \"A\" ...\n $ diam   : num  22.4 36.1 44.4 24.6 17.7 ...\n $ biom   : num  732 1171 673 1552 504 ...\n\n\nR confirms that the object erables. erables is a data.frame that contains 100 observations (lines) of 3 variables (columns) : station , a variable of type Factor with 2 levels, and diam and biom that are 2 numeric variables.\n\n1.2.4 Entering data in R\nR is not the ideal environment to input data. It is possible, but the syntax is heavy and makes most people upset. Use your preferred worksheet program instead. It will be more efficient and less frustrating.\n\n1.2.5 Cleaning up / correcting data\nAnother operation that can be frustrating in R. Our advice: unless you want to keep track of all corrections made (so that you can go back to the original data), do not change data in R. Return to the original data file (in a worksheet or database), correct the data there, and then reimport into R. It is simple to resubmit the few lines of code to reimport data. Doing things this way will leave you with a single version of your data file that has all corrections, and the code that allows you to repeat the analysis exactly.\n\n1.2.6 Exporting data from R\nYou have 2 options: export data in .csv or in .Rdata\nTo export in .Rdata use the function save() to export in .csv use write.csv()\nFor example, to save teh object mydata in a file wonderful_data.csvthat will be saved in your working directory you can type:\n\nwrite.csv(mydata, file = \"wonderful_data.csv\", row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-introR.html#preliminary-examination-of-data",
    "href": "01-introR.html#preliminary-examination-of-data",
    "title": "\n1  Introduction to R\n",
    "section": "\n1.3 Preliminary examination of data",
    "text": "1.3 Preliminary examination of data\nThe first step of data analysis is to examine the data at hand. This examination will tell you if the data were correctly imported, whether the numbers are credible, whether all data came in, etc. This initial data examination often will allow you to detect unlikely observations, possibly due to errors at the data entry stage. Finally, the initial plotting of the data will allow you to visualize the major trends that will be confirmed later by your statistical analysis.\nThe file sturgeon.csv contains data on sturgeons from the Saskatchewan River. These data were collected to examine how sturgeon size varies among sexes ( sex ), sites ( location ), and years( year ).\n\n\nLoad the data from sturgeon.csv in a R object named sturgeon.\nuse the function str() to check that the data was loaded and read correctly.\n\n\nsturgeon &lt;- read.csv(\"data/sturgeon.csv\")\nstr(sturgeon)\n\n'data.frame':   186 obs. of  9 variables:\n $ fklngth : num  37 50.2 28.9 50.2 45.6 ...\n $ totlngth: num  40.7 54.1 31.3 53.1 49.5 ...\n $ drlngth : num  23.6 31.5 17.3 32.3 32.1 ...\n $ rdwght  : num  15.95 NA 6.49 NA 29.92 ...\n $ age     : int  11 24 7 23 20 23 20 7 23 19 ...\n $ girth   : num  40.5 53.5 31 52.5 50 54.2 48 28.5 44 39 ...\n $ sex     : chr  \"MALE\" \"FEMALE\" \"MALE\" \"FEMALE\" ...\n $ location: chr  \"THE_PAS\" \"THE_PAS\" \"THE_PAS\" \"THE_PAS\" ...\n $ year    : int  1978 1978 1978 1978 1978 1978 1978 1978 1978 1978 ...\n\n\n\n1.3.1 Summary statistics\nTo get summary statistics on the contents of the data frame sturgeon, type the command:\n\nsummary(sturgeon)\n\n    fklngth         totlngth        drlngth          rdwght     \n Min.   :24.96   Min.   :28.15   Min.   :14.33   Min.   : 4.73  \n 1st Qu.:41.00   1st Qu.:43.66   1st Qu.:25.00   1st Qu.:18.09  \n Median :44.06   Median :47.32   Median :27.00   Median :23.10  \n Mean   :44.15   Mean   :47.45   Mean   :27.29   Mean   :24.87  \n 3rd Qu.:48.00   3rd Qu.:51.97   3rd Qu.:29.72   3rd Qu.:30.27  \n Max.   :66.85   Max.   :72.05   Max.   :41.93   Max.   :93.72  \n                 NA's   :85      NA's   :13      NA's   :4      \n      age            girth           sex              location        \n Min.   : 7.00   Min.   :11.50   Length:186         Length:186        \n 1st Qu.:17.00   1st Qu.:40.00   Class :character   Class :character  \n Median :20.00   Median :44.00   Mode  :character   Mode  :character  \n Mean   :20.24   Mean   :44.33                                        \n 3rd Qu.:23.50   3rd Qu.:48.80                                        \n Max.   :55.00   Max.   :73.70                                        \n NA's   :11      NA's   :85                                           \n      year     \n Min.   :1978  \n 1st Qu.:1979  \n Median :1979  \n Mean   :1979  \n 3rd Qu.:1980  \n Max.   :1980  \n               \n\n\nFor each variable, R lists:\n\nthe minimum\nthe maximum\nthe median that is the \\(50^{th}\\) percentile, here the \\(93^{rd}\\) value of the 186 observations ordered in ascending order\nvalues at the first (25%) and third quartile (75%)\nthe number of missing values in the column.\n\nNote that several variables have missing values (NA). Only the variables fklngth (fork length), sex , location , and year have 186 observations.\n\n\n\n\n\n\nBeware of missing values\nSeveral R functions are sensitive to missing values and you will frequently have to do your analyses on data subsets without missing data, or by using optional parameters in various commands. We will get back to this, but you should always pay attention and take note of missing data when you do analyses.\n\n\n\n\n1.3.2 Histogram, empirical probability density, boxplot, and visual assessment of normality\nLet’s look more closely at the distribution of fklngth. The command hist() will create a histogram. For the histogram of fklngth in the sturgeon data frame, type the command:\n\nhist(sturgeon$fklngth)\n\n\n\nHistogram of fluke length of sturgeons\n\n\n\nThe data appear to be approximately normal. This is good to know.\n\n\n\n\n\n\nNote that this syntax is a bit heavy as you need to prefix variable names by the data frame name sturgeon$. You can lighten the syntax by making the variables directly accessible by commands by typing the command attach(). However, I strongly recommend not to use it because it can lead to many problems hard to detect compare to the little benfit is provides\n\n\n\nThis histogram (Fig. @ref(fig:hist-stur)) is a very classical representation of the distribution. Histograms are not perfect however because their shape partly depends on the number of bins used, more so for small samples. One can do better, especially if you want to visually compare the observed distribution to a normal distribution. But you need to come up with a bit of extra R code based on the ggplot2 📦.\n\n## load ggplot2 if needed\nlibrary(ggplot2)\n\n## use \"sturgeon\" dataframe to make plot called mygraph\n# and define x axis as representing fklngth\nmygraph &lt;- ggplot(data = sturgeon, aes(x = fklngth))\n\n## add data to the mygraph ggplot\nmygraph &lt;- mygraph +\n  ## add semitransparent histogram\n  geom_histogram(aes(y = ..density..),\n    bins = 30, color = \"black\", alpha = 0.3\n  ) +\n  ##  add density smooth\n  geom_density() +\n  ## add observations positions or rug bars\n  geom_rug() +\n  ## add Gaussian curve adjusted to the data with mean and sd from fklngth\n  stat_function(\n    fun = dnorm,\n    args = list(\n      mean = mean(sturgeon$fklngth),\n      sd = sd(sturgeon$fklngth)\n    ),\n    color = \"red\"\n  )\n\n## display graph\nmygraph\n\n\n\nDistribution of fluke length in sturgeon plotted with ggplot\n\n\n\nEach observation is represented by a short vertical bar below the x- axis (rug). The red line is the normal distribution with the same mean and standard deviation as the data. The other line is the empirical distribution, smoothed from the observations.\nThe ggplot object you just created (mygraph) can be further manipulated. For example, you can plot the distribution of fklngth per sex and year groups simply by adding a facet_grid() statement:\n\nmygraph + facet_grid(year ~ sex)\n\n\n\n\n\n\n\nEach panel contains the data distribution for one sex that year, and the recurring red curve is the normal distribution for the entire data set. It can serve as a reference to help visually evaluate differences among panels.\nAnother way to visually assess normality of data is the QQ plot that is obtained by the pair of commands qqnorm() and qqline().\n\nqqnorm(sturgeon$fklngth)\nqqline(sturgeon$fklngth)\n\n\n\n\n\n\n\nPerfectly normal data would follow the straight diagonal line. Here there are deviations in the tails of the distribution and a bit to the right of the center. Compare this representation to the two preceding graphs. You will probably agree that it is easier to visualize how data deviate from normality by looking at a histogram of an empirical probability density than by looking at the QQ plots. However, QQ plots are often automatically produced by various statistical routines and you should be able to interpret them. In addition, one can easily run a formal test of normality in R with the command shapiro.test() that computes a statistic (W) that measures how tightly data fall around the straight diagonal line of the QQ plot. If data fall perfectly on the line, then W = 1. If W is much less than 1, then data are not normal.\nFor the fklngth data:\n\nshapiro.test(sturgeon$fklngth)\n\n\n    Shapiro-Wilk normality test\n\ndata:  sturgeon$fklngth\nW = 0.97225, p-value = 0.0009285\n\n\nW is close to 1, but far enough to indicate a statistically significant deviation from normality.\nVisual examination of very large data sets is often made difficult by the superposition of data points. Boxplots are an interesting alternative. The command boxplot(fklngth~sex, notch=TRUE) produces a boxplot of fklngth for each sex , and adds whiskers.\n\nboxplot(fklngth ~ sex, data = sturgeon, notch = TRUE)\n\n\n\nBoxplot of fluke length in strugeon by sex\n\n\n\nThe slightly thicker line inside the box of figure @ref(fig:boxplot-stur) indicates the median. The width of the notch is proportional to the uncertainty around the median estimate. One can visually assess the approximate statistical significance of differences among medians by looking at the overlap of the notches (here there is no overlap and one could tentatively conclude that the median female size is larger than the median male size). Boxes extend from the first to third quartile (the 25th to 75th percentile if you prefer). Bars (whiskers) extend above and below the boxes from the minimum to the maximum observed value or, if there are extreme values, from the smallest to the largest observed value within 1.5x the interquartile range from the median. Observations exceeding the limits of the whiskers (hence further away from the median than 1.5x the interquartile range, the range between the 25th and 75th percentile) are plotted as circles. These are outliers, possibly aberrant data.\n\n1.3.3 Scatterplots\nIn addition to histograms and other univariate plots, it is often informative to examine scatter plots. The command plot(y~x) produces a scatter plot of y on the vertical axis (the ordinate) vs x on the horizontal axis (abscissa).\n\n\n\n\n\n\nExercise\n\n\n\nCreate a scatterplot of fklngth vs age using the plot() command.\n\n\nYou should obtain:\n\nplot(fklngth ~ age, data = sturgeon)\n\n\n\n\n\n\n\nR has a function to create all pairwise scatterplots rapidly called pairs() . One of pairs() options is the addition of a lowess trace on each plot to that is a smoothed trend in the data. To get the plot matrix with the lowess smooth for all variables in the sturgeon data frame, execute the command pairs(sturgeon, panel=panel.smooth). Howeber given the large number of variable in sturgeon we can limit the plot to the first 6 columns in the data.\n\npairs(sturgeon[, 1:6], panel = panel.smooth)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-introR.html#creating-data-subsets",
    "href": "01-introR.html#creating-data-subsets",
    "title": "\n1  Introduction to R\n",
    "section": "\n1.4 Creating data subsets",
    "text": "1.4 Creating data subsets\nYou will frequently want to do analyses on some subset of your data. The command subset() is what you need to isolate cases meeting some criteria. For example, to create a subset of the sturgeon data frame that contains only females caught in 1978, you could write:\n\nsturgeon_female_1978 &lt;- subset(sturgeon, sex == \"FEMALE\" & year == \"1978\")\nsturgeon_female_1978\n\n     fklngth totlngth  drlngth rdwght age girth    sex   location year\n2   50.19685 54.13386 31.49606     NA  24  53.5 FEMALE    THE_PAS 1978\n4   50.19685 53.14961 32.28346     NA  23  52.5 FEMALE    THE_PAS 1978\n6   49.60630 53.93701 31.10236  35.86  23  54.2 FEMALE    THE_PAS 1978\n7   47.71654 51.37795 33.97638  33.88  20  48.0 FEMALE    THE_PAS 1978\n15  48.89764 53.93701 29.92126  35.86  23  52.5 FEMALE    THE_PAS 1978\n105 46.85039       NA 28.34646  23.90  24    NA FEMALE CUMBERLAND 1978\n106 40.74803       NA 24.80315  17.50  18    NA FEMALE CUMBERLAND 1978\n107 40.35433       NA 25.59055  20.90  21    NA FEMALE CUMBERLAND 1978\n109 43.30709       NA 27.95276  24.10  19    NA FEMALE CUMBERLAND 1978\n113 53.54331       NA 33.85827  48.90  20    NA FEMALE CUMBERLAND 1978\n114 51.77165       NA 31.49606  35.30  26    NA FEMALE CUMBERLAND 1978\n116 45.27559       NA 26.57480  23.70  24    NA FEMALE CUMBERLAND 1978\n118 53.14961       NA 32.67717  45.30  25    NA FEMALE CUMBERLAND 1978\n119 50.19685       NA 32.08661  33.90  26    NA FEMALE CUMBERLAND 1978\n123 49.01575       NA 29.13386  37.50  22    NA FEMALE CUMBERLAND 1978\n\n\n\n\n\n\n\n\nWhen using criteria to select cases, be careful of the == syntax to mean equal to. In this context, if you use a single =, you will not get what you want. The following table lists the most common criteria to create expressions and their R syntax.\n\n\n\n\n\nOperator\nExplanation\nOperator\nExplanation\n\n\n\n==\nEqual to\n!=\nNot equal to\n\n\n&gt;\nLarger than\n&lt;\nLower than\n\n\n&gt;=\nLarger than or equal to\n&lt;=\nLower than or equal to\n\n\n&\nAnd (vectorized)\n|\nOr (vectorized)\n\n\n&&\nAnd (control)\n||\nOr (control)\n\n\n!\nNot\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUsing the commands subset() and hist() , create a histogram for females caught in 1979 and 1980 (hint: sex==\"FEMALE\" & (year ==\"1979\" | year==\"1980\"))\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsub_female_7980 &lt;- subset(sturgeon, sex == \"FEMALE\" & (year == \"1979\" | year == \"1980\"))\nhist(sub_female_7980$fklngth)\n\n\n\nDistibution of fluke length of female sturgeons in 1979 and 1980",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-introR.html#data-transformation",
    "href": "01-introR.html#data-transformation",
    "title": "\n1  Introduction to R\n",
    "section": "\n1.5 Data transformation",
    "text": "1.5 Data transformation\nYou will frequently transform raw data to better satisfy assumptions of statistical tests. R will allow you to do that easily. The most used functions are probably:\n\nlog()\nsqrt()\nifelse()\n\nYou can use these functions directly within commands, create vector variables, or add columns in data frames. To do a plot of the decimal log of fklngth vs age, you can simply use the log10() function within the plot command:\n\nplot(log10(fklngth)~age, data = sturgeon)\n\nTo create a vector variable, an orphan variable if you wish, one that is not part of a data frame, called lfklngth and corresponding too the decimal log of fklngth, simply enter:\n\nlogfklngth &lt;- log10(sturgeon$fklngth)\n\nIf you want this new variable to be added to a data frame, then you must prefix the variable name by the data frame name and the $ symbol. For example to add the variable lfkl containing the decimal log of fklngth to the sturgeon data frame, enter:\n\nsturgeon$lfkl &lt;- log10(sturgeon$fklngth)\n\nlfkl will be added to the data frame sturgeon for the R session. Do not forget to save the modified data frame if you want to keep the modified version. Or better, save you Rscript and do not forget to run the line of code again next time you need it.\nFor conditional transformations, you can use the function ifelse(). For example, to create a new variable called dummy with a value of 1 for males and 0 for females, you can use:\n\nsturgeon$dummy &lt;- ifelse(sturgeon$sex == \"MALE\", 1, 0)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-introR.html#exercice",
    "href": "01-introR.html#exercice",
    "title": "\n1  Introduction to R\n",
    "section": "\n1.6 Exercice",
    "text": "1.6 Exercice\nThe file salmonella.csv contains numerical values for the variable called ratio for two environments (milieu: IN VITRO or IN VIVO) and for 3 strains (souche). Examine the ratio variable and make a graph to visually assess normality for the wild (SAUVAGE) strain.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## load the data\nsalmonella &lt;- read.csv(\"data/salmonella.csv\")\n\n## create the base for the graph defining data and x\nmygraph &lt;- ggplot(subset(salmonella, souche == \"SAUVAGE\"), aes(x = ratio))\n## add graph components\nmygraph &lt;- mygraph +\n  # density smooth\n  geom_density() +\n  # obersations positions\n  geom_rug() +\n  # histogram\n  geom_histogram(aes(y = ..density..),\n    bins = 30,\n    color = \"black\",\n    alpha = 0.3\n  ) +\n  # ajusted Gaussian distribution\n  stat_function(\n    fun = dnorm,\n    args = list(\n      mean = mean(subset(salmonella, souche == \"SAUVAGE\")$ratio),\n      sd = sd(subset(salmonella, souche == \"SAUVAGE\")$ratio)\n    ),\n    color = \"red\"\n  )\n## plot the graph\nmygraph\n\n\n\nDistibution of infection ratios by the wild (SAUVAGE) strain of salmonella",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "02-Gpower.html",
    "href": "02-Gpower.html",
    "title": "\n2  Power Analysis with R and G*Power\n",
    "section": "",
    "text": "2.1 The theory",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Power Analysis with R and G\\*Power</span>"
    ]
  },
  {
    "objectID": "02-Gpower.html#the-theory",
    "href": "02-Gpower.html#the-theory",
    "title": "\n2  Power Analysis with R and G*Power\n",
    "section": "",
    "text": "2.1.1 What is power?\nPower is the probability of rejecting the null hypothesis when it is false\n\n2.1.2 Why do a power analysis?\nAssess the strength of evidence\nPower analysis, performed after accepting a null hypothesis, can help assess the probability of rejecting the null if it were false, and if the magnitude of the effect was equal to that observed (or to any other given magnitude). This type of a posteriori analysis is very common.\nDesign better experiments\nPower analysis, performed prior to conducting an experiment (but most often after a preliminary experiment), can be used to determine the number of observations required to detect an effect of a given magnitude with some probability (the power). This type of a priori experiment should be more common.\nEstimate minimum detectable effect\nSampling effort is often predetermined (when you are handed data of an experiment already completed), or extremely constrained (when logistics dictates what can be done). Whether it is a priori or a posteriori, power analysis can help you estimate, for a fixed sample size and a given power, what is the minimum effect size that can be detected.\n\n2.1.3 Factors affecting power\nFor a given statistical test, there are 3 factors that affect power.\nDecision criteria\nPower is related to \\(\\alpha\\), the probability level at which one rejects the null hypothesis. If this decision criteria is made very strict (i.e. if critical \\(\\alpha\\) is set to a very low value, like 0.1% or \\(p = 0.001\\)), then power will be lower than if the critical \\(\\alpha\\) was less strict.\nSample size\nThe larger the sample size, the larger the power. As sample size increases, one’s ability to detect small effect sizes as being statistically significant gets better.\nEffect size\nThe larger the effect size, the larger the power. For a given sample size, the ability to detect an effect as being significant is higher for large effects than for small ones. Effect size measures how false the null hypothesis is.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Power Analysis with R and G\\*Power</span>"
    ]
  },
  {
    "objectID": "02-Gpower.html#what-is-gpower",
    "href": "02-Gpower.html#what-is-gpower",
    "title": "\n2  Power Analysis with R and G*Power\n",
    "section": "\n2.2 What is G*Power?",
    "text": "2.2 What is G*Power?\nG*Power is free software developed by quantitative psychologists from the University of Dusseldorf in Germany. It is available in MacOS and Windows versions. It can be run under Linux using Wine or a virtual machine.\nG*Power will allow you to do power analyses for the majority of statistical tests we will cover during the term without making lengthy calculations and looking up long tables and figures of power curves. It is a really useful tool that you need to master.\nIt is possible to perform all analysis made by G*Power in R, but it requires a bit more code, and a better understanding of the process since everything should be coded by hand. In simple cases, R code is also provided.\n\n\n\n\n\n\nExercise\n\n\n\nDownload the software here and install it on your computer and your workstation (if it is not there already).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Power Analysis with R and G\\*Power</span>"
    ]
  },
  {
    "objectID": "02-Gpower.html#how-to-use-gpower",
    "href": "02-Gpower.html#how-to-use-gpower",
    "title": "\n2  Power Analysis with R and G*Power\n",
    "section": "\n2.3 How to use G*Power",
    "text": "2.3 How to use G*Power\n\n2.3.1 General Principle\nUsing G*Power generally involves 3 steps:\n\nChoosing the appropriate test\nChoosing one of the 5 types of available power analyses\nEnter parameter values and press the Calculate button\n\n2.3.2 Types of power analyses\nFirst, \\(\\alpha\\) is define as the probability level at which one rejects the null hypothesis, and \\(\\beta\\) is \\(1 - power\\).\nA priori\nComputes the sample size required given \\(\\beta\\), \\(\\alpha\\), and the effect size. This type of analysis is useful when planning experiments.\nCompromise\nComputes \\(\\alpha\\) and \\(\\beta\\) for a given \\(\\alpha\\)/\\(\\beta\\) ratio, sample size, and effect size. Less commonly used (I have never used it myself) although it can be useful when the \\(\\alpha\\)/\\(\\beta\\) ratio has meaning, for example when the cost of type I and type II errors can be quantified.\nCriterion\nComputes \\(\\alpha\\) for a given \\(\\beta\\), sample size, and effect size. In practice, I see little interest in this. Let me know if you see something I don’t!\nPost-hoc\nComputes the power for a given \\(\\alpha\\), effect size, and sample size. Used frequently to help in the interpretation of a test that is not statistically significant, but only if an effect size that is biologically significant is used (and not the observed effect size). Not relevant when the test is significant.\nSensitivity\nComputes the detectable effect size for a given \\(\\beta\\) ,\\(\\alpha\\), and sample size. Very useful at the planning stage of an experiment.\n\n2.3.3 How to calculate effect size\nG*Power can perform power analyses for several statistical tests. The metric for effect size depends on the test. Note that other software packages often use different effect size metrics and that it is important to use the correct one for each package. GPower has an effect size calculator for many tests that only requires you to enter the relevant values. The following table lists the effect size metrics used by GPower for the various tests.\n\n\n\n\n\n\n\nTest\nTaille d’effet\nFormule\n\n\n\nt-test on means\nd\n\\(d = \\frac{|\\mu_1 - \\mu_2|}{\\sqrt{({s_1}^2 + {s_2}^2)/2}}\\)\n\n\nt-test on correlations\nr\n\n\n\nother t-tests\nd\n\\(d = \\frac{\\mu}{\\sigma}\\)\n\n\nF-test (ANOVA)\nf\n\\(f = \\frac{\\frac{\\sqrt{\\sum_{i=1}^k (\\mu_i - \\mu)^2}}{k}}{\\sigma}\\)\n\n\nother F-tests\n\\(f^2\\)\n\\(f^2 = \\frac{{R_p}^2}{1-{R_p}^2}\\)\n\n\n\n\n\n\\({R_p}\\) is the squared partial correlation coefficient\n\n\nChi-square test\nw\n\\(w = \\sqrt{ \\sum_{i=1}^m \\frac{(p_{0i} - p_{1i})^2 }{ p_{0i}} }\\)\n\n\n\n\n\n\\(p_{0i}\\) and \\(p_{1i}\\) are theporportion in category \\(i\\) predicted by the null, \\(_0\\), and alternative, \\(_1\\), hypothesis",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Power Analysis with R and G\\*Power</span>"
    ]
  },
  {
    "objectID": "02-Gpower.html#power-analysis-for-a-t-test-on-two-independent-means",
    "href": "02-Gpower.html#power-analysis-for-a-t-test-on-two-independent-means",
    "title": "\n2  Power Analysis with R and G*Power\n",
    "section": "\n2.4 Power analysis for a t-test on two independent means",
    "text": "2.4 Power analysis for a t-test on two independent means\n\n\n\n\n\n\nAll the power analysis presented in this chapter can be done using 2 functions in R.\n\n\npwr.t.test() when the two samples have a similar size\n\npwr.t2n.test() when samples have different numbers of observations\n\n\n\n\nThe objective of this lab is to learn to use G*Power and understand how the 4 parameters of power analyses (\\(\\alpha\\), \\(\\beta\\), sample size and effect size) are related to each other. For this, you will only use the standard t-test to compare two independent means. This is the test most used by biologists, you have all used it, and it will serve admirably for this lab. What you will learn today will be applicable to all other power analyses.\nJaynie Stephenson studied the productivity of streams in the Ottawa region. She has measured fish biomass in 36 streams, 18 on the Shield and 18 in the Ottawa Valley. She found that fish biomass was lower in streams from the valley (2.64 \\(g/m^2\\) , standard deviation = 3.28) than from the Shield (3.31 \\(g/m^2\\) , standard deviation = 2.79.).\nWhen she tested the null hypothesis that fish biomass is the same in the two regions by a t-test, she obtained:\nPooled-Variance Two-Sample t-Test\nt = -0.5746, df = 34, p-value = 0.5693\nShe therefore accepted the null hypothesis (since p is much larger than 0.05) and concluded that fish biomass is the same in the two regions.\n\n2.4.1 Post-hoc analysis\nUsing the observed means and standard deviations, we can use G*Power to calculate the power of the two-tailed t-test for two independent means, using the observed effect size (the difference between the two means, weighted by the standard deviations) for \\(\\alpha\\) = 0.05.\nStart G*Power.\n\nIn *Test family , choose: t tests\nFor Statistical test , choose: Means: Difference between two independent means (two groups)\nFor Type of power analysis , choose: Post hoc: Compute achieved power - given \\(\\alpha\\), sample size, and effect size\nAt Input Parameters ,\n\n\nin the box Tail(s) , chose: Two,\ncheck that \\(\\alpha\\) err prob is equal to 0.05\nEnter 18 for the Sample size of group 1 and of group 2\nthen, to calculate effect size (d), click on Determine =&gt;\n\n\n\nIn the window that opens,\n\n\nselect n1 = n2 , then\nenter the two means (Mean group 1 et 2)\nthe two standard deviations(SD group 1 et 2)\nclick on Calculate and transfer to main window\n\n\n\nAfter you click on the Calculate button in the main window, you should get the following:\n\n\n\n\n\nPost-hoc analysis with estimated effect size\n\n\n\nSimilar analysis can be done in R. You first need to calculate the effect size d for a t-test comparing 2 means, and then use the pwr.t.test() function from the pwr 📦. The easiest is to create anew function in R to estimate the effect size dsince we are going to reuse it multiple times during the lab.\n\n# load package pwr\nlibrary(pwr)\n# define d for a 2 sample t-test\nd &lt;- function(u1, u2, sd1, sd2) {\n  abs(u1 - u2) / sqrt((sd1^2 + sd2^2) / 2)\n}\n\n# power analysis\npwr.t.test(\n  n = 18,\n  d = d(u1 = 2.64, sd1 = 3.28, u2 = 3.31, sd2 = 2.79),\n  sig.level = 0.05,\n  type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 18\n              d = 0.220042\n      sig.level = 0.05\n          power = 0.09833902\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n# plot similar to G*Power\nx &lt;- seq(-4, 4, length = 200)\nplot(x, dnorm(x), type = \"l\", col = \"red\", lwd = 2)\nqc &lt;- qt(0.025, 16)\nabline(v = qc, col = \"green\")\nabline(v = -qc, col = \"green\")\nlines(x, dnorm(x, mean = (3.31 - 2.64)), type = \"l\", col = \"blue\", lwd = 2)\n\n# power corresponds to the shaded area\ny &lt;- dnorm(x, mean = (3.31 - 2.64))\npolygon(\n  c(x[x &lt;= -qc], -qc), c(y[x &lt;= -qc], 0),\n  col = rgb(red = 0, green = 0.2, blue = 1, alpha = 0.5))\n\n\n\nPost-hoc analysis with estimated effect size in R\n\n\n\nLet’s examine the figure @ref(fig:gpower-1).\n\nThe curve on the left, in red, corresponds to the expected distribution of the t-statistics when \\(H_0\\) is true (i.e. when the two means are equal) given the sample size (18 per region) and the observed standard deviations.\nThe vertical green lines correspond to the critical values of t for \\(\\alpha = 0.05\\) and a total sample size of 36 (2x18).\nThe shaded pink regions correspond to the rejection zones for \\(H_0\\). If Jaynie had obtained a t-value outside the interval delimited by the critical values ranging from -2.03224 to 2.03224, she would then have rejected \\(H_0\\) , the null hypothesis of equal means. In fact, she obtained a t-value of -0.5746 and concluded that the biomass is equal in the two regions.\nThe curve on the right, in blue, corresponds to the expected distribution of the t-statistics if \\(H_1\\) is true (here \\(H_1\\) is that there is a difference in biomass between the two regions equal to \\(3.33 - 2.64 = 0.69 g/m^2\\) , given the observed standard deviations). This distribution is what we should observe if \\(H_1\\) was true and we repeated a large number of times the experiment using random samples of 18 streams in each of the two regions and calculated a t-statistic for each sample. On average, we would obtain a t-statistic of about 0.6.\nNote that there is considerable overlap of the two distributions and that a large fraction of the surface under the right curve is within the interval where \\(H_0\\) is accepted between the two vertical green lines at -2.03224 and 2.03224. This proportion, shaded in blue under the distribution on the right is labeled \\(\\beta\\) and corresponds to the risk of type II error (accept \\(H_0\\) when \\(H_1\\) is true).\nPower is simply \\(1-\\beta\\), and is here 0.098339. Therefore, if the mean biomass differed by \\(0.69 g/m^2\\) between the two regions, Jaynie had only 9.8% chance of being able to detect it as a statistically significant difference at =5% with a sample size of 18 streams in each region.\n\nLet’s recapitulate: The difference in biomass between regions is not statistically significant according to the t-test. It is because the difference is relatively small relative to the precision of the measurements. It is therefore not surprising that that power, i.e. the probability of detecting a statistically significant difference, is small. Therefore, this analysis is not very informative.\nIndeed, a post hoc power analysis using the observed effect size is not useful. It is much more informative to conduct a post hoc power analysis for an effect size that is different from the observed effect size. But what effect size to use? It is the biology of the system under study that will guide you. For example, with respect to fish biomass in streams, one could argue that a two fold change in biomass (say from 2.64 to 5.28 g/m2 ) has ecologically significant repercussions. We would therefore want to know if Jaynie had a good chance of detecting a difference as large as this before accepting her conclusion that the biomass is the same in the two regions. So, what were the odds that Jaynie could detect a difference of 2.64 g/m2 between the two regions? G*Power can tell you if you cajole it the right way.\n\n\n\n\n\n\nExercise\n\n\n\nChange the mean of group 2 to 5.28, recalculate effect size, and click on Calculate to obtain figure @ref(fig:gpower-2).\n\n\n\n\n\n\nPost-hoc analysis using an effect size different from the one estimated\n\n\n\nSame analysis using R (without all the code for the interesting but not really useful plot)\n\npwr.t.test(\n  n = 18,\n  d = d(u1 = 2.64, sd1 = 3.28, u2 = 5.28, sd2 = 2.79),\n  sig.level = 0.05,\n  type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 18\n              d = 0.8670313\n      sig.level = 0.05\n          power = 0.7146763\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nThe power is 0.71, therefore Jaynie had a reasonable chance (71%) of detecting a doubling of biomass with 18 streams in each region.\nNote that this post hoc power analysis, done for an effect size considered biologically meaningful, is much more informative than the preceeding one done with the observed effect size (which is what too many students do because it is the default of so many power calculation programs). Jaynie did not detect a difference between the two regions. There are two possibilities: 1) there is really no difference between the regions, or 2) the precision of measurements is so low (because the sample size is small and/or there is large variability within a region) that it is very unlikely to be able to detect even large differences. The second power analysis can eliminate this second possibility because Jaynie had 71% chances of detecting a doubling of biomass.\n\n2.4.2 A priori analysis\nSuppose that a difference in biomass of \\(3.31-2.64 = 0.67 g/m^2\\) can be ecologically significant. The next field season should be planned so that Jaynie would have a good chance of detecting such a difference in fish biomass between regions. How many streams should Jaynie sample in each region to have 80% of detecting such a difference (given the observed variability)?\n\n\n\n\n\n\nExercise\n\n\n\nChange the type of power analysis in G*Power to A priori: Compute sample size - given \\(\\alpha\\) , power, and effect size. Ensure that the values for means and standard deviations are those obtained by Jaynie. Recalculate the effect size metric and enter 0.8 for power and you will obtain (@ref(fig:gpower-3).\n\n\n\n\n\n\nA priori analysis\n\n\n\n\npwr.t.test(\n  power = 0.8,\n  d = d(u1 = 2.64, sd1 = 3.28, u2 = 3.31, sd2 = 2.79),\n  sig.level = 0.05,\n  type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 325.1723\n              d = 0.220042\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nOuch! The required sample would be of 326 streams in each region! It would cost a fortune and require several field teams otherwise only a few dozen streams could be sampled over the summer and it would be very unlikely that such a small difference in biomass could be detected. Sampling fewer streams would probably be in vain and could be considered as a waste of effort and time: why do the work on several dozens of streams if the odds of success are that low?\nIf we recalculate for a power of 95%, we find that 538 streams would be required from each region. Increasing power means more work!\n\npwr.t.test(\n  power = 0.95,\n  d = d(u1 = 2.64, sd1 = 3.28, u2 = 3.31, sd2 = 2.79),\n  sig.level = 0.05,\n  type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 537.7286\n              d = 0.220042\n      sig.level = 0.05\n          power = 0.95\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n2.4.3 Sensitivity analysis - Calculate the detectable effect size\nGiven the observed variability, a sampling effort of 18 streams per region, and with \\(\\alpha\\) = 0.05, what effect size could Jaynie detect with 80% probability \\(\\beta=0.2\\))?\n\n\n\n\n\n\nExercise\n\n\n\nChange analysis type in G*Power to Sensitivity: Compute required effect size - given \\(\\alpha\\) , power, and sample size and size is 18 in each region.\n\n\n\n\n\n\nAnalyse de sensitivité\n\n\n\n\npwr.t.test(\n  power = 0.8,\n  n = 18,\n  sig.level = 0.05,\n  type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 18\n              d = 0.9612854\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nThe detectable effect size for this sample size, \\(\\alpha = 0.05\\) and \\(\\beta = 0.2\\) (or power of 80%) is 0.961296.\n\n\n\n\n\n\nAttention, this effect size is the metric d and is dependent on sampling variability.\n\n\n\nHere, d is approximately equal to\n\\[ d = \\frac{| \\bar{X_1} \\bar{X_2} |} {\\sqrt{\\frac{{s_1}^2 +{s_2}^2}{2}}}\\]\nTo convert this d value without units into a value for the detectable difference in biomass between the two regions, you need to multiply d by the denominator of the equation.\n\\[\n| \\bar{X_1} - \\bar{X_2} | = d * \\sqrt{\\frac{{s_1}^2 +{s_2}^2}{2}}\n\\]\nIn R this can be done with the following code\n\npwr.t.test(\n  power = 0.8,\n  n = 18,\n  sig.level = 0.05,\n  type = \"two.sample\")$d * sqrt((3.28^2 + 2.79^2) / 2)\n\n[1] 2.926992\n\n\nTherefore, with 18 streams per region, \\(\\alpha\\) = 0.05 and \\(\\beta\\) = 0.2 (so power of 80%), Jaynie could detect a difference of 2.93 g/m2 between regions, a bit more than a doubling of biomass.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Power Analysis with R and G\\*Power</span>"
    ]
  },
  {
    "objectID": "02-Gpower.html#important-points-to-remember",
    "href": "02-Gpower.html#important-points-to-remember",
    "title": "\n2  Power Analysis with R and G*Power\n",
    "section": "\n2.5 Important points to remember",
    "text": "2.5 Important points to remember\n\nPost hoc power analyses are relevant only when the null hypothesis is accepted because it is impossible to make a type II error when rejecting \\(H_0\\) .\nWith very large samples, power is very high and minute differences can be statistically detected, even if they are not biologically significant.\nWhen using a stricter significance criteria (\\(\\alpha &lt; 0.05\\)) power is reduced.\nMaximizing power implies more sampling effort, unless you use a more liberal statistical criteria (\\(\\alpha &gt; 0.05\\))\nThe choice of \\(\\beta\\) is somewhat arbitrary. \\(\\beta=0.2\\) (power of 80%) is considered relatively high by most.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Power Analysis with R and G\\*Power</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html",
    "href": "03-reg_lin.html",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "",
    "text": "3.1 R packages and data\nFor this la b you need:\nYou need to load the packages in R with library() and if need needed install them first with install.packages() For the data, load them using the read.csv() function.\nlibrary(car)\nlibrary(lmtest)\nlibrary(performance)\nlibrary(boot)\nlibrary(ggplot2)\nlibrary(pwr)\n\nsturgeon &lt;- read.csv(\"data/sturgeon.csv\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html#set-lm",
    "href": "03-reg_lin.html#set-lm",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "",
    "text": "R packages:\n\ncar\nlmtest\nboot\npwr\nggplot\nperformance\n\n\ndata:\n\nsturgeon.csv\n\n\n\n\n\n\n\n\n\n\n\nNote that the command to read the data assumes that the data file is in a folder named data within the working directory. Adjust as needed.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html#scatter-plots",
    "href": "03-reg_lin.html#scatter-plots",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "\n3.2 Scatter plots",
    "text": "3.2 Scatter plots\nCorrelation and regression analysis should always begin with an examination of the data: this is a critical first step in determining whether such analyses are even appropriate for your data. Suppose we are interested in the extent to which length of male sturgeon in the vicinity of The Pas and Cumberland House covaries with weight. To address this question, we look at the correlation between fklngth and rdwght. Recall that one of the assumptions in correlation analysis is that the relationship between the two variables is linear. To evaluate this assumption, a good first step is to produce a scatterplot.\n\nLoad the data from sturgeon.csv in an obk=jcet named sturgeon. Make a scatter plot of rdwght vs fklngth fit with a locally weighted regression (Loess) smoother, and a linear regression line.\n\n\nsturgeon &lt;- read.csv(\"data/sturgeon.csv\")\nstr(sturgeon)\n\n'data.frame':   186 obs. of  9 variables:\n $ fklngth : num  37 50.2 28.9 50.2 45.6 ...\n $ totlngth: num  40.7 54.1 31.3 53.1 49.5 ...\n $ drlngth : num  23.6 31.5 17.3 32.3 32.1 ...\n $ rdwght  : num  15.95 NA 6.49 NA 29.92 ...\n $ age     : int  11 24 7 23 20 23 20 7 23 19 ...\n $ girth   : num  40.5 53.5 31 52.5 50 54.2 48 28.5 44 39 ...\n $ sex     : chr  \"MALE\" \"FEMALE\" \"MALE\" \"FEMALE\" ...\n $ location: chr  \"THE_PAS\" \"THE_PAS\" \"THE_PAS\" \"THE_PAS\" ...\n $ year    : int  1978 1978 1978 1978 1978 1978 1978 1978 1978 1978 ...\n\n\n\nmygraph &lt;- ggplot(\n  data = sturgeon[!is.na(sturgeon$rdwght), ], # source of data\n  aes(x = fklngth, y = rdwght)\n)\n# plot data points, regression, loess trace\nmygraph &lt;- mygraph +\n  stat_smooth(method = lm, se = FALSE, color = \"green\") + # add linear regression, but no SE shading\n  stat_smooth(color = \"red\", se = FALSE) + # add loess\n  geom_point() # add data points\n\nmygraph # display graph\n\n\n\nScatter plot of Weight as a function of length in sturgeons\n\n\n\n\n\nDoes this curve suggest a good correlation between the two? Based on visual inspection, does the relationship between these two variables appear linear?\n\nThere is some evidence of nonlinearity, as the curve appears to have a positive second derivative (concave up). This notwithstanding, it does appear the two variables are highly correlated.\n\nRedo the scatterplot, but after logtransformation of both axes.\n\n\n# apply log transformation on defined graph\nmygraph + scale_x_log10() + scale_y_log10()\n\n\n\nPlot weight-length in sturgeon using a log scale\n\n\n\nCompare the diagrams before and after the transformation (Figs @ref(fig:stur-2) and @ref(fig:stur-log)). Since the relationship is more linear after transformation, correlation analysis should be done on the transformed data",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html#data-transformations-and-the-product-moment-correlation",
    "href": "03-reg_lin.html#data-transformations-and-the-product-moment-correlation",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "\n3.3 Data transformations and the product-moment correlation",
    "text": "3.3 Data transformations and the product-moment correlation\nRecall that another assumption underlying significance testing of the product-moment correlation is that the distribution of the two variables in question is bivariate normal. We can test to see whether each of the two variables are normally distributed using the same procedures outlined in the exercise on two-sample comparisons. If the two variables are each normally distributed, then one is usually (relatively) safe in assuming the joint distribution is normal, although this needn’t necessarily be true.\n\nExamine the distribution of the 4 variables (the two original variables and the log-transformed variables). What do you conclude from visual inspection of these plots?\n\nThe following graph contains the 4 QQ plots (qqplot()). It was produced by the code below that starts with the par() command to ensure that all 4 plots would appear together on the same page in 2 rows and 2 columns:\n\npar(mfrow = c(2, 2)) # split graph in 4 (2 rows, 2 cols) filling by rows\nqqnorm(sturgeon$fklngth, ylab = \"fklngth\")\nqqline(sturgeon$fklngth)\nqqnorm(log10(sturgeon$fklngth), ylab = \"log10(fklngth)\")\nqqline(log10(sturgeon$fklngth))\nqqnorm(sturgeon$rdwght, ylab = \"rdwght\")\nqqline(sturgeon$rdwght)\nqqnorm(log10(sturgeon$rdwght), ylab = \"log10(rdwgth)\")\nqqline(log10(sturgeon$rdwght))\n\n\n\n\n\n\npar(mfrow = c(1, 1)) # redefine plotting area to 1 plot\n\nNone of these distributions are perfectly normal, but deviations are mostly minor.\n\nTo generate a scatterplot matrix of all pairs of variables, with linear regression and lowess traces, you can use scatterplotMatrix from car 📦.\n\n\nscatterplotMatrix(\n  ~ fklngth + log10(fklngth) + rdwght + log10(rdwght),\n  data = sturgeon,\n  smooth = TRUE, diagonal = \"density\"\n)\n\nWarning in applyDefaults(diagonal, defaults = list(method = \"adaptiveDensity\"),\n: unnamed diag arguments, will be ignored\n\n\n\n\n\n\n\n\n\nNext, calculate the Pearson product-moment correlation between each pair (untransformed and log transformed) using the cor() command. However, to do this, it will be easier if you first add your transformed data as columns in the sturgeon data frame.\n\n\nsturgeon$lfklngth &lt;- with(sturgeon, log10(fklngth))\nsturgeon$lrdwght &lt;- log10(sturgeon$rdwght)\n\nThen you can get the correlation matrix by:\n\ncor(sturgeon[, c(\"fklngth\", \"lfklngth\", \"lrdwght\", \"rdwght\")], use = \"complete.obs\")\n\nNote the use=\"complete.obs\" parameter. It tells R to keep only lines of the data frame where all variables were measured. If there are missing data, some lines will be removed, but correlations will be calculated for the same subset of cases for all pairs of variables. One could use, instead, use=\"pairwise.complete.obs\" , to tell R to only eliminate observations when values are missing for this particular pair of variables. In this situation, if there are missing values in the data frame, the sample size for pairwise correlations will vary. In general, I recommend you use the option use=\"complete.obs\", unless you have so many missing values that it eliminates the majority of your data.\n\nWhy is the correlation between the untransformed variables smaller than between the transformed variables?\n\n\ncor(sturgeon[, c(\"fklngth\", \"lfklngth\", \"lrdwght\", \"rdwght\")], use = \"complete.obs\")\n\n           fklngth  lfklngth   lrdwght    rdwght\nfklngth  1.0000000 0.9921435 0.9645108 0.9175435\nlfklngth 0.9921435 1.0000000 0.9670139 0.8756203\nlrdwght  0.9645108 0.9670139 1.0000000 0.9265513\nrdwght   0.9175435 0.8756203 0.9265513 1.0000000\n\n\nSeveral things should be noted here.\n\nthe correlation between fork length and round weight is high, regardless of which variables are used: so as might be expected, heavier fish are also longer, and vice versa\nthe correlation is greater for the transformed variables than the untransformed variables.\n\nWhy? Because the correlation coefficient is inversely proportional to the amount of scatter around a straight line. If the relationship is curvilinear (as it is for the untransformed data), the scatter around a straight line will be greater than if the relationship is linear. Hence, the correlation coefficient will be smaller.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html#testing-the-significance-of-correlations-and-bonferroni-probabilities",
    "href": "03-reg_lin.html#testing-the-significance-of-correlations-and-bonferroni-probabilities",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "\n3.4 Testing the significance of correlations and Bonferroni probabilities",
    "text": "3.4 Testing the significance of correlations and Bonferroni probabilities\nIt’s possible to test the significance of individual correlations using the commands window. As an example, let’s try testing the significance of the correlation between lfklngth and rdwght (the smallest correlation in the above table).\n\nIn the R script window, enter the following to test the correlation between lfkgnth and rdwght :\n\n\ncor.test(\n  sturgeon$lfklngth, sturgeon$rdwght,\n  alternative = \"two.sided\",\n  method = \"pearson\"\n)\n\n\n    Pearson's product-moment correlation\n\ndata:  sturgeon$lfklngth and sturgeon$rdwght\nt = 24.322, df = 180, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8367345 0.9057199\nsample estimates:\n      cor \n0.8756203 \n\n\nWe see here that the correlation is highly significant (\\(p&lt; 2.2e-16\\)), which is no surprise given how high the correlation coefficient is (0.8756).\nIt’s important to bear in mind that when you are estimating correlations, the probability of finding any one correlation that is “significant” by pure chance increases with the number of pairwise correlations examined. Suppose, for example, that you have five variables; there are then a total of 10 possible pairwise correlations, and from this set, you would probably not be surprised to find at least one that is “significant” purely by chance. One way of avoiding the problem is to adjust individual \\(\\alpha\\) levels for pairwise correlations by dividing by the number of comparisons, k, such that: \\(\\alpha' = \\frac{\\alpha}{k}\\) (Bonferroni probabilities), i.e. if initially, \\(\\alpha = 0.05\\) and there are a total of 10 comparisons, then \\(\\alpha'= 0.005\\).\nIn the above example where we examined correlations between fklngth and rdwght and their log, it would be appropriate to adjust the \\(\\alpha\\) at which significance is tested by the total number of correlations in the matrix (in this case, 6, so \\(\\alpha'=0.0083\\)). Does your decision about the significance of the correlation between lfklngth and rdwght change?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html#non-parametric-correlations-spearmans-rank-and-kendalls-tau",
    "href": "03-reg_lin.html#non-parametric-correlations-spearmans-rank-and-kendalls-tau",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "\n3.5 Non-parametric correlations: Spearman’s rank and Kendall’s \\(\\tau\\)\n",
    "text": "3.5 Non-parametric correlations: Spearman’s rank and Kendall’s \\(\\tau\\)\n\nThe analysis done with the sturgeon data in the section above suggests that one of the assumptions of correlation, namely, bivariate normality, may not be valid for fklngth and rdwght nor for the log transforms of these variables. Finding an appropriate transformation is sometimes like looking for a needle in a haystack; indeed, it can be much worse simply because for some distributions, there is no transformation that will normalize the data. In such cases, the best option may be to go to a non-parametric analysis that does not assume bivariate normality or linearity. All such correlations are based on the ranks rather than the data themselves: two options available in R are Spearman and Kendall’s \\(\\tau\\) (tau).\n\nTest the correlation between fklngth and rdwght using both the Spearman and Kendall’s tau. The following commands will produce the correlations:\n\n\ncor.test(\n  sturgeon$lfklngth, sturgeon$rdwght,\n  alternative = \"two.sided\",\n  method = \"spearman\"\n)\n\nWarning in cor.test.default(sturgeon$lfklngth, sturgeon$rdwght, alternative =\n\"two.sided\", : Cannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  sturgeon$lfklngth and sturgeon$rdwght\nS = 47971, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.9522546 \n\n\n\ncor.test(\n  sturgeon$lfklngth, sturgeon$rdwght,\n  alternative = \"two.sided\",\n  method = \"kendall\"\n)\n\n\n    Kendall's rank correlation tau\n\ndata:  sturgeon$lfklngth and sturgeon$rdwght\nz = 16.358, p-value &lt; 2.2e-16\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.8208065 \n\n\nContrast these results with those obtained using the Pearson product-moment correlation. Why the difference?\nTest the non-parametric correlations on pairs of the transformed variables. You should immediately note that the non-parametric correlations are identical for untransformed and transformed variables. This is because we are using the ranks, rather than the raw data, and the rank ordering of the data does not change when a transformation is applied to the raw values.\nNote that the correlations for Kendall’s tau (0.820) are lower than for the Spearman rank (0.952) correlation. This is because Kendall’s gives more weight to ranks that are far apart, whereas Spearman’s weights each rank equally. Generally, Kendalls’s is more appropriate when there is more uncertainty about the reliability of close ranks.\nThe sturgeons in this sample were collected using nets and baited hooks of a certain size. What impact do you think this method of collection had on the shapes of the distributions of fklngth and rdwght ? Under these circumstances, do you think correlation analysis is appropriate at all?\nNote that correlation analysis assumes that each variable is randomly sampled. In the case of sturgeon, this is not the case: baited hooks and nets will only catch sturgeon above a certain minimum size. Note that in the sample, there are no small sturgeons, since the fishing gear targets only larger fish. Thus, we should be very wary of the correlation coefficients associated with our analysis, as the inclusion of smaller fish may well change our estimate of these correlations.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html#simple-linear-regression",
    "href": "03-reg_lin.html#simple-linear-regression",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "\n3.6 Simple linear regression",
    "text": "3.6 Simple linear regression\nIn correlation analysis we are interested in how pairs of variables covary: However, in regression analysis, we are attempting to estimate a model that predicts a variable (the dependent variable) from another variable (the independent variable).\nAs with any statistical analysis, the best way to begin is by looking at your data. If you are interested in the relationship between two variables, say, Y and X, produce a plot of Y versus X just to get a “feel” for the relationship.\n\nThe data file sturgeon.csv contains data for sturgeons collected from 1978-1980 at Cumberland House, Saskatchewan and The Pas, Manitoba. Make a scatterplot of fklngth (the dependent variable) versus age (the independent variable) for males and add a linear regression and a loess smoother. What do you conclude from this plot?\n\n\nsturgeon.male &lt;- subset(sturgeon, subset = sex == \"MALE\")\nmygraph &lt;- ggplot(\n  data = sturgeon.male, # source of data\n  aes(x = age, y = fklngth)\n) # aesthetics: y=fklngth, x=rdwght\n# plot data points, regression, loess trace\nmygraph &lt;- mygraph +\n  stat_smooth(method = lm, se = FALSE, color = \"green\") + # add linear regression, but no SE shading\n  stat_smooth(color = \"red\") + # add loess\n  geom_point() # add data points\nmygraph # display graph\n\n\n\n\n\n\n\nThis suggests that the relationship between age and fork length is not linear.\nSuppose that we want to know the growth rate of male sturgeon. One estimate (perhaps not a very good one) of the growth rate is given by the slope of the fork length - age regression.\nFirst, let’s run the regression with the lm() command, and save its results in an object called RegModel.1.\n\nRegModel.1 &lt;- lm(fklngth ~ age, data = sturgeon.male)\n\nNothing appears on the screen, but don’t worry, it all got saved in memory. To see the statistical results, type:\n\nsummary(RegModel.1)\n\n\nCall:\nlm(formula = fklngth ~ age, data = sturgeon.male)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.4936 -2.2263  0.1849  1.7526 10.8234 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 28.50359    1.16873   24.39   &lt;2e-16 ***\nage          0.70724    0.05888   12.01   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.307 on 73 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.664, Adjusted R-squared:  0.6594 \nF-statistic: 144.3 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nR output gives you:\n\n\nCall: A friendly reminder of the model fitted and the data used.\n\nResiduals: General statistics about the residuals around the fitted model.\n\nCoefficients: Fitted model parameter estimates, standard errors, t values and associated probabilities.\n\nResidual standard error: Square root of the residual variance.\n\nMultiple R-squared: Coefficient of determination. It corresponds to the proportion of the total variance of the dependent variable that is accounted for by the regression (i.e. by the independent variable)\n\nAdjusted R-squared: The adjusted R-squared accounts for the number of parameters in the model. If you want to compare the performance of several models with different numbers of parameters, this is the one to use\n\nF-statistic: This is the test of the overall significance of the model. In the simple regression case, this is the same as the test of the slope of the regression.\n\nThe estimated regression equation is therefore:\n\\[ Fklngth = 28.50359 + 0.70724 * age\\]\nGiven the highly significant F-value of the model (or equivalently the highly significant t-value for the slope of the line), we reject the null hypothesis that there is no relationship between fork length and age.\n\n3.6.1 Testing regression assumptions\nSimple model I regression makes four assumptions:\n\nthe X variable is measured without error;\nthe relationship between Y and X is linear;\nthat for any value of X, the Y’s are independently and normally distributed;\nthe variance of Y for fixed X is independent of X.\n\nHaving done the regression, we can now test the assumptions. For most biological data, the first assumption is almost never valid; usually there is error in both Y and X. This means that in general, slope estimates are biased, but predicted values are unbiased. However, so long as the error in X is small relative to the range of X in your data, the fact that X has an associated error is not likely to influence the outcome dramatically. On the other hand, if there is substantial error in X, regression results based on a model I regression may give poor estimates of the functional relationship between Y and X. In this case, more sophisticated regression procedures must be employed which are, unfortunately, beyond the scope of this course.\nThe other assumptions of a model I regression can, however, be tested, or at least evaluated visually. The plot() command can display diagnostics for linear models.\n\npar(mfrow = c(2, 2), las = 1)\nplot(RegModel.1)\n\nThe par() command is used here to tell R to display 2 rows and 2 columns of graphs per page (there are 4 diagnostic graphs for linear models generated automatically), and the last statement is to tell R to rotate the labels of the Y axis so that they are perpendicular to the Y axis. (Yes, I know, this is not at all obvious.)\nYou will get:\n\n\n\n\n\n\n\n\n\n\nUpper left tell you about linearity, normality, and homoscedasticity of the residuals. It shows the deviations around the regression vs the predicted values. Remember that the scatterplot ( fklngth vs age ) suggested that the relationship between fork length and age is not linear. Very young and very old sturgeons tended to fall under the line, and fish of average age tended to be a bit above the line. This is exactly what the residual vs fitted plot shows. The red line is a lowess trace through these data. If the relationship was linear, it would be approximately flat and close to 0. The scatter of residuals tells you a bit about their normality and homoscedasticity, although this graph is not the best way to look at these properties. The next two are better.\n\nUpper right is to assess the normality of the residuals. It is a QQ plot of the residuals . If the residuals were normally distributed, they would fall very close to the diagonal line. Here, we see it is mostly the case, except in the tails\n\nBottom left titled Scale-Location, helps with assessing homoscedasticity. It plots the square root of the absolute value of the standardized residual (residual divided by the standard error of the residuals, this scales the residuals so that their variance is 1 ) as a function of the fitted value. This graph can help you visualize whether the spread of the residuals is constant or not. If residuals are homoscedastic, then the average will not change with increasing fitted values. Here, there is slight variability, but it is not monotonous (i.e. it does not increase or decrease systematically) and there is no strong evidence against the assumption of homoscedasticity.\n\nBottom right plots the residuals as a function of leverage and can help detecting the presence of outliers or points that have a very strong influence on the regression results. The leverage of a point measures how far it is from the other points, but only with respect to the independent variable. In the case of simple linear regression, it is a function of the difference between the observation and the mean of the independent variable. You should look more closely at any observation with a leverage value that is greater than: \\(2(k+1)/n\\), where $\\(k\\) is the number of independent variables (here 1), and \\(n\\) is the number of observations. In this case there is 1 independent variable, 75 observations, and points with a leverage higher than 0.053 may warrant particular scrutiny. The plot also gives you information about how the removal of a point from the data set would change the predictions. This is measured by the Cook’s distance, illustrated by the red lines on the plot. A data point with a Cook distance larger than 1 has a large influence.\n\n\n\n\n\n\n\nNote that R automatically labels the most extreme cases on each of these 4 plots. It does not mean that these cases are outliers, or that you necessarily need be concerned with them. In any data set, there will always be a minimum and a maximum residual.\n\n\n\nThe R package performance offers a new and updated version of those graphs with colours and more plots to help visually assess the assumptions with the function model_check()\n\ncheck_model(RegModel.1)\n\n\n\n\n\n\n\nSo, what is the verdict about the linear regression between fklngth and age ? It fails the linearity, possibly fails the normality, passes homoscedasticity, and this does not seem to be too strongly affected by some bizarre points.\n\n3.6.2 Formal tests of regression assumptions\nIn my practice, I seldom use formal tests of regression assumptions and mostly rely on graphs of the residuals to guide my decisions. To my knowledge, this is what most biologists and data analysts do. However, in my early analyst life I was not always confident that I was interpreting these graphs correctly and wished that I had a formal test or a statistic quantifying the degree of deviation from the regression assumptions.\nThe lmtest R package, not part of the base R installation, but available from CRAN, contains a number of tests for linearity and homoscedasticity. And one can test for normality using the Shapiro-Wilk test seen previously.\nFirst, you need to load (and maybe install) the lmtest package.\n\nlibrary(lmtest)\n\n\n\n\n\n\n\nExercise\n\n\n\nRun the following commands\n\n\n\nbptest(RegModel.1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  RegModel.1\nBP = 1.1765, df = 1, p-value = 0.2781\n\n\nThe Breusch-Pagan test examines whether the variability of the residuals is constant with respect to increasing fitted values. A low p value is indicative of heteroscedasticity. Here, the p value is high, and supports my visual assessment that the homoscedasticity assumption is met by these data.\n\ndwtest(RegModel.1)\n\n\n    Durbin-Watson test\n\ndata:  RegModel.1\nDW = 2.242, p-value = 0.8489\nalternative hypothesis: true autocorrelation is greater than 0\n\n\nThe Durbin-Watson test can detect serial autocorrelation in the residuals. Under the assumption of no autocorrelation, the D statistic is 2. This test can detect violation of independence of observations (residuals), although it is not foolproof. Here there is no problem identified.\n\nresettest(RegModel.1)\n\n\n    RESET test\n\ndata:  RegModel.1\nRESET = 14.544, df1 = 2, df2 = 71, p-value = 5.082e-06\n\n\nThe RESET test is a test of the assumption of linearity. If the linearity assumption is met, the RESET statistic will be close to 1. Here, the statistic is much larger (14.54), and very highly significant. This confirms our visual assessment that the relationship is not linear.\n\nshapiro.test(residuals(RegModel.1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(RegModel.1)\nW = 0.98037, p-value = 0.2961\n\n\nThe Shapiro-Wilk normality test on the residual confirms that the deviation from normality of the residuals is not large.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html#data-transformations-in-regression",
    "href": "03-reg_lin.html#data-transformations-in-regression",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "\n3.7 Data transformations in regression",
    "text": "3.7 Data transformations in regression\nThe analysis above revealed that the linearity assumption underlying regression analysis is not met by the fklngth - age data. If we want to use regression analysis, data transformations are required:\nLet’s plot the log-transformed data\n\npar(mfrow = c(1, 1), las = 1)\nggplot(\n  data = sturgeon.male,\n  aes(x = log10(age), y = log10(fklngth))\n) +\n  geom_smooth(color = \"red\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"green\") +\n  geom_point()\n\n\n\n\n\n\n\nWe can fit the linear regression model on the log-transformed variables.\n\nRegModel.2 &lt;- lm(log10(fklngth) ~ log10(age), data = sturgeon.male)\nsummary(RegModel.2)\n\n\nCall:\nlm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.082794 -0.016837 -0.000719  0.021102  0.087446 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.19199    0.02723   43.77   &lt;2e-16 ***\nlog10(age)   0.34086    0.02168   15.72   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03015 on 73 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.772, Adjusted R-squared:  0.7688 \nF-statistic: 247.1 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nNote that by using the log transformed data, the proportion of variation explained by the regression has increased by 10% (from 0.664 to 0.772), a substantial increase. So the relationship has become more linear. Good. Let’s look at the residual diagnostic plots:\n\npar(mfrow = c(2, 2), las = 1)\nplot(RegModel.2)\n\n\n\n\n\n\ncheck_model(RegModel.2)\n\n\n\n\n\n\n\nSo things appear a little better than before, although still not ideal. For example, the Residual vs fitted plot still suggests a potential nonlinearity. The QQ plot is nicer than before, indicating that residuals are more normally distributed after the log-log transformation. There is no indication of heteroscedasticity. And, although there are still a few points with somewhat high leverage, none have a Cook’s distance above 0.5. It thus seems that transforming data improved things: more linear, more normal, less dependence on extreme data. Do the formal tests support this visual assessment?\n\nbptest(RegModel.2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  RegModel.2\nBP = 0.14282, df = 1, p-value = 0.7055\n\ndwtest(RegModel.2)\n\n\n    Durbin-Watson test\n\ndata:  RegModel.2\nDW = 2.1777, p-value = 0.6134\nalternative hypothesis: true autocorrelation is greater than 0\n\nresettest(RegModel.2)\n\n\n    RESET test\n\ndata:  RegModel.2\nRESET = 4.4413, df1 = 2, df2 = 71, p-value = 0.01523\n\nshapiro.test(residuals(RegModel.2))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(RegModel.2)\nW = 0.98998, p-value = 0.8246\n\n\nIndeed, they do: residuals are still homoscedastic (Breusch-Pagan test), show no autocorrelation (Durbin-Watson test), are normal (Shapiro-Wilk test), and they are more linear (p value of the RESET test is now 0.015, instead of 0.000005). Linearity has improved, but is still violated somewhat.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html#dealing-with-outliers",
    "href": "03-reg_lin.html#dealing-with-outliers",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "\n3.8 Dealing with outliers",
    "text": "3.8 Dealing with outliers\nIn this case, there are no real clear outliers. Yes, observations 8, 24, and 112 are labeled as the most extreme in the last set of residual diagnostic plots. But they are still within what I consider the “reasonable” range. But how does one define a limit to the reasonable? When is an extreme value a real outlier we have to deal with? Opinions vary about the issue, but I favor conservatism.\nMy rule is that, unless the value is clearly impossible or an error in data entry, I do not delete “outliers”; rather, I analyze all my data. Why? Because, I want my data to reflect natural or real variability. Indeed, variability is often what interests biologists the most.\nKeeping extreme values is the fairest way to proceed, but it often creates other issues. These values will often be the main reason why the data fail to meet the assumptions of the statistical analysis. One solution is to run the analysis with and without the outliers, and compare the results. In many cases, the two analyses will be qualitatively similar: the same conclusions will be reached, and the effect size will not be very different. Sometimes, however, this comparison will reveal that the presence of the outliers changes the story. The logical conclusion then is that the results depend on the outliers and that the data at hand are not very conclusive. As an example, let’s rerun the analysis after eliminating observations labeled 8, 24, and 112.\n\nRegModel.3 &lt;- lm(log10(fklngth) ~ log10(age), data = sturgeon.male, subset = !(rownames(sturgeon.male) %in% c(\"8\", \"24\", \"112\")))\nsummary(RegModel.3)\n\n\nCall:\nlm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male, \n    subset = !(rownames(sturgeon.male) %in% c(\"8\", \"24\", \"112\")))\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.069163 -0.017390  0.000986  0.018590  0.047647 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.22676    0.02431   50.46   &lt;2e-16 ***\nlog10(age)   0.31219    0.01932   16.16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02554 on 70 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.7885,    Adjusted R-squared:  0.7855 \nF-statistic:   261 on 1 and 70 DF,  p-value: &lt; 2.2e-16\n\n\nThe intercept, slope, and R squared are about the same, and the significance of the slope is still astronomical. Removing the “outliers” has little effect in this case.\nAs for the diagnostic residual plots and the formal tests of assumptions:\n\npar(mfrow = c(2, 2))\nplot(RegModel.3)\n\n\n\n\n\n\nbptest(RegModel.3)\n\n\n    studentized Breusch-Pagan test\n\ndata:  RegModel.3\nBP = 0.3001, df = 1, p-value = 0.5838\n\ndwtest(RegModel.3)\n\n\n    Durbin-Watson test\n\ndata:  RegModel.3\nDW = 2.0171, p-value = 0.5074\nalternative hypothesis: true autocorrelation is greater than 0\n\nresettest(RegModel.3)\n\n\n    RESET test\n\ndata:  RegModel.3\nRESET = 3.407, df1 = 2, df2 = 68, p-value = 0.0389\n\nshapiro.test(residuals(RegModel.3))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(RegModel.3)\nW = 0.98318, p-value = 0.4502\n\n\nNo real difference either. Overall, this suggests that the most extreme values do not have undue influence on the results.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html#quantifying-effect-size-in-regression-and-power-analysis",
    "href": "03-reg_lin.html#quantifying-effect-size-in-regression-and-power-analysis",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "\n3.9 Quantifying effect size in regression and power analysis",
    "text": "3.9 Quantifying effect size in regression and power analysis\nBiological interpretation differs from statistical interpretation. Statistically, we conclude that size increase with age (i.e. the slope is positive and different from 0). But this conclusion alone does not tell if the difference between young and old fish is large. The slope and the scatterplot are more informative than the p-value here. The slope (in log-log space) is 0.34. This means that for each unit increase of X (log10(age)), there is an increase of 0.34 units of log10(fklngth). In other words, when age is multiplied by 10, fork length is multiplied by about 2 (10^0.34^). Humm, length increases more slowly than age. This slope value (0.34) is an estimate of raw effect size. It measure how much length changes with age.\nIt would also be important to estimate the confidence interval around the estimate of the slope. This can beobtained using the confint() function.\n\nconfint(RegModel.2)\n\n                2.5 %   97.5 %\n(Intercept) 1.1377151 1.246270\nlog10(age)  0.2976433 0.384068\n\n\nThe 95% confidence interval for the slope is 0.29-0.38. It is quite narrow and include only values far from zero.\n\n3.9.1 Power to detect a given slope\nYou can compute power with G*Power for some slope value that you deem of sufficient magnitude to warrant detection.\n\nGo to t Tests: Linear bivariate regression: One group, size of slope.\nSelect Post hoc: Compute achieved power- given \\(\\alpha\\), sample size,and effect size\n\n\nFor example, suppose that sturgeon biologists deem that a slope of 0.1 for the relationship between log10(fklngth) and log10(age) is meaningful and you wanted to estimate the power to detect such a slope with a sample of 20 sturgeons. Results from the log-log regression contain most of what you need:\n\nsummary(RegModel.2)\n\n\nCall:\nlm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.082794 -0.016837 -0.000719  0.021102  0.087446 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.19199    0.02723   43.77   &lt;2e-16 ***\nlog10(age)   0.34086    0.02168   15.72   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03015 on 73 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.772, Adjusted R-squared:  0.7688 \nF-statistic: 247.1 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nNote the Residual standard error value (0.03015). You will need this. The other thing you need is an estimate of the standard deviation of log10(age). R can (of course) compute it. Be careful, the sd() function will return NA if there are missing values. You can get around this by adding na.rm=TRUE as an argument ot the sd() function.\n\nsd(log10(sturgeon.male$age), na.rm = TRUE)\n\n[1] 0.1616675\n\n\nYou can then enter these values (slope to be detected, sample size, alpha, standard deviation of the independent variable) to calculate another quantity that G*Power needs (standard deviation of y) using the Determine panel. Finally you can calculate Power. The filled panels should look like this\n\n\n\n\n\n\nNote: The SD of y can’t just be taken from the data because if the slope chanages (e.g. H1) then this will change the SD of y. SD y needs to be estimated from the observed scatter around the line and the hypothesized slope).\n\n\n\n\n\n\n\nPower analysis for age-length in sturgeon with N = 20 and slope = 0.1\n\n\n\nPower to detect a significant slope, if the slope is 0.1, variability of data points around the regression is like in our sample, for a sample of 20 sturgeons, with \\(\\alpha = 0.05\\) is 0.621. Only about 2/3 of samples of that size would detect a significant effect of age on fklngth.\nIn R, you can do the analysis also but we will use another trick to work with the pwr.t.test() function. First we, need to estimate the effect size d. IN this case d is estimated as: \\[ d = \\frac{b}{s_b\\sqrt{n-k-1}} \\] where \\(b\\) is the slope, \\(s_b\\) is the standard error on the slope, \\(n\\) is the number of observations and \\(k\\) is the number of independent variables (1 for simple liner regression).\nSE of the slope is 0.02168. The model was fitted using 75 fishes (n=75). We can then estimate d. \\[ d = \\frac{b}{s_b\\sqrt{n-k-1}} = \\frac{0.1}{0.02168\\sqrt{74-1-1}}=0.54\\]\nWe can simply use the pwr.t.test() function to estimate the power.\n\nlibrary(pwr)\n\n# analyse de puissance\npwr.t.test(n = 20, d = 0.54, sig.level = 0.05, type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 20\n              d = 0.54\n      sig.level = 0.05\n          power = 0.6299804\n    alternative = two.sided\n\n\nYou can see that the results is really similar but not exactly the same than with G*power which is normal since we did not use the exact same formula to estimate power.\n\n3.9.2 Sample size required to achieve desired power\nTo estimate the sample size required to achieve 99% power to detect a slope of 0.1 (in log-log space), with alpha=0.05, you simply change the type of analysis:\n\n\n\n\nA priori power analysis to estimate the sample size needed to have a power of 0.99\n\n\n\nIn R you can simply do:\n\nlibrary(pwr)\n\n# analyse de puissance\npwr.t.test(power = 0.99, d = 0.54, sig.level = 0.05, type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 64.96719\n              d = 0.54\n      sig.level = 0.05\n          power = 0.99\n    alternative = two.sided\n\n\nBy increasing sample size to 66, with the same assumptions as before, power increases to 99%.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "03-reg_lin.html#bootstrapping-the-simple-linear-regression",
    "href": "03-reg_lin.html#bootstrapping-the-simple-linear-regression",
    "title": "\n3  Correlation and simple linear regression\n",
    "section": "\n3.10 Bootstrapping the simple linear regression",
    "text": "3.10 Bootstrapping the simple linear regression\nA non-parametric test for the intercept and slope of a linear regression can be obtained by bootstrapping.\n\n# load boot\nlibrary(boot)\n# function to obtain regression weights\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ] # allows boot to select sample\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n# bootstrapping with 1000 replications\nresults &lt;- boot(\n  data = sturgeon.male,\n  statistic = bs,\n  R = 1000, formula = log10(fklngth) ~ log10(age)\n)\n# view results\nresults\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = sturgeon.male, statistic = bs, R = 1000, formula = log10(fklngth) ~ \n    log10(age))\n\n\nBootstrap Statistics :\n     original       bias    std. error\nt1* 1.1919926  0.002088188  0.03343620\nt2* 0.3408557 -0.001478888  0.02647836\n\n\nFor each parameter in the model (here the intercept is labeled t1\\* and the slope of the regression line is labeled t2\\*) , you obtain:\nPour chaque paramètre du modèle (ici l’ordonnée à l’origine est appelée t1* et la pente de la régression t2\\*), R imprime :\n\n\noriginal original parameter estimate (on all non-bootstrapped data)\n\nbias the difference between the mean value of all bootstrap estimates and the original value\n\nstd. error standard error of the bootstrap estimate\n\n\npar(mfrow = c(2, 2))\nplot(results, index = 1) # intercept\n\n\n\n\n\n\nplot(results, index = 2) # log10(age)\n\n\n\n\n\n\n\nThe distribution of the bootstrapped estimates is rather Gaussian, with only small deviations in the tails (where it counts for confidence intervals…). One could use the standard error of the bootstrap estimates to calculate a symmetrical confidence interval as mean +- t SE. But, given that R can as easily calculate a bias-corrected adjusted (BCa) confidence interval, or one based on the actual distribution, (Percentile) why not have it do it all:\n\n# interval de confiance pour l'ordonnée à l'origine\nboot.ci(results, type = \"all\", index = 1)\n\nWarning in boot.ci(results, type = \"all\", index = 1): bootstrap variances\nneeded for studentized intervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"all\", index = 1)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 1.124,  1.255 )   ( 1.123,  1.259 )  \n\nLevel     Percentile            BCa          \n95%   ( 1.125,  1.261 )   ( 1.115,  1.251 )  \nCalculations and Intervals on Original Scale\n\n\n\n# intervalle de confiance pour la pente\nboot.ci(results, type = \"all\", index = 2)\n\nWarning in boot.ci(results, type = \"all\", index = 2): bootstrap variances\nneeded for studentized intervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"all\", index = 2)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 0.2904,  0.3942 )   ( 0.2882,  0.3948 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.2870,  0.3935 )   ( 0.2942,  0.4018 )  \nCalculations and Intervals on Original Scale\n\n\nHere the 4 types of CI that R managed to calculate are essentially the same. Had data been violating more strongly the standard assumptions (normality, homoscedasticity), then the different methods (Normal, Basic, Percentile, and BCa) would have diverged more. In that case, which one is best? BCa has the favor of most, currently.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Correlation and simple linear regression</span>"
    ]
  },
  {
    "objectID": "04-t_test.html",
    "href": "04-t_test.html",
    "title": "\n4  Two - sample comparisons\n",
    "section": "",
    "text": "4.1 R packages and data\nFor this la b you need:\nYou need to load the packages in R with library() and if need needed install them first with install.packages() For the data, load them using the read.csv() function.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two - sample comparisons</span>"
    ]
  },
  {
    "objectID": "04-t_test.html#set-ttest",
    "href": "04-t_test.html#set-ttest",
    "title": "\n4  Two - sample comparisons\n",
    "section": "",
    "text": "R packages:\n\ncar\nlmtest\nboot\npwr\nggplot2\nperformance\n\n\ndata:\n\nsturgeon.csv\nskulldat_2020.csv",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two - sample comparisons</span>"
    ]
  },
  {
    "objectID": "04-t_test.html#visual-examination-of-sample-data",
    "href": "04-t_test.html#visual-examination-of-sample-data",
    "title": "\n4  Two - sample comparisons\n",
    "section": "\n4.2 Visual examination of sample data",
    "text": "4.2 Visual examination of sample data\nOne of the first steps in any type of data analysis is to visualize your data with plots and summary statistics, to get an idea of underlying distributions, possible outliers, and trends in your data. This often begins with plots of the data, such as histograms, probability plots, and box plots, that allow you to get a feel for whether your data are normally distributed, whether they are correlated one to the other, or whether there are any suspicious looking points that may lead you to go back to the original data file to check for errors.\nSuppose we want to test the null hypothesis that the size, as indexed by fork length ( fklngth in file sturgeon.csv - the length, in cm, from the tip of the nose to the base of the fork in the caudal fin), of sturgeon at The Pas and Cumberland House is the same. To begin, we have a look at the underlying distributions of the sample data to get a feel for whether the data are normally distributed in each sample. We will not actually test for normality at this point; the assumption of normality in parametric analyses refers always to the residuals and not the raw data themselves. However, if the raw data are non-normally distributed, then you usually have good reason to suspect that the residuals also will be non-normally distributed.\nAn excellent way to visually compare a data distribution to a normal distribution is to superimpose a histogram of the data and a normal curve. To do so, we must proceed in two steps:\n\ntell R that we want to make a histogram with a density curve superimposed\ntell R that we want this to be done for both locations.\n\n\nUsing the data file sturgeon.csv , generate histograms for fklngth data at The Pas and Cumberland House.\n\n\n# use \"sturgeon\" dataframe to make plot called mygraph\n# and define x axis as representing fklngth\nmygraph &lt;- ggplot(\n  data = sturgeon,\n  aes(x = fklngth)\n) +\n  xlab(\"Fork length (cm)\")\n# add data to the mygraph ggplot\nmygraph &lt;- mygraph +\n  geom_density() + # add data density smooth\n  geom_rug() + # add rug (bars at the bottom of the plot)\n  geom_histogram( # add black semitransparent histogram\n    aes(y = ..density..),\n    color = \"black\", alpha = 0.3\n  ) +\n  # add normal curve in red, with mean and sd from fklength\n  stat_function(\n    fun = dnorm,\n    args = list(\n      mean = mean(sturgeon$fklngth),\n      sd = sd(sturgeon$fklngth)\n    ),\n    color = \"red\"\n  )\n# display graph, by location\nmygraph + facet_grid(. ~ location)\n\n\n\nDistribution of sturgeon length at 2 locations\n\n\n\nBased on your visual inspection, are the two samples normally distributed? Visual inspection of these plots suggests that this variable is approximately normally distributed in each sample.\nSince we are interested in finding out if mean fish size differs among the two locations, it is probably also a good idea to generate a graph that compares the two groups of data. A box plot works well for this.\n\nGenerate a box plot of fklngth grouped by location . What do you conclude about differences in size among the two locations?\n\n\nggplot(data = sturgeon, aes(\n  x = location,\n  y = fklngth\n)) +\n  geom_boxplot(notch = TRUE)\n\n\n\nBoxplot of sturgeon legnth at 2 locations\n\n\n\nIt would appear as though there are not big differences in fish size among the two locations, although fish size at The Pas looks to be more variable, with a bigger range in size and outliers (defined as values &gt; 1.5 * inter-quartile range) at both ends of the distribution.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two - sample comparisons</span>"
    ]
  },
  {
    "objectID": "04-t_test.html#comparing-means-of-two-independent-samples-parametric-and-non-parametric-comparisons",
    "href": "04-t_test.html#comparing-means-of-two-independent-samples-parametric-and-non-parametric-comparisons",
    "title": "\n4  Two - sample comparisons\n",
    "section": "\n4.3 Comparing means of two independent samples: parametric and non-parametric comparisons",
    "text": "4.3 Comparing means of two independent samples: parametric and non-parametric comparisons\nTest the null hypothesis that the mean fklngth of The Pas and Cumberland House samples are the same. Using 3 different tests:\n\nparametric test with equal variances\nparametric test with unequal variances\nnon-parametric test\n\nWhat do you conclude?\n\n# t-test assuming equal variances\nt.test(\n  fklngth ~ location,\n  data = sturgeon,\n  alternative = \"two.sided\",\n  var.equal = TRUE\n)\n\n\n    Two Sample t-test\n\ndata:  fklngth by location\nt = 2.1359, df = 184, p-value = 0.03401\nalternative hypothesis: true difference in means between group CUMBERLAND and group THE_PAS is not equal to 0\n95 percent confidence interval:\n 0.1308307 3.2982615\nsample estimates:\nmean in group CUMBERLAND    mean in group THE_PAS \n                45.08439                 43.36984 \n\n\n\n# t-test assuming unequal variances\nt.test(\n  fklngth ~ location,\n  data = sturgeon,\n  alternative = \"two.sided\",\n  var.equal = FALSE\n)\n\n\n    Welch Two Sample t-test\n\ndata:  fklngth by location\nt = 2.2201, df = 169.8, p-value = 0.02774\nalternative hypothesis: true difference in means between group CUMBERLAND and group THE_PAS is not equal to 0\n95 percent confidence interval:\n 0.1900117 3.2390804\nsample estimates:\nmean in group CUMBERLAND    mean in group THE_PAS \n                45.08439                 43.36984 \n\n\n\n# test non paramétrique\nwilcox.test(\n  fklngth ~ location,\n  data = sturgeon,\n  alternative = \"two.sided\"\n)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  fklngth by location\nW = 4973, p-value = 0.06296\nalternative hypothesis: true location shift is not equal to 0\n\n\nBased on the t-test, we would reject the null hypothesis, i.e. there is a significant (but not highly significant) difference in mean fork length between the two populations.\nNote that using the Wilcoxon rank sum test, we do not reject the null hypothesis. The two different tests therefore give us two different results. The significant difference obtained using the t-test may, at least in part, be due to deviations from normality or homoscedasticity; on the other hand, the non-significant difference obtained using the U -statistic may be due to the fact that for fixed sample size, the power of a non-parametric test is lower than the corresponding parametric test. Given the p values obtained from both tests, and the fact that for samples of this size (84 and 101), the t-test is comparatively robust with respect to non-normality, I would be inclined to reject the null hypothesis. In practice to avoid P-hacking, you should decide which test is appropriate first and then apply and interpret it, or if you decide to do all you should present results of all and interpret accordingly.\nBefore accepting the results of the parametric t-test and rejecting the null hypothesis that there is no difference in size between the two locations, one should do some sort of assessment to determine if the model fits the assumption of normally distributed residuals and equal variances. Preliminary examination of the raw data suggested the data appeared roughly normal but there might be problems with variances (since the spread of data for The_Pas was much greater than for Cumberland). We can examine this more closely by looking at the residuals. An easy way to do so, is to fit a linear model and use the residual diagnostic plots:\n\nm1 &lt;- lm(fklngth ~ location, data = sturgeon)\npar(mfrow = c(2, 2))\nplot(m1)\n\n\n\nModel assumption checks\n\n\n\nThe first plot above shows the spread of the residuals around the estimated values for the two groups and allows us to get a feel for whether there are problems with the assumption of homogeneity of variances. If the variances were equal, the vertical spread of the two clusters of points should be about the same. The above plot shows that the vertical spread of the group with the smaller mean is greater than it is for the larger mean, suggesting again that there are problems with the variances. We can test this formally by examining the mean differences in the absolute value of the residuals.\nThe second graph above is a normal QQ plot (or probability plot) of the residuals of the model. Note that these generally fall on a straight line, suggesting there is no real problem with normality. We can do a formal test for normality on the residuals using the Shapiro-Wilk test.\n\nshapiro.test(residuals(m1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(m1)\nW = 0.97469, p-value = 0.001857\n\n\nHummm. The test indicates that the residuals are not normal. But, given that (a) the distribution is not very far (at least visually) from normal, and that (b) the number of observations in each location is reasonably large (i.e. &gt;30), we do not need to be overly concerned with this violation of the normality assumption.\nHow about equality of variance?\n\nlibrary(car)\nleveneTest(m1)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value    Pr(&gt;F)    \ngroup   1  11.514 0.0008456 ***\n      184                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nbptest(m1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  m1\nBP = 8.8015, df = 1, p-value = 0.00301\n\n\nThe above are the results of two tests implemented in R (in the car and lmtest packages 📦 that can be used to test for equal variances in t-tests or linear models involving only discontinuous or categorical independent variables. Doing the two of them is overkill. There is not much to prefer one test over another. Levene test is possibly the better known. It tests whether the mean of absolute values of the residuals differs among groups. The Breusch-Pagan test has the advantage of being applicable to more linear models (it can deal with regression-type continuous independent variables, at least to some extent). It tests whether the studentized (i.e. scaled by their sd estimate) squared residuals vary with the independent variables in a linear model. In this case, both indicate that variances are unequal.\nOn the basis of these results, we conclude that there is evidence (albeit weak) to reject the null hypothesis of no difference in fklngth by location. We have modified the t-test to accommodate unequal variances, and are satisfied that the assumption of normally distributed residuals is sufficiently met. Thus, it appears that fklngth at Cumberland is greater than fklngth at The Pas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two - sample comparisons</span>"
    ]
  },
  {
    "objectID": "04-t_test.html#bootstrap-and-permutation-tests-to-compare-2-means",
    "href": "04-t_test.html#bootstrap-and-permutation-tests-to-compare-2-means",
    "title": "\n4  Two - sample comparisons\n",
    "section": "\n4.4 Bootstrap and permutation tests to compare 2 means",
    "text": "4.4 Bootstrap and permutation tests to compare 2 means\n\n4.4.1 Bootstrap\nBootstrap and permutation tests can be used to compare means (or other statistics) between pairs of samples. The general idea is simple, and it can be implemented in more ways than I can count. Here, I use existing tools and the fact that a comparison of means can be construed as a test of a linear model. We will be able to use similar code later on when we fit more complex (but fun!) models.\n\nlibrary(boot)\n\nThe first section defines the function that I called bs that simply extracts coefficients from a fitted model:\n\n# function to obtain model coefficients for each iteration\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ]\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n\nThe second section with the boot() command is where the real work is done: take data in sturgeon, bootstrap \\(R = 1000\\) times, each time fit the model fklngth vs location, and keep the values calculated by the bs() function.\n\n# bootstrapping with 1000 replications\nresults &lt;- boot(\n  data = sturgeon, statistic = bs, R = 1000,\n  formula = fklngth ~ location\n)\n# view results\nresults\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = sturgeon, statistic = bs, R = 1000, formula = fklngth ~ \n    location)\n\n\nBootstrap Statistics :\n     original       bias    std. error\nt1* 45.084391  0.004105109   0.4414244\nt2* -1.714546 -0.011763884   0.7449435\n\n\nSo we get the original estimates for the two coefficients in this model: the mean at the first (alphabetical) location, Cumberland, and the difference in means between Cumberland and The Pas ). It is the second parameter, the difference between means, which is of interest here.\n\nplot(results, index = 2)\n\n\n\nDistribution of bootstrapped mean difference\n\n\n\n\n# get 95% confidence intervals\nboot.ci(results, type = \"bca\", index = 2)\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"bca\", index = 2)\n\nIntervals : \nLevel       BCa          \n95%   (-3.088, -0.235 )  \nCalculations and Intervals on Original Scale\n\n\nThe 95% CI for the difference between the two means does not include 0. Hence, the bootstrap test indicates that the two means are not equals.\n\n4.4.2 Permutation\nPermutation tests for linear models can easily be done using the lmPerm package 📦.\n\nm1Perm &lt;- lmp(\n  fklngth ~ location,\n  data = sturgeon,\n  perm = \"Prob\"\n)\n\n[1] \"Settings:  unique SS \"\n\n\nThe lmp() function does all the work for us. Here it is run with the option perm to control the stopping rule used. Option Prob stops the sampling when the estimated standard deviation of the p-value falls below some fraction of the estimated. It is one of many stopping rules that one could use to do permutations on a subset of all the possibilities (because it would take foreeeever to do them all, even on your fast machine).\n\nsummary(m1Perm)\n\n\nCall:\nlmp(formula = fklngth ~ location, data = sturgeon, perm = \"Prob\")\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-18.40921  -3.75370  -0.08439   3.76598  23.48055 \n\nCoefficients:\n          Estimate Iter Pr(Prob)  \nlocation1   0.8573 3624    0.027 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.454 on 184 degrees of freedom\nMultiple R-Squared: 0.02419,    Adjusted R-squared: 0.01889 \nF-statistic: 4.562 on 1 and 184 DF,  p-value: 0.03401 \n\n\n\n\nIter coefficient: the Prob stopping rule stopped after 0.4013591 iterations. Note that this number will vary each time you run this snippet of code. These are random permutation results, so expect variability.\n\nPr(Prob) coefficient: The estimated probability associated to H0 is 2.1359 . The observed difference in fklngth between the two locations was larger than the permuted differences in about (1 - 2.1359= about -113.6%) of the 0.4013591 cases. Mind you, 0.4013591 permutations is not a large number, so small p values can’t be expected to be very precise. If it is critical that you get more precise p values, more permutations would be needed. Two parameters can be tweaked: maxIter, the maximum number of iterations (default=5000), and Ca, that stops iterations when estimated standard error of the estimated p is less than Ca*p. Default 0.1.\n\nF-statistic: The rest is the standard output for the model fitted to the data, with the standard parametric test. Here the p-value, assuming all assumptions are met, is 0.034.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two - sample comparisons</span>"
    ]
  },
  {
    "objectID": "04-t_test.html#comparing-the-means-of-paired-samples",
    "href": "04-t_test.html#comparing-the-means-of-paired-samples",
    "title": "\n4  Two - sample comparisons\n",
    "section": "\n4.5 Comparing the means of paired samples",
    "text": "4.5 Comparing the means of paired samples\nIn some experimental designs, individuals are measured twice: common examples are the measurement of the same individual at two different times during development, or of the same individual subjected to two different experimental treatments. In these cases, the two samples are not independent (they include the same individuals), and a paired comparison must be made.\nThe file skulldat_2020.csv shows measurements of lower face width of 15 North American girls measured at age 5 and again at age 6 years (data from Newman and Meredith, 1956).\n\nLet’s first run a standard t-test comparing the face width at age 5 and 6, not taking into account that the data are not independent and that they are consecutive measurements on the same individuals.\n\n\nskull &lt;- read.csv(\"data/skulldat_2020.csv\")\nt.test(width ~ age,\n  data = skull,\n  alternative = \"two.sided\",\n  paired = FALSE\n)\n\n\n    Welch Two Sample t-test\n\ndata:  width by age\nt = -1.7812, df = 27.93, p-value = 0.08576\nalternative hypothesis: true difference in means between group 5 and group 6 is not equal to 0\n95 percent confidence interval:\n -0.43002624  0.03002624\nsample estimates:\nmean in group 5 mean in group 6 \n       7.461333        7.661333 \n\n\nSo far, we specified the t-test using a formula notation as y ~ x where y is the variable for which we want to compare the means and x is a variable defining the groups. This works really well when the samples are not paired and when the data is presented in a long format. For example theskull data is presented in a long format and contains 3 variables:\n\n\nwidth: head width for each observations\n\nage: age at measurement 5 or 6\n\nid: person identity\n\n\nhead(skull)\n\n  width age id\n1  7.33   5  1\n2  7.53   6  1\n3  7.49   5  2\n4  7.70   6  2\n5  7.27   5  3\n6  7.46   6  3\n\n\nWhen data are paired, we need to indicate how they are paired. In the skulldata, samples are paired by an individual identity, id, with mearurement taken at different ages. However, the function t.test does not cope well with this data structure. We need to transpose the data from a long to a wide format where we have a column per group, with the data of a given individual on the same line. Here is how we can do it.\n\nskull_w &lt;- data.frame(id = unique(skull$id))\nskull_w$width5 &lt;- skull$width[match(skull_w$id, skull$id) & skull$age == 5]\nskull_w$width6 &lt;- skull$width[match(skull_w$id, skull$id) & skull$age == 6]\nhead(skull_w)\n\n  id width5 width6\n1  1   7.33   7.53\n2  2   7.49   7.70\n3  3   7.27   7.46\n4  4   7.93   8.21\n5  5   7.56   7.81\n6  6   7.81   8.01\n\n\nNow, let’s run the appropriate paired t-test. What do you conclude? Compare this with the previous result and explain any differences.\n\nt.test(skull_w$width5, skull_w$width6,\n  alternative = \"two.sided\",\n  paired = TRUE\n)\n\n\n    Paired t-test\n\ndata:  skull_w$width5 and skull_w$width6\nt = -19.72, df = 14, p-value = 1.301e-11\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.2217521 -0.1782479\nsample estimates:\nmean difference \n           -0.2 \n\n\nThe first analysis above assumes that the two samples of girls at age 5 and 6 are independent samples, whereas the second analysis assumes that the same girl is measured twice, once at age 5 and once at age 6 years.\nNote that in the former case, we accept the null based on \\(p = 0.05\\), but in the latter we reject the null. In other words, the appropriate (paired sample) test shows a very significant effect of age, whereas the inappropriate one does not. The reason is because there is a strong correlation between face width at age 5 and face width at age 6:\n\ngraphskull &lt;- ggplot(data = skull_w, aes(x = width5, y = width6)) +\n  geom_point() +\n  labs(x = \"Skull width at age 5\", y = \"Skull width at age 6\") +\n  geom_smooth() +\n  scale_fill_continuous(low = \"lavenderblush\", high = \"red\")\ngraphskull\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\nRelation between head width at age 5 and 6\n\n\n\nWith r = 0.9930841. In the presence of correlation, the standard error of the pairwise difference in face width at age 5 and 6 is much smaller than the standard error of the difference between the mean face width at age 5 and 6. Thus, the associated t-statistic will be much larger for a paired sample test, i.e. the power of the test is much greater, and the p values are smaller.\n\nRepeat the above procedure with the nonparametric alternative, the Wilcoxon signed-rank test. What do you conclude?\n\n\nwilcox.test(skull_w$width5, skull_w$width6,\n  alternative = \"two.sided\",\n  paired = TRUE\n)\n\nWarning in wilcox.test.default(skull_w$width5, skull_w$width6, alternative =\n\"two.sided\", : cannot compute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  skull_w$width5 and skull_w$width6\nV = 0, p-value = 0.0007193\nalternative hypothesis: true location shift is not equal to 0\n\n\nSo, we reach the same conclusion as we did using the paired sample t-test and conclude there are significant differences in skull sizes of girls aged 5 and 6 (what a surprise!).\nBut, wait a minute. We have used two-tailed tests here. But, given what we know about how children grow, a one-tail hypothesis would be preferable. This can be done by changing the alternative option. One uses the alternative hypothesis to decide if it is “less” or greater”. Here, we expect that if there is an effect (i.e the alternative hypothesis), width5 will be less than width6\n\nt.test(skull_w$width5, skull_w$width6,\n  alternative = \"less\",\n  paired = TRUE\n)\n\n\n    Paired t-test\n\ndata:  skull_w$width5 and skull_w$width6\nt = -19.72, df = 14, p-value = 6.507e-12\nalternative hypothesis: true mean difference is less than 0\n95 percent confidence interval:\n       -Inf -0.1821371\nsample estimates:\nmean difference \n           -0.2 \n\nwilcox.test(skull_w$width5, skull_w$width6,\n  alternative = \"less\",\n  paired = TRUE\n)\n\nWarning in wilcox.test.default(skull_w$width5, skull_w$width6, alternative =\n\"less\", : cannot compute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  skull_w$width5 and skull_w$width6\nV = 0, p-value = 0.0003597\nalternative hypothesis: true location shift is less than 0\n\n\n\n\n\n\n\n\nNote that instead of rerunning the t-test specifying a one-tailed test, you can:\n\nif the sign of the estimate goes in the same direction as the alternative hypothesis, simply divide by 2 the probability you obtain with the two-tailed test\nif not the sign of the estimate is in the opposite direction of the alternative hypothesis, use \\(1 - p/2\\)\n\n\n\n\n\nTo estimate the power of a paired t-test in R, we can use the function power.t.test()as for other t-tests but we need to specify the argument type = \"paired\". You need to specify the mean diference within the pairs as the deltaand standard deviance of difference within pairs as sd.\n\nskull_w$diff &lt;- skull_w$width6 - skull_w$width5\npower.t.test(\n  n = 15,\n  delta = mean(skull_w$diff),\n  sd = sd(skull_w$diff),\n  type = \"paired\")\n\n\n     Paired t test power calculation \n\n              n = 15\n          delta = 0.2\n             sd = 0.03927922\n      sig.level = 0.05\n          power = 1\n    alternative = two.sided\n\nNOTE: n is number of *pairs*, sd is std.dev. of *differences* within pairs",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two - sample comparisons</span>"
    ]
  },
  {
    "objectID": "04-t_test.html#bibliography",
    "href": "04-t_test.html#bibliography",
    "title": "\n4  Two - sample comparisons\n",
    "section": "\n4.6 Bibliography",
    "text": "4.6 Bibliography\nBumpus, H.C. (1898) The elimination of the unfit as illustrated by the introduced sparrow, Passer domesticus. Biological Lectures, Woods Hole Biology Laboratory, Woods Hole, 11 th Lecture: 209 - 226.\nNewman, K.J. and H.V. Meredith. (1956) Individual growth in skeletal bigonial diameter during the childhood period from 5 to 11 years of age. Amer. J. Anat. 99: 157 - 187.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Two - sample comparisons</span>"
    ]
  },
  {
    "objectID": "05-anova.html",
    "href": "05-anova.html",
    "title": "\n5  One-way ANOVA\n",
    "section": "",
    "text": "5.1 R packages and data\nFor this lab you need:\nlibrary(ggplot2)\nlibrary(car)\nlibrary(multcomp)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "05-anova.html#set-ano",
    "href": "05-anova.html#set-ano",
    "title": "\n5  One-way ANOVA\n",
    "section": "",
    "text": "R packages:\n\nggplot2\nmultcomp\ncar\n\n\ndata\n\ndam10dat.csv",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "05-anova.html#one-way-anova-with-multiple-comparisons",
    "href": "05-anova.html#one-way-anova-with-multiple-comparisons",
    "title": "\n5  One-way ANOVA\n",
    "section": "\n5.2 One-way ANOVA with multiple comparisons",
    "text": "5.2 One-way ANOVA with multiple comparisons\nThe one-way ANOVA is the multi-group analog of the t-test, which is used to compare two groups/levels. It makes essentially the same assumptions, and in the case of two groups/levels, is in fact mathematically equivalent to the t-test.\nIn 1960-1962, the Grand Rapids Dam was built on the Saskatchewan River upstream of Cumberland House. There are anecdotal reports that during dam construction, a number of large sturgeon were stranded and died in shallow pools. Surveys of sturgeon were carried out in 1954, 1958, 1965 and 1966 with fork length (fklngth) and round weight (rdwght) being recorded (not necessarily both measurements for each individual). These data are in the data file Dam10dat.csv.\n\n5.2.1 Visualiser les données\n\nUsing Dam10dat.csv, you must first change the data type of the numerical variable year , so that R recognizes that we wish to treat this variable as a factor variable and not a continuous variable.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndam10dat &lt;- read.csv(\"data/Dam10dat.csv\")\ndam10dat$year &lt;- as.factor(dam10dat$year)\nstr(dam10dat)\n\n'data.frame':   118 obs. of  21 variables:\n $ year    : Factor w/ 4 levels \"1954\",\"1958\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ fklngth : num  45 50 39 46 54.5 49 42.5 49 56 54 ...\n $ totlngth: num  49 NA 43 50.5 NA 51.7 45.5 52 60.2 58.5 ...\n $ drlngth : logi  NA NA NA NA NA NA ...\n $ drwght  : num  16 20.5 10 17.5 19.7 21.3 9.5 23.7 31 27.3 ...\n $ rdwght  : num  24.5 33 15.5 28.5 32.5 35.5 15.3 40.5 51.5 43 ...\n $ sex     : int  1 1 1 2 1 2 1 1 1 1 ...\n $ age     : int  24 33 17 31 37 44 23 34 33 47 ...\n $ lfkl    : num  1.65 1.7 1.59 1.66 1.74 ...\n $ ltotl   : num  1.69 NA 1.63 1.7 NA ...\n $ ldrl    : logi  NA NA NA NA NA NA ...\n $ ldrwght : num  1.2 1.31 1 1.24 1.29 ...\n $ lrdwght : num  1.39 1.52 1.19 1.45 1.51 ...\n $ lage    : num  1.38 1.52 1.23 1.49 1.57 ...\n $ rage    : int  4 6 3 6 7 7 4 6 6 7 ...\n $ ryear   : int  1954 1954 1954 1954 1954 1954 1954 1954 1954 1954 ...\n $ ryear2  : int  1958 1958 1958 1958 1958 1958 1958 1958 1958 1958 ...\n $ ryear3  : int  1966 1966 1966 1966 1966 1966 1966 1966 1966 1966 ...\n $ location: int  1 1 1 1 1 1 1 1 1 1 ...\n $ girth   : logi  NA NA NA NA NA NA ...\n $ lgirth  : logi  NA NA NA NA NA NA ...\n\n\n\n\n\n\nNext, have a look at the fklngth data, just as we did in the last lab for t-tests. Create a histogram with density line grouped by year to get a feel for what’s happening with your data and a boxplot of length per year. What can you say about these data?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmygraph &lt;- ggplot(dam10dat, aes(x = fklngth)) +\n  labs(x = \"Fork length (cm)\") +\n  geom_density() +\n  geom_rug() +\n  geom_histogram(aes(y = ..density..),\n    color = \"black\",\n    alpha = 0.3\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(\n      mean = mean(dam10dat$fklngth),\n      sd = sd(dam10dat$fklngth)\n    ),\n    color = \"red\"\n  )\n\n# display graph, by year\nmygraph + facet_wrap(~year, ncol = 2)\n\n\n\nDistribution of sturgeon length per year\n\n\n\n\nboxplot(fklngth ~ year, data = dam10dat)\n\n\n\nBoxplot of sturgeon length per year\n\n\n\n\n\n\nIt appears as though there may have been a small drop in fklngth after the construction of the dam, but the data are variable and the effects are not clear. There might also be some problems with normality in the 1954 and 1966 samples, and it looks as though there are outliers in the 1958 and 1966 samples. Let’s proceed with testing the assumptions of the ANOVA by running the analysis and looking at the residuals.\n\n5.2.2 Testing the assumptions of a parametric ANOVA\nParametric one-way ANOVAs have three major assumptions:\n\nthe residuals are normally distributed\nthe error variance is the same for all groups (homoscedasticity)\nthe residuals are independent.\n\nThese assumptions must be tested before we can accept the results of any parametric ANOVA.\n\nCarry out a one-way ANOVA on fklngth by year and produce the residual diagnostic plots\n\n\n# Fit anova model and plot residual diagnostics\nanova.model1 &lt;- lm(fklngth ~ year, data = dam10dat)\npar(mfrow = c(2, 2))\nplot(anova.model1)\n\n\n\nDiagnostic plots for a one-way ANOVA\n\n\n\n\n\n\n\n\n\nDouble check that the independent variable is a factor. If the dependent variable is a character, then you will obtain only 3 graphs and an error message like:\n`hat values (leverages) are all = 0.1\nand there are no factor predictors; no plot no. 5`\n\n\n\nD’après les graphiques, on peut douter de la normalité et de l’homogénéité des variances. Judging from the plots, it looks as though there may be problems with both normality and variance heterogeneity. Note that there is one point (case 59) with large expected values and a large residual that appear to lie well off the line: this is the outlier we noted earlier. This point might be expected to inflate the variance for the group it belongs to. Formal tests may also provide some insight as to whether we should be concerned about normality and variance heterogeneity.\n\nPerform a normality test on the residuals from the ANOVA.\n\n\nshapiro.test(residuals(anova.model1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model1)\nW = 0.91571, p-value = 1.63e-06\n\n\nThis test confirms our suspicions from the probability plot: the residuals are not normally distributed. Recall, however, that the power here is high, so only small deviations from normality are required to reject the null.\n\nNext, test for homoscedasticity:\n\n\nleveneTest(fklngth ~ year, data = dam10dat)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value  Pr(&gt;F)  \ngroup   3  2.8159 0.04234 *\n      114                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe probability value tells you that you can reject the null hypothesis that there is no difference in variances among years. Thus, we conclude there is evidence that the variances in the groups are not equal.\n\n5.2.3 Performing the ANOVA\nLet’s look at the results of the ANOVA, assuming for the moment that assumptions are met well enough.\n\nsummary(anova.model1)\n\n\nCall:\nlm(formula = fklngth ~ year, data = dam10dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.2116  -2.6866  -0.7116   2.2103  26.7885 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  48.0243     0.8566  56.061  &lt; 2e-16 ***\nyear1958      0.1872     1.3335   0.140  0.88859    \nyear1965     -5.5077     1.7310  -3.182  0.00189 ** \nyear1966     -3.3127     1.1684  -2.835  0.00542 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.211 on 114 degrees of freedom\nMultiple R-squared:  0.1355,    Adjusted R-squared:  0.1128 \nF-statistic: 5.957 on 3 and 114 DF,  p-value: 0.0008246\n\n\n\n\nCoefficients: Estimates Note the 4 coefficients printed. They can be used to obtain the predicted values for the model (i.e. the group means). The mean fklngth for the first year (1954) is 48.0243. The coefficients for the 3 other years are the difference between the mean for that year and for 1954. So, the mean for 1965 is (48.0243-5.5077=42.5166). For each estimated coefficient, there is a standard error, a t-value and associated probability (for H0 that the coefficient is 0). Note here that coefficients for 1965 and 1966 are both negative and significantly less than 0. Fish were smaller after the construction of the dam than in 1954. Take these p-values with a grain of salt: these are not corrected for multiple comparisons, and they constitute only a subset of the possible comparisons. In general, I pay little attention to this part of the output and look more at what comes next.\n\nResidual standard error: The square root of the variance of the residuals (observed minus fitted values) corresponds to the amount of variability that is unexplained by the models (here an estimate of how much size varied among fish, once corrected for differences among years)\n\nMutiple R-squared The R-squared is the proportion of the variance of the dependent variable that can be explained by the model. Here the model explains only 13.5% of the variability. Size differences among year are relatively small compared to the ranges of sizes that can occur within years. This corresponds well to the visual impression left by the histograms of fklngth per year\n\n\n\n\nF-Statistic This is the p-value for the “omnibus” test, the test that all means are equal. Here it is much smaller than 0.05 and hence we would reject H0 and conclude that fklngth varies among the years\n\nThe anova() command produces the standard ANOVA table that contains most of the same information:\n\nanova(anova.model1)\n\nAnalysis of Variance Table\n\nResponse: fklngth\n           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nyear        3  485.26 161.755  5.9574 0.0008246 ***\nResiduals 114 3095.30  27.152                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe total variability in fklngth sums of square is partitioned into what can be accounted for by year (485.26) and what is left unexplained as residual variability (3095.30). Year indeed explains \\((485.26/(3095.30+485.26)=.1355\\) or 13.55% of the variability). The mean square of the residuals is their variance.\n\n5.2.4 Performing multiple comparisons of means test\n\nThe pairwise.t.test() function can be used to compare means and adjust (or not) probabilities for multiple comparisons by choosing one of the options for the argument p.adj:\n\nComparing all means without corrections for multiple comparisons.\n\npairwise.t.test(dam10dat$fklngth, dam10dat$year,\n  p.adj = \"none\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  dam10dat$fklngth and dam10dat$year \n\n     1954   1958   1965  \n1958 0.8886 -      -     \n1965 0.0019 0.0022 -     \n1966 0.0054 0.0079 0.1996\n\nP value adjustment method: none \n\n\nOption \"bonf\" adjusts the p-values according to the Bonferroni correction. In this case, since there are 6 p-values calculated, it amounts to simply multiplying the uncorrected p-values by 6 (unless the result is above 1, in that case the adjusted p-value is 1).\n\npairwise.t.test(dam10dat$fklngth, dam10dat$year,\n  p.adj = \"bonf\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  dam10dat$fklngth and dam10dat$year \n\n     1954  1958  1965 \n1958 1.000 -     -    \n1965 0.011 0.013 -    \n1966 0.033 0.047 1.000\n\nP value adjustment method: bonferroni \n\n\nOption \"holm\" is the sequential Bonferroni correction, where the p-values are ranked from (i=1) smallest to (N) largest. The correction factor for p-values is then $\\((N-i+1)\\). Here, for example, we have N=6 pairs that are compared. The lowest uncorrected p-value is 0.0019 for 1954 vs 1965. The corrected p-value becomes \\(0.0019*(6-1+1)= 0.011\\). The second lowest p-value is 0.0022. The corrected p/value is therefore \\(0.0022*(6-2+1)=0.011\\). For the highest p-value, the correction is \\((N-N+1)=1\\), hence it is equal to the uncorrected probability.\n\npairwise.t.test(dam10dat$fklngth, dam10dat$year,\n  p.adj = \"holm\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  dam10dat$fklngth and dam10dat$year \n\n     1954  1958  1965 \n1958 0.889 -     -    \n1965 0.011 0.011 -    \n1966 0.022 0.024 0.399\n\nP value adjustment method: holm \n\n\nThe “fdr” option is for controlling the false discovery rate.\n\npairwise.t.test(dam10dat$fklngth, dam10dat$year,\n  p.adj = \"fdr\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  dam10dat$fklngth and dam10dat$year \n\n     1954   1958   1965  \n1958 0.8886 -      -     \n1965 0.0066 0.0066 -     \n1966 0.0108 0.0119 0.2395\n\nP value adjustment method: fdr \n\n\nThe four post-hoc tests here tell us the same thing: differences are all between two groups of years: 1954/58 and 1965/66, since all comparisons show differences between the 50’s and 60’s but no differences within the 50’s or 60’s. So, in this particular case, the conclusion is not affected by the choice of adjustment method. But in other situations, you will observe contradictory results.\nWhich one to choose? Unadjusted p-values are certainly suspect when there are multiple tests. On the other hand, the traditional Bonferroni correction is very conservative, and becomes even more so when there are a large number of comparisons. Recent work suggest that the fdr approach may be a good compromise when there are a lot of comparisons. The Tukey method of multiple comparisons is one of the most popular and is easily performed with R (note, however, that there is a pesky bug that manifests itself when the independent variable can look like a number rather than a factor, hence the little pirouette with paste0() to add a letter m before the first digit):\n\ndam10dat$myyear &lt;- as.factor(paste0(\"m\", dam10dat$year))\nTukeyHSD(aov(fklngth ~ myyear, data = dam10dat))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = fklngth ~ myyear, data = dam10dat)\n\n$myyear\n                  diff        lwr        upr     p adj\nm1958-m1954  0.1872141  -3.289570  3.6639986 0.9990071\nm1965-m1954 -5.5076577 -10.021034 -0.9942809 0.0100528\nm1966-m1954 -3.3126964  -6.359223 -0.2661701 0.0274077\nm1965-m1958 -5.6948718 -10.436304 -0.9534397 0.0116943\nm1966-m1958 -3.4999106  -6.875104 -0.1247171 0.0390011\nm1966-m1965  2.1949612  -2.240630  6.6305526 0.5710111\n\n\n\npar(mar = c(4, 7, 2, 1))\nplot(TukeyHSD(aov(fklngth ~ myyear, data = dam10dat)), las = 2)\n\n\n\nInter-annual differences in sturgeon length\n\n\n\nThe confidence intervals, corrected for multiple tests by the Tukey method, are plotted for differences among years. Unfortunately, the labels are not all printed because they would overlap, but the order is the same as in the preceding table. The multcomp 📦 can produce a better plot version, but requires a bit more code:\n\n# Alternative way to compute Tukey multiple comparisons\n# set up a one-way ANOVA\nanova_fkl_year &lt;- aov(fklngth ~ myyear, data = dam10dat)\n# set up all-pairs comparisons for factor `year'\n\nmeandiff &lt;- glht(anova_fkl_year, linfct = mcp(\n  myyear =\n    \"Tukey\"\n))\nconfint(meandiff)\n\n\n     Simultaneous Confidence Intervals\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: aov(formula = fklngth ~ myyear, data = dam10dat)\n\nQuantile = 2.5924\n95% family-wise confidence level\n \n\nLinear Hypotheses:\n                   Estimate lwr      upr     \nm1958 - m1954 == 0   0.1872  -3.2696   3.6440\nm1965 - m1954 == 0  -5.5077  -9.9951  -1.0202\nm1966 - m1954 == 0  -3.3127  -6.3417  -0.2837\nm1965 - m1958 == 0  -5.6949 -10.4091  -0.9807\nm1966 - m1958 == 0  -3.4999  -6.8557  -0.1441\nm1966 - m1965 == 0   2.1950  -2.2152   6.6051\n\npar(mar = c(5, 7, 2, 1))\nplot(meandiff)\n\n\n\nInter-annual differences in sturgeon length\n\n\n\nThis is better. Also useful is a plot the means and their confidence intervals with the Tukey groupings shown as letters above:\n\n# Compute and plot means and Tukey CI\nmeans &lt;- glht(\n  anova_fkl_year,\n  linfct = mcp(myyear = \"Tukey\")\n)\ncimeans &lt;- cld(means)\n# use sufficiently large upper margin\n# plot\nold_par &lt;- par(mai = c(1, 1, 1.25, 1))\nplot(cimeans)\n\n\n\nInter-annual differences in sturgeon length\n\n\n\nNote the letters appearing on top. Years labelled with the same letter do not differ significantly.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "05-anova.html#data-transformations-and-non-parametric-anova",
    "href": "05-anova.html#data-transformations-and-non-parametric-anova",
    "title": "\n5  One-way ANOVA\n",
    "section": "\n5.3 Data transformations and non-parametric ANOVA",
    "text": "5.3 Data transformations and non-parametric ANOVA\nIn the above example to examine differences in fklngth among years , we detected evidence of non-normality and variance heterogeneity. If the assumptions underlying a parametric ANOVA are not valid, there are several options:\n\nif sample sizes in each group are reasonably large, parametric ANOVA is reasonably robust with respect to the normality assumption, for the same reason that the t-test is, so the results are probably not too bad;\nwe can transform the data;\nwe can go the non-parametric route.\n\n\nRepeat the one-way ANOVA in the section above, but this time run the analysis on the log 10 fklngth . With this transformation, do some of the problems encountered previously disappear?\n\n\n# Fit anova model on log10 of fklngth and plot residual diagnostics\npar(mfrow = c(2, 2))\nanova.model2 &lt;- lm(log10(fklngth) ~ year, data = dam10dat)\nplot(anova.model2)\n\n\n\nDiagnostic plots for the ANOVA of sturgeon length by year\n\n\n\nLooking at the residuals, things look barely better than before without the log transformation. Running the Wilks-Shapiro test for normality on the residuals, we get:\n\nshapiro.test(residuals(anova.model2))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model2)\nW = 0.96199, p-value = 0.002048\n\n\nSo, it would appear that we still have some problems with the assumption of normality and are just on the border line of meeting the assumption of homogeneity of variances. You have several choices here:\n\ntry to find a different transformation to satisfy the assumptions,\nassume the data are close enough to meeting the assumptions, or\nperform a non-parametric ANOVA.\n\n\nThe most commonly used non-parametric analog of the parametric one-way ANOVA is the Kruskall-Wallis one-way ANOVA. Perform a Kruskall-Wallis one-way ANOVA of fklngth , and compare these results to the parametric analysis above. What do you conclude?\n\n\nkruskal.test(fklngth ~ year, data = dam10dat)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  fklngth by year\nKruskal-Wallis chi-squared = 15.731, df = 3, p-value = 0.001288\n\n\nSo, the conclusion is the same as with the parametric ANOVA: we reject the null that the mean rank is the same for each year. Thus, despite violation of one or more assumptions, the parametric analysis is telling us the same thing as the non-parametric analysis: the conclusion is, therefore, quite robust.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "05-anova.html#dealing-with-outliers",
    "href": "05-anova.html#dealing-with-outliers",
    "title": "\n5  One-way ANOVA\n",
    "section": "\n5.4 Dealing with outliers",
    "text": "5.4 Dealing with outliers\nOur preliminary analysis of the relationship between fklngth and year suggested there might be some outliers in the data. These were evident in the box plots of fklngth by year and flagged as cases 59, 23 and 87 in the residual probability plot and residual-fit plot. In general, you have to have very good reasons for removing outliers from a data set (e.g., you know there was a mistake made in the data collection/entry). However, it is often useful to know how the analysis changes if you remove the outliers from the data set.\n\nRepeat the original ANOVA of fklngth by year but work with a subset of the data without the outliers. Have any of the conclusions changed?\n\n\ndamsubset &lt;- dam10dat[-c(23, 59, 87), ] # removes obs 23, 59 and 87\naov_damsubset &lt;- aov(fklngth ~ as.factor(year), damsubset)\nsummary(aov_damsubset)\n\n                 Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nas.factor(year)   3  367.5  122.50   6.894 0.000267 ***\nResiduals       111 1972.4   17.77                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nshapiro.test(residuals(aov_damsubset))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(aov_damsubset)\nW = 0.98533, p-value = 0.2448\n\n\n\nleveneTest(fklngth ~ year, damsubset)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value   Pr(&gt;F)   \ngroup   3  4.6237 0.004367 **\n      111                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nElimination of three outliers, in this case, makes things better in terms of the normality assumption, but does not improve the variances. Moreover, the fact that the conclusion drawn from the original ANOVA with outliers retained does not change upon their removal reinforces the fact that there is no good reason to remove the points. Instead of a Kruskall-Wallis rank-based test, a permutation test could be used.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "05-anova.html#permutation-test",
    "href": "05-anova.html#permutation-test",
    "title": "\n5  One-way ANOVA\n",
    "section": "\n5.5 Permutation test",
    "text": "5.5 Permutation test\nThis is an example for a more complex way of doing permutation that we used when lmPerm was not available.\n\n#############################################################\n# Permutation Test for one-way ANOVA\n# modified from code written by David C. Howell\n# http://www.uvm.edu/~dhowell/StatPages/\n# More_Stuff/Permutation%20Anova/PermTestsAnova.html\n# set desired number of permutations\nnreps &lt;- 500\n# to simplify reuse of this code, copy desired dataframe to mydata\nmydata &lt;- dam10dat\n# copy model formula to myformula\nmyformula &lt;- as.formula(\"fklngth ~ year\")\n# copy dependent variable vector to mydep\nmydep &lt;- mydata$fklngth\n# copy independent variable vector to myindep\nmyindep &lt;- as.factor(mydata$year)\n################################################\n# You should not need to modify code chunk below\n################################################\n# Compute observed F value for original sample\nmod1 &lt;- lm(myformula, data = mydata) # Standard Anova\nsum_anova &lt;- summary(aov(mod1)) # Save summary to variable\nobs_f &lt;- sum_anova[[1]]$\"F value\"[1] # Save observed F value\n# Print standard ANOVA results\ncat(\n  \" The standard ANOVA for these data follows \",\n  \"\\n\"\n)\n\nprint(sum_anova, \"\\n\")\ncat(\"\\n\")\ncat(\"\\n\")\nprint(\"Resampling as in Manly with unrestricted sampling of observations. \")\n\n# Now start resampling\nboot_f &lt;- numeric(nreps) # initalize vector to receive permuted\nvalues\nboot_f[1] &lt;- obs_f\nfor (i in 2:nreps) {\n  newdependent &lt;- sample(mydep, length(mydep)) # randomize dep\n  var\n  mod2 &lt;- lm(newdependent ~ myindep) # refit model\n  b &lt;- summary(aov(mod2))\n  boot_f[i] &lt;- b[[1]]$\"F value\"[1] # store F stats\n}\npermprob &lt;- length(boot_f[boot_f &gt;= obs_f]) / nreps\ncat(\n  \" The permutation probability value is: \", permprob,\n  \"\\n\"\n)\n# end of code chunk for permutation\n\nVersion lmPerm du test de permutation.\n\n## lmPerm version of permutation test\nlibrary(lmPerm)\n# for generality, copy desired dataframe to mydata\n# and model formula to myformula\nmydata &lt;- dam10dat\nmyformula &lt;- as.formula(\"fklngth ~ year\")\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(myformula, data = mydata)\n# Calculate permutation p-value\nanova(lmp(myformula, data = mydata, perm = \"Prob\", center = FALSE, Ca = 0.001))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "06-anova_mult.html",
    "href": "06-anova_mult.html",
    "title": "\n6  Multiway ANOVA: factorial and nested designs\n",
    "section": "",
    "text": "6.1 R packages and data needed\nFor this lab you need:\nlibrary(multcomp)\nlibrary(car)\nlibrary(tidyverse)\nlibrary(effects)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiway ANOVA: factorial and nested designs</span>"
    ]
  },
  {
    "objectID": "06-anova_mult.html#set-anomul",
    "href": "06-anova_mult.html#set-anomul",
    "title": "\n6  Multiway ANOVA: factorial and nested designs\n",
    "section": "",
    "text": "R packages:\n\ntidyverse\nmulticomp\ncar\neffects\n\n\ndata files:\n\nStu2wdat.csv\nStu2mdat.csv\nnr2wdat.csv\nnestdat.csv\nwmcdat2.csv\nwmc2dat2.csv",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiway ANOVA: factorial and nested designs</span>"
    ]
  },
  {
    "objectID": "06-anova_mult.html#two-way-factorial-design-with-replication",
    "href": "06-anova_mult.html#two-way-factorial-design-with-replication",
    "title": "\n6  Multiway ANOVA: factorial and nested designs\n",
    "section": "\n6.2 Two-way factorial design with replication",
    "text": "6.2 Two-way factorial design with replication\nMany experiments are designed to investigate the joint effects of several different factors: in a two-way ANOVA, we examine the effect of two factors, but in principle the analysis can be extended to three, four or even five factors, although interpreting the results from 4- and 5-way ANOVAs can be very difficult.\nSuppose that we are interested in the effects of two factors: location (Cumberland House and The Pas) and sex (male or female) on sturgeon size (data can be found in Stu2wdat.csv). Note that because the sample sizes are not the same for each group, this is an unbalanced design. Note also that there are missing data for some of the variables, meaning that not every measurement was made on every fish.\n\n6.2.1 Fixed effects ANOVA (Model I)\n\nBegin by having a look at the data by generating box plots of rdwght for sex and location from the file Stu2wdat.csv .\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nStu2wdat &lt;- read.csv(\"data/Stu2wdat.csv\")\n\nggplot(Stu2wdat, aes(x = sex, y = rdwght)) +\ngeom_boxplot(notch = TRUE) +\nfacet_grid(~location)\n\nWarning: Removed 4 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\nFrom this, it appears as though females might be larger at both locations. It’s difficult to get an idea of whether fish differ in size between the two locations. The presence of outliers on these plots suggests there might be problems meeting normality assumptions for the residuals.\n\nGenerate summary statistics for rdwght by sex and location .\n\n\nStu2wdat &lt;- read.csv(\"data/Stu2wdat.csv\")\naggregate(rdwght ~ sex + location, data = Stu2wdat, FUN = \"summary\")\n\n           sex     location rdwght.Min. rdwght.1st Qu. rdwght.Median\n1 FEMALE       CUMBERLAND      15.10000       20.40000      26.80000\n2 MALE         CUMBERLAND      14.00000       19.22500      20.85000\n3 FEMALE       THE_PAS         12.54000       19.14000      27.39000\n4 MALE         THE_PAS          4.73000       14.63000      20.79000\n  rdwght.Mean rdwght.3rd Qu. rdwght.Max.\n1    27.37347       31.40000    55.60000\n2    22.14118       23.90000    35.60000\n3    27.97717       33.88000    93.72000\n4    20.64652       24.94250    49.94000\n\n\nThe summary statistics confirm our interpretation of the box plots: females appear to be larger than males, and differences in fish size between locations are small.\n\nUsing the file Stu2wdat.csv , do a two-way factorial ANOVA:\n\n\n# Fit anova model and plot residual diagnostics\n# but first, save current par and set graphic page to hold 4 graphs\nopar &lt;- par(mfrow = c(2, 2))\nanova.model1 &lt;- lm(rdwght ~ sex + location + sex:location,\n  contrasts = list(sex = contr.sum, location = contr.sum),\n  data = Stu2wdat\n)\nanova(anova.model1)\n\nAnalysis of Variance Table\n\nResponse: rdwght\n              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nsex            1  1839.6 1839.55 18.6785 2.569e-05 ***\nlocation       1     4.3    4.26  0.0433    0.8355    \nsex:location   1    48.7   48.69  0.4944    0.4829    \nResiduals    178 17530.4   98.49                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nBe careful here. R gives you the sequential sums of squares (Type I) and associated Mean squares and probabilities. These are not to be trusted unless the design is perfectly balanced. In this case, there are varying numbers of observations across sex and location combinations and therefore the design is not balanced.\n\n\n\nWhat you want are the partial sums of squares (type III). The easiest way to get them is to use the Anova() function in the car 📦 package (note the subtle difference, Anova() is not the same as anova(), remember case matters in R.). However, this is not enough by itself. To get the proper values for the type III sums of square, one also needs to specify contrasts, hence the cryptic contrasts = list(sex = contr.sum,location = contr.sum).\n\nlibrary(car)\nAnova(anova.model1, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n             Sum Sq  Df   F value    Pr(&gt;F)    \n(Intercept)  106507   1 1081.4552 &lt; 2.2e-16 ***\nsex            1745   1   17.7220 4.051e-05 ***\nlocation          9   1    0.0891    0.7656    \nsex:location     49   1    0.4944    0.4829    \nResiduals     17530 178                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOn the basis of the ANOVA, there is no reason to reject two null hypotheses: (1) that the effect of sex (if any) does not depend on location (no interaction), and (2) that there is no difference in the size of sturgeon (pooled over sex ) between the two locations . On the other hand, we reject the null hypothesis that there is no difference in size between male and female sturgeon (pooled over location ), precisely as expected from the graphs.\n\npar(mfrow = c(2, 2))\nplot(anova.model1)\n\n\n\nChecking model assumptions for ANOVA model1\n\n\n\nAs usual, we cannot accept the above results without first ensuring that the assumptions of ANOVA are met. Examination of the residuals plots above shows that the residuals are reasonably normally distributed, with the exception of three potential outliers flagged on the QQ plot (cases 101, 24, & 71; the latter two are on top of one another). However, Cook’s distances are not large for these (the 0.5 contour is not even visible on the plot), so there is little indication that these are a concern.The residuals vs fit plot shows that the spread of residuals is about equal over the range of the fitted values, again with the exception of a few cases. When we test for normality of residuals we get:\n\nshapiro.test(residuals(anova.model1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model1)\nW = 0.87213, p-value = 2.619e-11\n\n\nSo, there is evidence of non-normality in the residuals.\nWe will use the Levene’s test to examine the assumption of homogeneity of variances, just as we did with the 1-way anova.\n\nleveneTest(rdwght ~ sex * location, data = Stu2wdat)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value  Pr(&gt;F)  \ngroup   3  3.8526 0.01055 *\n      178                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf the assumption of homogeneity of variances was valid, we would be accepting the null that the mean of the absolute values of residuals does not vary among levels of sex and location (i.e., group ). The above table shows that the hypothesis is rejected and we conclude there is evidence of heteroscedascticity. All in all, there is some evidence that several important assumptions have been violated. However, whether these violations are sufficiently large to invalidate our conclusions remains to be seen.\n\n\n\n\n\n\nExercise\n\n\n\nRepeat this procedure using the data file Stu2mdat.Rdata . Now what do you conclude? Suppose you wanted to compare the sizes of males and females: in what way would these comparisons differ between Stu2wdat.Rdata and Stu2mdat.Rdata ?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nStu2mdat &lt;- read.csv(\"data/Stu2mdat.csv\")\nanova.model2 &lt;- lm(\n  formula = rdwght ~ sex + location + sex:location,\n  contrasts = list(sex = contr.sum, location = contr.sum),\n  data = Stu2mdat\n)\nsummary(anova.model2)\nAnova(anova.model2, type = 3)\n\n\n\n\n\n\n\nCall:\nlm(formula = rdwght ~ sex + location + sex:location, data = Stu2mdat, \n    contrasts = list(sex = contr.sum, location = contr.sum))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.917  -6.017  -0.580   4.445  65.743 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     24.5346     0.7461  32.885  &lt; 2e-16 ***\nsex1            -0.5246     0.7461  -0.703    0.483    \nlocation1        0.2227     0.7461   0.299    0.766    \nsex1:location1   3.1407     0.7461   4.210 4.05e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.924 on 178 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.09744,   Adjusted R-squared:  0.08223 \nF-statistic: 6.405 on 3 and 178 DF,  p-value: 0.0003817\n\n\nNote that in this case, we see that at Cumberland House, females are larger than males, whereas the opposite is true in The Pas (you can confirm this observation by generating summary statistics). What happens with the ANOVA (remember, you want Type III sum of squares)?\n\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n             Sum Sq  Df   F value    Pr(&gt;F)    \n(Intercept)  106507   1 1081.4552 &lt; 2.2e-16 ***\nsex              49   1    0.4944    0.4829    \nlocation          9   1    0.0891    0.7656    \nsex:location   1745   1   17.7220 4.051e-05 ***\nResiduals     17530 178                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn this case, the interaction term sex:location is significant but the main effects are not significant.\n\nYou might find it useful here to generate plots for the two data files to compare the interactions between sex and location. The effect plot shows the relationship between means for each combination of factors (also called cell means). Generate an effect plot for the two models using the allEffects() command from the effects 📦 package:\n\n\nlibrary(effects)\nallEffects(anova.model1)\n\n model: rdwght ~ sex + location + sex:location\n\n sex*location effect\n              location\nsex            CUMBERLAND   THE_PAS     \n  FEMALE           27.37347     27.97717\n  MALE             22.14118     20.64652\n\nplot(allEffects(anova.model1), \"sex:location\")\n\n\n\nEffet du sexe et du lieu sur le poids des esturgeons\n\n\n\n\nallEffects(anova.model2)\n\n model: rdwght ~ sex + location + sex:location\n\n sex*location effect\n              location\nsex            CUMBERLAND   THE_PAS     \n  FEMALE           27.37347     20.64652\n  MALE             22.14118     27.97717\n\nplot(allEffects(anova.model2), \"sex:location\")\n\n\n\nEffet du sexe et du lieu sur le poids des esturgeons\n\n\n\nThere is a very large difference between the results from Stu2wdat and Stu2mdat. In the former case, because there is no significant interaction, we can essentially pool over the levels of factor 1 (sex, say) to test for the effects of location , or over the levels of factor 2 (location) to test for the effects of sex . In fact, if we do so and simply run a one-way ANOVA on the Stu2wdat data with sex as the grouping variable, we get:\n\nAnova(aov(rdwght ~ sex, data = Stu2wdat), type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  78191   1 800.440 &lt; 2.2e-16 ***\nsex           1840   1  18.831 2.377e-05 ***\nResiduals    17583 180                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNote that here the residual sum of squares (17583) is only slightly higher than for the 2-way model (17530), simply because, in the 2-way model, only a small fraction of the explained sums of squares is due to the location main effect or the sex:LOCATION interaction. On the other hand, if you try the same trick with stu2mdat, you get:\n\n\nAnova(aov(rdwght ~ sex, data = Stu2mdat), type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n            Sum Sq  Df  F value Pr(&gt;F)    \n(Intercept)  55251   1 515.0435 &lt;2e-16 ***\nsex            113   1   1.0571 0.3053    \nResiduals    19309 180                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere, the residuals sum of squares (19309) is much larger than in the 2-way model (17530), because most of the explained sums of squares is due to the interaction. Note that if we did this, we would conclude that male and female sturgeons don’t differ in size. But in fact they do: it’s just that the difference is in different directions, depending on location. This is why it is always dangerous to try and make too much of main effects in the presence of interactions!\n\n6.2.2 Mixed effects ANOVA (Model III)\nWe have neglected an important component in the above analyses, and that is related to the type of ANOVA model we wish to run. In this example, Location could be considered a random effect, whereas sex is a fixed effect (because it is “fixed” biologically), and so this model could be treated as a mixed model (Model III) ANOVA. Note that in these analyses, R treats analyses by default as Model I ANOVA, so that the main effects and the interaction are tested over the residuals mean square. Recall, however, that in a Model III ANOVA, main effects are tested over the interaction mean square or the pooled interaction mean square and residual mean square (depending on which statistician you consult!)\n\nWorking with the Stu2wdat data, rebuild the ANOVA table for rdwght for the situation in which location is a random factor and sex is a fixed factor. To do this, you need to recalculate the F-ratio for sex using the sex:location interaction mean square instead of the residual mean square. This is most easily accomplished by hand, making sure you are working with the Type III Sums of squares ANOVA table.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nAnova(anova.model1, type = 3)\n\n\n\n\n\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n             Sum Sq  Df   F value    Pr(&gt;F)    \n(Intercept)  106507   1 1081.4552 &lt; 2.2e-16 ***\nsex            1745   1   17.7220 4.051e-05 ***\nlocation          9   1    0.0891    0.7656    \nsex:location     49   1    0.4944    0.4829    \nResiduals     17530 178                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFor sex, the new ratio of mean squares is\n\\[F = \\frac{(1745/1)}{(49/1)} = 35.6\\]\nTo assign a probability to the new F-value, enter the following in the commands window: pf(F, df1, df2, lower.tail = FALSE) , where F is the newly calculated F-value, and df1 and df2 are the degrees of freedom of the numerator (sex) and denominator (SEX:location), respectively.\n\npf(35.6, 1, 1, lower.tail = FALSE)\n\n[1] 0.1057152\n\n\nNote that the p value for sex is now non-significant. This is because the error MS of the initial ANOVA is smaller than the interaction MS, but mostly because the number of degrees of freedom of the denominator of the F test has dropped from 178 to 1. In general, a drop in the denominator degrees of freedom makes it much more difficult to reach significance.\n\n\n\n\n\n\nMixed model which are a generalisation of mixed-effect ANOVA are now really developped and are to be favoured intead of doing it by hand.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiway ANOVA: factorial and nested designs</span>"
    ]
  },
  {
    "objectID": "06-anova_mult.html#way-factorial-anova-without-replication",
    "href": "06-anova_mult.html#way-factorial-anova-without-replication",
    "title": "\n6  Multiway ANOVA: factorial and nested designs\n",
    "section": "\n6.3 2-way factorial ANOVA without replication",
    "text": "6.3 2-way factorial ANOVA without replication\nIn some experimental designs, there are no replicates within data cells: perhaps it is simply too expensive to obtain more than one datum per cell. A 2-way ANOVA is still possible under these circumstances, but there is an important limitation.\n\n\n\n\n\n\nBecause there is no replication within cells, there is no error variance: we have simply a row sum of squares, a column sum of squares, and a remainder sum of squares. This has important implications: if there is an interaction in a Model III ANOVA, only the fixed effect can be tested (over the remainder MS); for Model I ANOVAs, or for random effects in Model III ANOVAs, it is not appropriate to test main effects over the remainder unless we are sure there is no interaction.\n\n\n\nA limnologist studying Round Lake in Algonquin Park takes a single temperature ( temp ) reading at 10 different depths ( depth , in m) at four times ( date) over the course of the summer. Her data are shown in Nr2wdat.csv.\n\nDo a two-way unreplicated ANOVA using temp as the dependent vari able, date and depth as the factor variables (you will need to recode depth to tell R to treat this variable as a factor). Note that there is no interaction term included in this model.\n\n\nnr2wdat &lt;- read.csv(\"data/nr2wdat.csv\")\nnr2wdat$depth &lt;- as.factor(nr2wdat$depth)\nanova.model4 &lt;- lm(temp ~ date + depth, data = nr2wdat)\nAnova(anova.model4, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: temp\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 1511.99  1 125.5652 1.170e-11 ***\ndate         591.15  3  16.3641 2.935e-06 ***\ndepth       1082.82  9   9.9916 1.450e-06 ***\nResiduals    325.12 27                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAssuming that this is a Model III ANOVA ( date random, depth fixed), what do you conclude? (Hint: you may want to generate an interaction plot of temp versus depth and month, just to see what’s going on.)\n\ninteraction.plot(nr2wdat$depth, nr2wdat$date, nr2wdat$temp)\n\n\n\nEffet du mois et de la profondeur sur la température\n\n\n\nThere is a highly significant decrease in temperature as depth increases. To test the effect of month (the (assumed) random factor), we must assume that there is no interaction between depth and month, i.e. that the change in temperature with depth is the same for each month. This is a dubious assumption: if you plot temperature against depth for each month, you should see that the temperature profile becomes increasingly non-linear as the summer progresses (i.e. the thermocline develops), from almost a linear decline in early spring to what amounts to a step decline in August. In other words, the relationship between temperature and depth does change with month, so that if you were to use the above fitted model to estimate, say, the temperature at a depth of 5 m in July, you would not get a particularly good estimate.\nIn terms of residual diagnostics, have a look at the residuals probability plot and residuals vs fitted values plot.\n\npar(mfrow = c(2, 2))\nplot(anova.model4)\n\n\n\nConditions d’applications du modèle anova.model4\n\n\n\n\nshapiro.test(residuals(anova.model4))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model4)\nW = 0.95968, p-value = 0.1634\n\n\nTesting the residuals for normality, we get p = 0.16, so that the normality assumption seems to be O.K. In terms of heteroscedasticity, we can only test among months, using depths as replicates (or among depths using months as replicates). Using depths as replicates within months, we find\n\nleveneTest(temp ~ date, data = nr2wdat)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value    Pr(&gt;F)    \ngroup  3  17.979 2.679e-07 ***\n      36                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSo there seems to be some problem here, as can be plainly seen in the above plot of residuals vs fit. All in all, this analysis is not very satisfactory: there appears to be some problems with the assumptions, and the assumption of no interaction between depth and date would appear to be invalid.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiway ANOVA: factorial and nested designs</span>"
    ]
  },
  {
    "objectID": "06-anova_mult.html#nested-designs",
    "href": "06-anova_mult.html#nested-designs",
    "title": "\n6  Multiway ANOVA: factorial and nested designs\n",
    "section": "\n6.4 Nested designs",
    "text": "6.4 Nested designs\nA common experimental design occurs when each major group (or treatment) is divided into randomly chosen subgroups. For example, a geneticist interested in the effects of genotype on desiccation resistance in fruit flies might conduct an experiment with larvae of three different genotypes. For each genotype (major group), she sets up three environmental chambers (sub-groups, replicates within groups) with a fixed temperature humidity regime, and in each chamber, she has five larvae for which she records the number of hours each larvae survived.\n\nThe file Nestdat.csv contains the results of just such an experi ment. The file lists three variables: genotype , chamber and survival . Run a nested ANOVA with survival as the dependent variable, genotype/chamber as the independent variables (this is the shorthand notation for a chamber effect nested under genotype).\n\n\nnestdat &lt;- read.csv(\"data/nestdat.csv\")\nnestdat$chamber &lt;- as.factor(nestdat$chamber)\nnestdat$genotype &lt;- as.factor(nestdat$genotype)\nanova.nested &lt;- lm(survival ~ genotype / chamber, data = nestdat)\n\nWhat do you conclude from this analysis? What analysis would (should) you do next? (Hint: if there is a non-significant effect of chambers within genotypes, then you can increase the power of between-genotype comparisons by pooling over chambers within genotypes, although not everyone (Dr. Rundle included) agrees with such pooling.) Do it! Make sure you check your assumptions!\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nanova(anova.nested)\n\nAnalysis of Variance Table\n\nResponse: survival\n                 Df  Sum Sq Mean Sq  F value Pr(&gt;F)    \ngenotype          2 2952.22 1476.11 292.6081 &lt;2e-16 ***\ngenotype:chamber  6   40.65    6.78   1.3432 0.2639    \nResiduals        36  181.61    5.04                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow = c(2, 2))\nplot(anova.nested)\n\n\n\nConditions d’applications du modèle anova.nested\n\n\n\n\n\n\nWe conclude from this analysis that there is no (significant) variation among chambers within genotypes, but that the null hypothesis that all genotypes have the same dessiccation resistance (as measured by survival) is rejected (Test of genotype using MS genotype:chamber as denominator: F = 1476.11/6.78 = 217.7153, P&lt;0.0001). In other words, genotypes differ in their survival.\nSince the chambers within genotypes effect is non-significant, we may want to pool over chambers to increase our degrees of freedom:\n\nanova.simple &lt;- lm(survival ~ genotype, data = nestdat)\nanova(anova.simple)\n\nAnalysis of Variance Table\n\nResponse: survival\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \ngenotype   2 2952.22 1476.11  278.93 &lt; 2.2e-16 ***\nResiduals 42  222.26    5.29                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThus, we conclude that there is significant variation among the three genotypes in dessiccation resistance.\nA box plot of survival across genotypes shows clearly that there is significant variation among the three genotypes in dessiccation resistance. This can be combined with a formal Tukey multiple comparison test:\n\npar(mfrow = c(1, 1))\n# Compute and plot means and Tukey CI\nmeans &lt;- glht(anova.simple, linfct = mcp(\n  genotype =\n    \"Tukey\"\n))\ncimeans &lt;- cld(means)\n# use sufficiently large upper margin\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\n# plot\nplot(cimeans, las = 1) # las option to put y-axis labels as God intended them\n\n\n\nEffet du genotype sur la résistance à la dessication avec un test de Tukey\n\n\n\nSo, we conclude from the Tukey analysis and plot that dessiccation resistance (R) , as measured by larval survival under hot, dry conditions, varies significantly among all three genotypes with R(AA) &gt; R(Aa) &gt; R(aa).\nBefore concluding this, however, we must test the assumptions. Here are the residual plots and diagnostics for the one-way (unnested) design:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(anova.simple)\n\n\n\nConditions d’applications du modèle anova.simple\n\n\n\n\n\n\nSo, all the assumptions appear to be valid, and the conclusion reached above still holds. Note that if you compare the residual mean squares of the nested and one-way ANOVAs (5.04 vs 5.29), they are almost identical. This is not surprising, given the small contribution of the chamber %in% genotype effect to the explained sum of squares.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiway ANOVA: factorial and nested designs</span>"
    ]
  },
  {
    "objectID": "06-anova_mult.html#two-way-non-parametric-anova",
    "href": "06-anova_mult.html#two-way-non-parametric-anova",
    "title": "\n6  Multiway ANOVA: factorial and nested designs\n",
    "section": "\n6.5 Two-way non-parametric ANOVA",
    "text": "6.5 Two-way non-parametric ANOVA\nTwo-way non-parametric ANOVA is an extension of the non-parametric one-way methods discussed previously. The basic procedure is to rank all the data in the sample from smallest to largest, then carry out a 2-way ANOVA on the ranks. This can be done either for replicated or unreplicated data.\nUsing the data file Stu2wdat.csv , do a two-factor ANOVA to examine the effects of sex and location on rank(rdwght).\n\naov.rank &lt;- aov(\n  rank(rdwght) ~ sex * location,\n  contrasts = list(\n    sex = contr.sum, location = contr.sum\n  ),\n  data = Stu2wdat\n)\n\nThe Scheirer-Ray-Hare extension of the Kruskall-Wallis test is done by computing a statistic H given by the effect sums of squares (SS) divided by the total MS. The latter can be calculated as the variance of the ranks. We compute an H statistic for each term. The H-statistics are then compared to a theoretical \\(\\chi^2\\) (chi-square) distribution using the command line: pchisq(H, df, lower.tail = FALSE) , where H and df are the calculated H-statistics and associated degrees of freedom, respectively.\n\nUse the ANOVA table based on ranks to test the effects of sex and on rdwght. What do you conclude? How does this result compare with the result obtained with the parametric 2-way ANOVA done before?\n\n\nAnova(aov.rank, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rank(rdwght)\n              Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept)  1499862   1 577.8673 &lt; 2.2e-16 ***\nsex            58394   1  22.4979 4.237e-06 ***\nlocation        1128   1   0.4347    0.5105    \nsex:location    1230   1   0.4738    0.4921    \nResiduals     472383 182                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTo calculate the Scheirer-Ray-Hare extension to the Kruskall-Wallis test, you must first calculate the total mean square (MS), i.e. the variance of the ranked data. In this case, there are 186 observations, their ranks are therefore the series 1, 2, 3, …, 186. The variance can be calculated simply as var(1:186) (Isn’t R neat? Cryptic maybe, but neat). So we can compute the H statistic for each term:\n\nHsex &lt;- 58394 / var(1:186)\nHlocation &lt;- 1128 / var(1:186)\nHsexloc &lt;- 1230 / var(1:186)\n\nAnd convert these statistics into p-values:\n\n# sex\nHsex\n\n[1] 20.14628\n\npchisq(Hsex, 1, lower.tail = FALSE)\n\n[1] 7.173954e-06\n\n# location\nHlocation\n\n[1] 0.3891668\n\npchisq(Hlocation, 1, lower.tail = FALSE)\n\n[1] 0.5327377\n\n# sex:location\nHsexloc\n\n[1] 0.4243574\n\npchisq(Hsexloc, 1, lower.tail = FALSE)\n\n[1] 0.5147707\n\n\nNote that these results are the same as those obtained in our original two-way parametric ANOVA. Despite the reduced power, we still find significant differences between the sexes, but still no interaction and no effect due to location.\nThere is, however, an important difference. Recall that in the original parametric ANOVA, there was a significant effect of sex when we considered the problem as a Model I ANOVA. However, if we consider it as Model III, the significant sex effect could in principle disappear, because the df associated with the interaction MS are much smaller than the df associated with the Model I error MS. In this case, however, the interaction MS is about half that of the error MS. So, the significant sex effect becomes even more significant if we analyze the problem as a Model III ANOVA. Once again, we see the importance of specifying the appropriate ANOVA design.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiway ANOVA: factorial and nested designs</span>"
    ]
  },
  {
    "objectID": "06-anova_mult.html#multiple-comparisons",
    "href": "06-anova_mult.html#multiple-comparisons",
    "title": "\n6  Multiway ANOVA: factorial and nested designs\n",
    "section": "\n6.6 Multiple comparisons",
    "text": "6.6 Multiple comparisons\nFurther hypothesis testing in multiway ANOVAs depends critically on the outcome of the initial ANOVA. If you are interested in comparing groups of marginal means (that is, means of treatments for one factor pooled over levels of the other factor, e.g., between male and female sturgeon pooled over location), this can be done exactly as outlined for multiple comparisons for one-way ANOVAs. For comparison of individual cell means, you must specify the interaction as the group variable.\nThe file wmcdat2.csv shows measured oxygen consumption ( o2cons ) of two species ( species = A, B)) of limpets at three different concentrations of seawater ( conc = 100, 75, 50%) taken from Sokal and Rohlf, 1995, p. 332.\n\nRun a 2-way factorial ANOVA on wmcdat2 data, using o2cons as the dependent variable and species and conc as the factors. What do you conclude?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwmcdat2 &lt;- read.csv(\"data/wmcdat2.csv\")\nwmcdat2$species &lt;- as.factor(wmcdat2$species)\nwmcdat2$conc &lt;- as.factor(wmcdat2$conc)\nanova.model5 &lt;- lm(o2cons ~ species * conc, data = wmcdat2)\nAnova(anova.model5, type = 3)\n\n\n\n\nThe ANOVA table is shown below. Technically, because the sample sizes in individual cells are rather small, this analysis should be repeated using a non-parametric ANOVA. For the moment, let’s stick with the parametric analysis.\n\n\nAnova Table (Type III tests)\n\nResponse: o2cons\n              Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)  1185.60  1 124.0165 4.101e-14 ***\nspecies         0.09  1   0.0097   0.92189    \nconc           74.90  2   3.9172   0.02755 *  \nspecies:conc   23.93  2   1.2514   0.29656    \nResiduals     401.52 42                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLook at the diagnostic plots:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(anova.model5)\n\n\n\n\n\n\n\n\n\n\nHomoscedasticity looks ok, but normality less so.. Testing for normality, we get:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nshapiro.test(residuals(anova.model5))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model5)\nW = 0.93692, p-value = 0.01238\n\n\n\n\n\nSo there is evidence of non-normality, but otherwise everything looks O.K. Since the ANOVA is relatively robust with respect to non-normality, we proceed, but if we wanted to reassure ourselves, we could run a non-parametric ANOVA, and get the same answer.\n\nOn the basis of the ANOVA results obtained above, which means would you proceed to compare? Why?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNeed to add an explnation here\n\n\n\nOverall, we conclude that there are no differences among species, and that the effect of concentration does not depend on species (no interaction). Since there is no interaction and no main effect due to species, the only comparison of interest is among salinity concentrations:\n\n# fit simplified model\nanova.model6 &lt;- aov(o2cons ~ conc, data = wmcdat2)\n# Make Tukey multiple comparisons\nTukeyHSD(anova.model6)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = o2cons ~ conc, data = wmcdat2)\n\n$conc\n           diff       lwr        upr     p adj\n75-50  -4.63625 -7.321998 -1.9505018 0.0003793\n100-50 -3.25500 -5.940748 -0.5692518 0.0141313\n100-75  1.38125 -1.304498  4.0669982 0.4325855\n\npar(mfrow = c(1, 1))\n# Graph of all comparisons for conc\ntuk &lt;- glht(anova.model6, linfct = mcp(conc = \"Tukey\"))\n# extract information\ntuk.cld &lt;- cld(tuk)\n# use sufficiently large upper margin\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\n# plot\nplot(tuk.cld)\n\n\n\nComparaison de Tukey des moyennes de consommation d’oxygèn en fonction del la concentration\n\n\npar(old.par)\n\nSo there is evidence of a significant difference in oxygen consumption at a reduction in salinity to 50% of regular seawater, but not at a reduction of only 25%.\n\nRepeat the analysis described above using wmc2dat2.csv . How do your results compare with those obtained for wmcdat2.csv ?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwmc2dat2 &lt;- read.csv(\"data/wmc2dat2.csv\")\nwmc2dat2$species &lt;- as.factor(wmc2dat2$species)\nwmc2dat2$conc &lt;- as.factor(wmc2dat2$conc)\nanova.model7 &lt;- lm(o2cons ~ species * conc, data = wmc2dat2)\n\n\n\n\nUsing wmc2dat2.csv,we get:\n\n\nAnova Table (Type III tests)\n\nResponse: o2cons\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)  343.09  1 36.2132 3.745e-07 ***\nspecies      133.52  1 14.0929 0.0005286 ***\nconc          66.76  2  3.5232 0.0385011 *  \nspecies:conc 168.15  2  8.8742 0.0006101 ***\nResiduals    397.91 42                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere there is a large interaction effect, and consequently, there is no point in comparing marginal means. This is made clear by examining an interaction plot:\n\nwith(wmc2dat2, interaction.plot(conc, species, o2cons))\n\n\n\n\n\n\n\n\nWorking still with the wmc2dat2 data set, compare individual cell means (6 in all), with the Bonferonni adjustment. To do this, it is helpful to create a new variable to indicate all the combinations of species and conc:\n\n\nwmc2dat2$species.conc &lt;- as.factor(paste0(wmc2dat2$species, wmc2dat2$conc))\n\nThen we can conduct pairwise bonferroni comparisons:\n\nwith(wmc2dat2, pairwise.t.test(o2cons, species.conc, p.adj = \"bonf\"))\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  o2cons and species.conc \n\n     A100   A50    A75    B100   B50   \nA50  0.1887 -      -      -      -     \nA75  1.0000 1.0000 -      -      -     \nB100 0.7223 1.0000 1.0000 -      -     \nB50  1.0000 0.0079 0.0929 0.0412 -     \nB75  0.6340 1.0000 1.0000 1.0000 0.0350\n\nP value adjustment method: bonferroni \n\n\nThese comparisons are a little more difficult to interpret, but the analysis essentially examines for differences among seawater concentrations within species A and for differences among concentrations within species B. We see here that the o2Cons at 50% seawater for species B is significantly different from that of 75% and 100% seawater for species B, whereas there are no significant differences in o2cons for species A across all seawater concentrations.\nI find these outputs rather unsatisfying because they show only p-values, but no indication of effect size. One can get both the conclusion from the multiple comparison procedure and an indication of effect size from the graph produced with the following code:\n\n# fit one-way anova comparing all combinations of species.conc combinations\nanova.modelx &lt;- aov(o2cons ~ species.conc, data = wmc2dat2)\ntuk2 &lt;- glht(anova.modelx, linfct = mcp(species.conc = \"Tukey\"))\n# extract information\ntuk2.cld &lt;- cld(tuk2)\n# use sufficiently large upper margin\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\n# plot\nplot(tuk2.cld)\n\n\n\n\n\n\npar(old.par)\n\nNote that in this analysis, we have used the error MS = 9.474 from the original model to contrast cell means. Recall, however, that this assumes that in fact we are dealing with a Model I ANOVA, which may or may not be the case ( conc is certainly a fixed factor, but species might be either fixed or random).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiway ANOVA: factorial and nested designs</span>"
    ]
  },
  {
    "objectID": "06-anova_mult.html#test-de-permutation-pour-lanova-à-deux-facteurs-de-classification",
    "href": "06-anova_mult.html#test-de-permutation-pour-lanova-à-deux-facteurs-de-classification",
    "title": "\n6  Multiway ANOVA: factorial and nested designs\n",
    "section": "\n6.7 Test de permutation pour l’ANOVA à deux facteurs de classification",
    "text": "6.7 Test de permutation pour l’ANOVA à deux facteurs de classification\nWhen data do not meet the assumptions of the parametric analysis in two- and multiway ANOVA, as an alternative to the non-parametric ANOVA, it is possible to run permutation tests to calculate p-values. The lmPerm package does this easily.\n\n#######################################################################\n## lmPerm version of permutation test\nlibrary(lmPerm)\n# for generality, copy desired dataframe to mydata\n# and model formula to myformula\nmydata &lt;- Stu2wdat\nmyformula &lt;- as.formula(\"rdwght ~ sex+location+sex:location\")\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(myformula, data = mydata)\n# Calculate permutation p-value\nanova(lmp(myformula, data = mydata, perm = \"Prob\", center = FALSE, Ca = 0.001))\n\nlmPerm was orphaned for a while and the code below, while clunkier, provided an alternative way of doing it. You would have to adapt it for other situations.\n\n###########################################################\n# Permutation test for two way ANOVA\n# Ter Braak creates residuals from cell means and then permutes across\n# all cells\n# This can be accomplished by taking residuals from the full model\n# modified from code written by David C. Howell\n# http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permutation%20Anova/PermTestsAnova.html\nnreps &lt;- 500\ndependent &lt;- Stu2wdat$rdwght\nfactor1 &lt;- as.factor(Stu2wdat$sex)\nfactor2 &lt;- as.factor(Stu2wdat$location)\nmy.dataframe &lt;- data.frame(dependent, factor1, factor2)\nmy.dataframe.noNA &lt;- my.dataframe[complete.cases(my.dataframe), ]\nmod &lt;- lm(dependent ~ factor1 + factor2 + factor1:factor2,\n  data = my.dataframe.noNA\n)\nres &lt;- mod$residuals\nTBint &lt;- numeric(nreps)\nTB1 &lt;- numeric(nreps)\nTB2 &lt;- numeric(nreps)\nANOVA &lt;- summary(aov(mod))\ncat(\n  \" The standard ANOVA for these data follows \",\n  \"\\n\"\n)\nF1 &lt;- ANOVA[[1]]$\"F value\"[1]\nF2 &lt;- ANOVA[[1]]$\"F value\"[2]\nFinteract &lt;- ANOVA[[1]]$\"F value\"[3]\nprint(ANOVA)\ncat(\"\\n\")\ncat(\"\\n\")\nTBint[1] &lt;- Finteract\nfor (i in 2:nreps) {\n  newdat &lt;- sample(res, length(res), replace = FALSE)\n  modb &lt;- summary(aov(newdat ~ factor1 + factor2 +\n    factor1:factor2,\n  data = my.dataframe.noNA\n  ))\n  TBint[i] &lt;- modb[[1]]$\"F value\"[3]\n  TB1[i] &lt;- modb[[1]]$\"F value\"[1]\n  TB2[i] &lt;- modb[[1]]$\"F value\"[2]\n}\nprobInt &lt;- length(TBint[TBint &gt;= Finteract]) / nreps\nprob1 &lt;- length(TB1[TB1 &gt;= F1]) / nreps\nprob2 &lt;- length(TB2[TB1 &gt;= F2]) / nreps\ncat(\"\\n\")\ncat(\"\\n\")\nprint(\"Resampling as in ter Braak with unrestricted sampling\nof cell residuals. \")\ncat(\n  \"The probability for the effect of Interaction is \",\n  probInt, \"\\n\"\n)\ncat(\n  \"The probability for the effect of Factor 1 is \",\n  prob1, \"\\n\"\n)\ncat(\n  \"The probability for the effect of Factor 2 is \",\n  prob2, \"\\n\"\n)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiway ANOVA: factorial and nested designs</span>"
    ]
  },
  {
    "objectID": "06-anova_mult.html#bootstrap-for-two-way-anova",
    "href": "06-anova_mult.html#bootstrap-for-two-way-anova",
    "title": "\n6  Multiway ANOVA: factorial and nested designs\n",
    "section": "\n6.8 Bootstrap for two-way ANOVA",
    "text": "6.8 Bootstrap for two-way ANOVA\nIn most cases, permutation tests will be more appropriate than bootstrap in ANOVA designs. However, for the sake of completedness, I have a snippet of code to do bootstrap for you::\n\n############################################################\n###########\n# Bootstrap for two-way ANOVA\n# You possibly want to edit bootfunction.mod1 to return other values\n# Here it returns the standard coefficients of the fitted model\n# Requires boot library\n#\nnreps &lt;- 5000\ndependent &lt;- Stu2wdat$rdwght\nfactor1 &lt;- as.factor(Stu2wdat$sex)\nfactor2 &lt;- as.factor(Stu2wdat$location)\nmy.dataframe &lt;- data.frame(dependent, factor1, factor2)\nmy.dataframe.noNA &lt;- my.dataframe[complete.cases(my.dataframe), ]\nlibrary(boot)\n# Fit model on observed data\nmod1 &lt;- aov(dependent ~ factor1 + factor2 + factor1:factor2,\n  data = my.dataframe.noNA\n)\n\n\n# Bootstrap 1000 time using the residuals bootstraping methods to\n# keep the same unequal number of observations for each level of the indep. var.\nfit &lt;- fitted(mod1)\ne &lt;- residuals(mod1)\nX &lt;- model.matrix(mod1)\nbootfunction.mod1 &lt;- function(data, indices) {\n  y &lt;- fit + e[indices]\n  bootmod &lt;- lm(y ~ X)\n  coefficients(bootmod)\n}\nbootresults &lt;- boot(my.dataframe.noNA, bootfunction.mod1,\n  R = 1000\n)\nbootresults\n## Calculate 90% CI and plot bootstrap estimates separately for each model parameter\nboot.ci(bootresults, conf = 0.9, index = 1)\nplot(bootresults, index = 1)\nboot.ci(bootresults, conf = 0.9, index = 3)\nplot(bootresults, index = 3)\nboot.ci(bootresults, conf = 0.9, index = 4)\nplot(bootresults, index = 4)\nboot.ci(bootresults, conf = 0.9, index = 5)\nplot(bootresults, index = 5)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiway ANOVA: factorial and nested designs</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html",
    "href": "07-reg_mult.html",
    "title": "\n7  Multiple regression\n",
    "section": "",
    "text": "7.1 R packages and data\nFor this lab you need:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#set-reg-mul",
    "href": "07-reg_mult.html#set-reg-mul",
    "title": "\n7  Multiple regression\n",
    "section": "",
    "text": "R packages:\n\nggplot2\ncar\nlmtest\nsimpleboot\nboot\nMuMIn\n\n\ndata files:\n\nMregdat.csv",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#points-to-keep-in-mind",
    "href": "07-reg_mult.html#points-to-keep-in-mind",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.2 Points to keep in mind",
    "text": "7.2 Points to keep in mind\nMultiple regression models are used in cases where there is one dependent variable and several independent, continuous variables. In many biological systems, the variable of interest may be influenced by several different factors, so that accurate description or prediction requires that several independent variables be included in the regression model. Before beginning, be aware that multiple regression takes time to learn well. Beginners should keep in mind several important points:\n\nAn overall regression model may be statistically significant even if none of the individual regression coefficients in the model are (caused by multicollinearity)\nA multiple regression model may be “nonsignificant” even though some of the individual coefficients are “significant” (caused by overfitting)\nUnless “independent” variables are uncorrelated in the sample, different model selection procedures may yield different results.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#first-look-at-the-data",
    "href": "07-reg_mult.html#first-look-at-the-data",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.3 First look at the data",
    "text": "7.3 First look at the data\nThe file Mregdat.Rdata contains data collected in 30 wetlands in the Ottawa-Cornwall-Kingston area. The data included are\n\nthe richness (number of species) of:\n\nbirds (bird , and its log transform logbird),\nplants (plant, logpl),\nmammals (mammal, logmam),\nherptiles (herptile, logherp)\ntotal species richness of all four groups combined (totsp, logtot)\n\n\nGPS coordinates of the wetland (lat , long)\nits area (logarea)\nthe percentage of the wetland covered by water at all times during the year (swamp)\nthe percentage of forested land within 1 km of the wetland (cpfor2)\nthe density (in m/hectare) of hard-surface roads within 1 km of the wetland (thtden).\n\nWe will focus on herptiles for this exercise, so we better first have a look at how this variable is distributed and correlated to the potential independent variables:\n\nmydata &lt;- read.csv(\"data/Mregdat.csv\")\nscatterplotMatrix(\n  ~ logherp + logarea + cpfor2 + thtden + swamp,\n  regLine = TRUE, smooth = TRUE, diagonal = TRUE,\n  data = mydata\n)\n\n\n\nMatrice de rélation et densité pour la richesse spécifique des amphibiens et reptiles",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#multiple-regression-models-from-scratch",
    "href": "07-reg_mult.html#multiple-regression-models-from-scratch",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.4 Multiple regression models from scratch",
    "text": "7.4 Multiple regression models from scratch\nWe begin the multiple regression exercise by considering a situation with one dependent variable and three (possibly) independent variables. First, we will start from scratch and build a multiple regression model based on what we know from building simple regression models. Next, we will look at automated methods of building multiple regressions models using simultaneous, forward, and backward stepwise procedures.\n\n\n\n\n\n\nExercise\n\n\n\nUsing the subset of the Mregdat.csv data file, regress logherp on logarea.\n\n\nOn the basis of the regression, what do you conclude?\n\nmodel_loga &lt;- lm(logherp ~ logarea, data = mydata)\nsummary(model_loga)\n\n\nCall:\nlm(formula = logherp ~ logarea, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.38082 -0.09265  0.00763  0.10409  0.46977 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.18503    0.15725   1.177 0.249996    \nlogarea      0.24736    0.06536   3.784 0.000818 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1856 on 26 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.3552,    Adjusted R-squared:  0.3304 \nF-statistic: 14.32 on 1 and 26 DF,  p-value: 0.0008185\n\npar(mfrow = c(2, 2))\nplot(model_loga)\n\n\n\nChecking model asusmptions for regression of logherp as a function of logarea\n\n\n\nIt looks like there is a positive relationship between herptile species richness and wetland area: the larger the wetland, the greater the number of species. Note, however, that about 2/3 of the observed variability in species richness among wetlands is not “explained” by wetland area (R2 = 0.355). Residual analysis shows no major problems with normality, heteroscedasticity or independence of residuals.\n\n\n\n\n\n\nExercise\n\n\n\nRerun the above regression, this time replacing logarea with cpfor2 as the independent variable, such that the expression in the formula field reads: logherp ~ cpfor2 . What do you conclude?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel_logcp &lt;- lm(logherp ~ cpfor2, data = mydata)\nsummary(model_logcp)\n\n\nCall:\nlm(formula = logherp ~ cpfor2, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.49095 -0.10266  0.05881  0.16027  0.25159 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.609197   0.104233   5.845 3.68e-06 ***\ncpfor2      0.002706   0.001658   1.632    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2202 on 26 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.09289,   Adjusted R-squared:  0.058 \nF-statistic: 2.662 on 1 and 26 DF,  p-value: 0.1148\n\n\n\n\n\nAccording to this result, we would accept the null hypothesis, and conclude that there is no relationship between herptile density and the proportion of forest on adjacent lands. But what happens when we enter both variables into the regression simultaneously?\n\n\n\n\n\n\nExercise\n\n\n\nRerun the above regression one more time, this time adding both independent variables into the model at once, such that logherp ~ logarea + cpfor2 . What do you conclude?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel_mcp &lt;- lm(logherp ~ logarea + cpfor2, data = mydata)\nsummary(model_mcp)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40438 -0.11512  0.01774  0.08187  0.36179 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.027058   0.166749   0.162 0.872398    \nlogarea     0.247789   0.061603   4.022 0.000468 ***\ncpfor2      0.002724   0.001318   2.067 0.049232 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.175 on 25 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4493,    Adjusted R-squared:  0.4052 \nF-statistic:  10.2 on 2 and 25 DF,  p-value: 0.0005774\n\n\n\n\n\nNow we reject both null hypotheses that the slope of the regression of logherp on logarea is zero and that the slope of the regression of logherp on cpfor2 is zero.\nWhy is cpfor2 a significant predictor of logherp in the combined model when it was not significant in the simple linear model? The answer lies in the fact that it is sometimes necessary to control for one variable in order to detect the effect of another variable. In this case, there is a significant relationship between logherp and logarea that masks the relationship between logherp and cpfor2 . When both variables are entered into the model at once, the effect of logarea is controlled for, making it possible to detect a cpfor2 effect (and vice versa).\n\n\n\n\n\n\nExercise\n\n\n\nRun another multiple regression, this time substituting thtden for cpfor2 as an independent variable (logherp ~ logarea + thtden).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel_mden &lt;- lm(logherp ~ logarea + thtden, data = mydata)\nsummary(model_mden)\n\n\nCall:\nlm(formula = logherp ~ logarea + thtden, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.31583 -0.12326  0.02095  0.13201  0.31674 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.37634    0.14926   2.521 0.018437 *  \nlogarea      0.22504    0.05701   3.947 0.000567 ***\nthtden      -0.04196    0.01345  -3.118 0.004535 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1606 on 25 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5358,    Adjusted R-squared:  0.4986 \nF-statistic: 14.43 on 2 and 25 DF,  p-value: 6.829e-05\n\n\n\n\n\nIn this case we reject the null hypotheses that there are no effects of wetland area ( logarea ) and road density ( thtden ) on herptile richness ( logherp ). Note here that road density has a negative effect on richness, whereas wetland area and forested area ( cpfor2; results from previous regression) both have positive effects on herptile richness.\nThe R2 of this model is even higher than the previous multiple regression model, reflecting a higher correlation between logherp and thtden than between logherp and cpfor2 (if you run a simple regression between logherp and thtden and compare it to the cpfor2 regression you should be able to detect this).\nThus far, it appears that herptile richness is related to wetland area ( logarea ), road density ( thtden ), and possibly forest cover on adjacent lands ( cpfor2 ). But, does it necessarily follow that if we build a regression model with all three independent variables, that all three will show significant relationships? No, because we have not yet examined the relationship between Logarea , cpfor2 and thtden . Suppose, for example, two of the variables (say, cpfor2 and thtden ) are perfectly correlated. Then the thtden effect is nothing more than the cpfor2 effect (and vice versa), so that once we include one or the other in the regression model, none of the remaining variability would be explained by the third variable.\n\n\n\n\n\n\nExercise\n\n\n\nFit a regression model with logherp as the dependent variable and logarea , cpfor2 and thtden as the independent variables. What do you conclude?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel_mtri &lt;- lm(logherp ~ logarea + cpfor2 + thtden, data = mydata)\nsummary(model_mtri)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2 + thtden, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30729 -0.13779  0.02627  0.11441  0.29582 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.284765   0.191420   1.488 0.149867    \nlogarea      0.228490   0.057647   3.964 0.000578 ***\ncpfor2       0.001095   0.001414   0.774 0.446516    \nthtden      -0.035794   0.015726  -2.276 0.032055 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1619 on 24 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5471,    Adjusted R-squared:  0.4904 \nF-statistic: 9.662 on 3 and 24 DF,  p-value: 0.0002291\n\n\n\n\n\nSeveral things to note here:\n\nThe regression coefficient for cpfor2 has become non-significant: once the variability explained by logarea and thtden is removed, a non-significant part of the remaining variability is explained by cpfor2.\nThe R2 for this model (.547 is only marginally larger than the R2 for the model with only logarea and thtden (.536, which is again consistent with the non-significant coefficient for cpfor2.\n\nNote also that although the regression coefficient for thtden has not changed much from that obtained when just thtden and logarea were included in the fitted model (-.036 vs -.042, the standard error for the regression coefficient for thtden has increased slightly, meaning the estimate is less precise. If the correlation between thtden and cpfor2 was greater, the change in precision would also be greater.\nWe can compare the fit of the last two models (i.e., the model with all 3 variables and the model with only logarea and thtden to decide which model is best to include.\n\nanova(model_mtri, model_mden)\n\nAnalysis of Variance Table\n\nModel 1: logherp ~ logarea + cpfor2 + thtden\nModel 2: logherp ~ logarea + thtden\n  Res.Df     RSS Df Sum of Sq     F Pr(&gt;F)\n1     24 0.62937                          \n2     25 0.64508 -1 -0.015708 0.599 0.4465\n\n\nNote that this is the identical result we obtained via the t-test of the effect of cpfor2 in the model with all 3 variables above as they are testing the same thing (this should make sense to you). From this analysis, we would conclude that the full model with all three variables included does not offer a significant improvement in fit over the model with only logarea and thtden. This isn’t surprising given that we already know that we cannot reject the null hypothesis of no effect of cpfor2 in the full model. Overall, we would conclude, on the basis of these analyses, that:\n\nGiven the three variables thtden , logarea and cpfor2 , the best model is one that includes the first two variables.\nThere is evidence of a negative relationship between herptile richness and the density of roads on adjacent lands.\nThere is evidence that the larger the wetland area, the greater the herptile species richness. Note that by “best”, I don’t mean the best possible model, I mean the best one given the three predictor variables we started with. It seems pretty clear that there are other factors controlling richness in wetlands, since even with the “best” model, almost half of the variability in richness is unexplained.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#stepwise-multiple-regression-procedures",
    "href": "07-reg_mult.html#stepwise-multiple-regression-procedures",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.5 Stepwise multiple regression procedures",
    "text": "7.5 Stepwise multiple regression procedures\nThere are a number of techniques available for selecting the multiple regression model that best suits your data. When working with only three independent variables it is often sufficient to work through the different combinations of possible variables yourself, until you are satisfied you have fit the best model. This is, essentially, what we did in the first section of this lab. However, the process can become tedious when dealing with numerous independent variables, and you may find an automatic procedure for fitting models to be easier to work with.\nStepwise regression in R relies on the Akaike Information Criterion, as a measure of goodness of fit\n\\[AIC = 2k + 2ln(L))\\]\nwhere k is the number of regressors, and L is the maximized value of the likelihood function for the model). This is a statistic that rewards prediction precision while penalizing model complexity. If a new model has an AIC lower than that of the current model, the new model is a better fit to the data.\n\n\n\n\n\n\nExercise\n\n\n\nStill working with the Mregdat data, run a stepwise multiple regression on the same set of variables:\n\n\n\n# Stepwise Regression\nstep_mtri &lt;- step(model_mtri, direction = \"both\")\n\nStart:  AIC=-98.27\nlogherp ~ logarea + cpfor2 + thtden\n\n          Df Sum of Sq     RSS     AIC\n- cpfor2   1   0.01571 0.64508 -99.576\n&lt;none&gt;                 0.62937 -98.267\n- thtden   1   0.13585 0.76522 -94.794\n- logarea  1   0.41198 1.04135 -86.167\n\nStep:  AIC=-99.58\nlogherp ~ logarea + thtden\n\n          Df Sum of Sq     RSS     AIC\n&lt;none&gt;                 0.64508 -99.576\n+ cpfor2   1   0.01571 0.62937 -98.267\n- thtden   1   0.25092 0.89600 -92.376\n- logarea  1   0.40204 1.04712 -88.013\n\nstep_mtri$anova # display results\n\n      Step Df   Deviance Resid. Df Resid. Dev       AIC\n1          NA         NA        24  0.6293717 -98.26666\n2 - cpfor2  1 0.01570813        25  0.6450798 -99.57640\n\n\nExamining the output, we find:\n\nR calculated the AIC for the starting model (here the full model with the 3 independent variables.\nThe AIC for models where terms are deleted. Note here that the only way to reduce the AIC is to drop 2.\nThe AIC for models where terms are added or deleted from the model selected in the first step (i.e. logherp ~ logarea + thtden. Note that none of these models are better.\n\nInstead of starting from the full (saturated) model and removing and possibly re-adding terms (i.e. direction = “both”), one can start from the null model and only add terms:\n\n# Forward selection approach\nmodel_null &lt;- lm(logherp ~ 1, data = mydata)\nstep_f &lt;- stepAIC(\n  model_null,\n  scope = ~ . + logarea + cpfor2 + thtden, direction = \"forward\"\n)\n\nStart:  AIC=-82.09\nlogherp ~ 1\n\n          Df Sum of Sq    RSS     AIC\n+ logarea  1   0.49352 0.8960 -92.376\n+ thtden   1   0.34241 1.0471 -88.013\n+ cpfor2   1   0.12907 1.2605 -82.820\n&lt;none&gt;                 1.3895 -82.091\n\nStep:  AIC=-92.38\nlogherp ~ logarea\n\n         Df Sum of Sq     RSS     AIC\n+ thtden  1   0.25093 0.64508 -99.576\n+ cpfor2  1   0.13078 0.76522 -94.794\n&lt;none&gt;                0.89600 -92.376\n\nStep:  AIC=-99.58\nlogherp ~ logarea + thtden\n\n         Df Sum of Sq     RSS     AIC\n&lt;none&gt;                0.64508 -99.576\n+ cpfor2  1  0.015708 0.62937 -98.267\n\nstep_f$anova # display results\n\nStepwise Model Path \nAnalysis of Deviance Table\n\nInitial Model:\nlogherp ~ 1\n\nFinal Model:\nlogherp ~ logarea + thtden\n\n       Step Df  Deviance Resid. Df Resid. Dev       AIC\n1                               27  1.3895281 -82.09073\n2 + logarea  1 0.4935233        26  0.8960048 -92.37639\n3  + thtden  1 0.2509250        25  0.6450798 -99.57640\n\n\nYou should first notice that the final result is the same as the default stepwise regression and as what we got building the model from scratch. In forward selection, R first fits the least complex model (i.e, with only an intercept), and then adds variables, one by one, according to AIC statistics. Thus, in the above example, the model was first fit with only an intercept. Next, logarea was added, followed by thtden. cpfor2 was not added because it would make AIC increase to above that of the model fit with the first two variables. Generally speaking, when doing multiple regressions, it is good practice to try several different methods (e.g. all regressions, stepwise, and backward elimination, etc.) and see whether you get the same results. If you don’t, then the “best” model may not be so obvious, and you will have to think very carefully about the inferences you draw. In this case, regardless of whether we use automatic, or forward/backward stepwise regression, we arrive at the same model.\nWhen doing multiple regression, always bear in mind the following:\n\nDifferent procedures may produce different “best” models, i.e. the “best” model obtained using forward stepwise regression needn’t necessarily be the same as that obtained using backward stepwise. It is good practice to try several different methods and see whether you end up with the same result. If you don’t, it is almost invariably due to multicollinearity among the independent variables.\n\nBe wary of stepwise regression. As the authors of SYSTAT, another commonly used statistical package, note:\n\nStepwise regression is probably the most abused computerized statistical technique ever devised. If you think you need automated stepwise regression to solve a particular problem, you probably don’t. Professional statisticians rarely use automated stepwise regression because it does not necessarily find the “best” fitting model, the “real” model, or alternative “plausible” models. Furthermore, the order in which variables enter or leave a stepwise program is usually of no theoretical significance. You are always better off thinking about why a model could generate your data and then testing that model.\n\n\nRemember that just because there is a significant regression of Y on X doesn’t mean that X causes Y: correlation does not imply causation!",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#detecting-multicollinearity",
    "href": "07-reg_mult.html#detecting-multicollinearity",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.6 Detecting multicollinearity",
    "text": "7.6 Detecting multicollinearity\nMulticollinearity is the presence of correlations among independent variables. In extreme cases (perfect collinearity) it will prevent you from fitting some models.\n\n\n\n\n\n\nWhen collinearity is not perfect, it reduces your ability to test for the effect of individual variables, but does not affect the ability of the model to predict.\n\n\n\nThe help file for the HH 📦package contains this clear passage about one of the indices of multicollinearity, the variance inflation factors:\n\nA simple diagnostic of collinearity is the variance inflation factor, VIF one for each regression coefficient (other than the intercept). Since the condition of collinearity involves the predictors but not the response, this measure is a function of the X’s but not of Y. The VIF for predictor i is \\[1/(1-R_i^2)\\] where Ri2 is the R2 from a regression of predictor i against the remaining predictors. If Ri2 is close to 1, this means that predictor i is well explained by a linear function of the remaining predictors, and, therefore, the presence of predictor i in the model is redundant. Values of VIF exceeding 5 are considered evidence of collinearity: The information carried by a predictor having such a VIF is contained in a subset of the remaining predictors. If, however, all of a model’s regression coefficients differ significantly from 0 (p-value &lt; .05), a somewhat larger VIF may be tolerable.\n\nVIFs indicate by how much the variance of each regression coefficient is increased by the presence of collinearity.\n\n\n\n\n\n\nThere are several vif() functions (I know of at least three in the packages car, HH and DAAG) and I do not know if and how they differ.\n\n\n\nTo quantify multicollinarity, one can simply call the vif() function from the package car:\n\nlibrary(car)\nvif(model_mtri)\n\n logarea   cpfor2   thtden \n1.022127 1.344455 1.365970 \n\n\nHere there is no evidence that multicollinearity is a problem since all vif are close to 1.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#polynomial-regression",
    "href": "07-reg_mult.html#polynomial-regression",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.7 Polynomial regression",
    "text": "7.7 Polynomial regression\nIn the regression models considered so far, we have assumed that the relationship between the dependent and independent variables is linear. If not, in some cases it can be made linear by transforming one or both variables. On the other hand, for many biological relationships no transformation in the world will help, and we are forced to go with some sort of non-linear regression method.\nThe simplest type of nonlinear regression method is polynomial regression, in which you fit regression models that include independent variables raised to some power greater than one, e.g. X2, X3, etc.\n\n\n\n\n\n\nExercise\n\n\n\nPlot the relationship between the residuals of the logherp ~ logarea regression and swamp.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# problème avec les données de manquantes dans logherp\nmysub &lt;- subset(mydata, !is.na(logherp))\n# ajouter les résidus dans les donnée\nmysub$resloga &lt;- residuals(model_loga)\nggplot(data = mysub, aes(y = resloga, x = swamp)) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\nRelation entre swamp et les résidus de la régression entre logherp et logarea\n\n\n\n\n\n\nVisual inspection of this graph suggests that there is a strong, but highly nonlinear, relationship between these two variables.\n\n\n\n\n\n\nExercise\n\n\n\nTry regressing the residuals of the logherp ~ logarea regression on swamp. What do you conclude?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel_resloga &lt;- lm(resloga ~ swamp, mysub)\nsummary(model_resloga)\n\n\nCall:\nlm(formula = resloga ~ swamp, data = mysub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.35088 -0.13819  0.00313  0.10849  0.45802 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  0.084571   0.109265   0.774    0.446\nswamp       -0.001145   0.001403  -0.816    0.422\n\nResidual standard error: 0.1833 on 26 degrees of freedom\nMultiple R-squared:  0.02498,   Adjusted R-squared:  -0.01252 \nF-statistic: 0.666 on 1 and 26 DF,  p-value: 0.4219\n\n\n\n\n\nIn other words, the fit is terrible, even though you can see from the graph that there is in fact quite a strong relationship between the two - it’s just that it is a non-linear relationship. (If you look at model assumptions for this model, you will see strong evidence of nonlinearity, as expected) The pattern might be well described by a quadratic relation.\n\n\n\n\n\n\nExercise\n\n\n\nRerun the above regression but add a second term in the Formula field to represent swamp2 . If you simply add swamp2 in the model R won’t fit a quadratic effect, you need to use the functionI() which indicates that the formula within should be evaluated before fitting the model.\nThe expression should appear as:\n\\[ residuals ~ swamp + I(swamp^2)\\].\nWhat do you conclude? What does examination of the residuals from this multiple regression tell you?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel_resloga2 &lt;- lm(resloga ~ swamp + I(swamp^2), mysub)\nsummary(model_resloga2)\n\n\nCall:\nlm(formula = resloga ~ swamp + I(swamp^2), data = mysub)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.181185 -0.085350  0.007377  0.067327  0.242455 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -7.804e-01  1.569e-01  -4.975 3.97e-05 ***\nswamp        3.398e-02  5.767e-03   5.892 3.79e-06 ***\nI(swamp^2)  -2.852e-04  4.624e-05  -6.166 1.90e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1177 on 25 degrees of freedom\nMultiple R-squared:  0.6132,    Adjusted R-squared:  0.5823 \nF-statistic: 19.82 on 2 and 25 DF,  p-value: 6.972e-06\n\npar(mfrow = c(2, 2))\nplot(model_resloga2)\n\n\n\n\n\n\n\n\n\n\nIt is clear that once the effects of area are controlled for, a considerable amount of the remaining variability in herptile richness is explained by swamp , in a nonlinear fashion. If you examine model assumptions, you will see that compared to the linear model, the fit is much better.\nBased on the results from the above analyses, how would you modify the regression model arrived at above? What, in your view, is the “best” overall model? Why? How would you rank the various factors in terms of their effects on herptile species richness?\nIn light of these results, we might want to try and fit a model which includes logarea, thtden, cpfor2, swamp and swamp^2^ :\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel_poly1 &lt;- lm(\n  logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2),\n  data = mydata\n)\nsummary(model_poly1)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2), \n    data = mydata)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.201797 -0.056170 -0.002072  0.051814  0.205626 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -3.203e-01  1.813e-01  -1.766   0.0912 .  \nlogarea      2.202e-01  3.893e-02   5.656 1.09e-05 ***\ncpfor2      -7.864e-04  9.955e-04  -0.790   0.4380    \nthtden      -2.929e-02  1.048e-02  -2.795   0.0106 *  \nswamp        3.113e-02  5.898e-03   5.277 2.70e-05 ***\nI(swamp^2)  -2.618e-04  4.727e-05  -5.538 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1072 on 22 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.8181,    Adjusted R-squared:  0.7767 \nF-statistic: 19.78 on 5 and 22 DF,  p-value: 1.774e-07\n\n\n\n\n\nNote that on the basis of this analysis, we could potentially drop cpfor2 and refit using the remaining variables:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel_poly2 &lt;- lm(\n  logherp ~ logarea + thtden + swamp + I(swamp^2),\n  data = mydata\n)\nsummary(model_poly2)\n\n\nCall:\nlm(formula = logherp ~ logarea + thtden + swamp + I(swamp^2), \n    data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.19621 -0.05444 -0.01202  0.07116  0.21295 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -3.461e-01  1.769e-01  -1.957   0.0626 .  \nlogarea      2.232e-01  3.842e-02   5.810 6.40e-06 ***\nthtden      -2.570e-02  9.364e-03  -2.744   0.0116 *  \nswamp        2.956e-02  5.510e-03   5.365 1.89e-05 ***\nI(swamp^2)  -2.491e-04  4.409e-05  -5.649 9.46e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1063 on 23 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.8129,    Adjusted R-squared:  0.7804 \nF-statistic: 24.98 on 4 and 23 DF,  p-value: 4.405e-08\n\n\n\n\n\nHow about multicollinearity in this model?\n\nvif(model_poly2)\n\n   logarea     thtden      swamp I(swamp^2) \n  1.053193   1.123491  45.845845  45.656453 \n\n\nVIF for the two swamp terms are much higher than the standard threshold of 5. However, this is expected for polynomial terms, and not really a concern given that both terms are highly significant in the model. The high VIF means that these two coefficients are not estimated precisely, but using both in the model still allows to make a good prediction (i.e. account for the response to swamp).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#checking-assumptions-of-a-multiple-regression-model",
    "href": "07-reg_mult.html#checking-assumptions-of-a-multiple-regression-model",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.8 Checking assumptions of a multiple regression model",
    "text": "7.8 Checking assumptions of a multiple regression model\nAll the model selection techniques or the manual model crafting assumes that the standard assumptions (independence, normality, homoscedasticity, linearity) are met. Given that a large number of models can be fitted, it may seem that testing the assumptions at each step would be an herculean task. However, it is generally sufficient to examine the residuals of the full (saturated) model and of the final model. Terms not contributing significantly to the fit do not affect residuals much, and therefore, the residuals to the full model, or the residuals to the final model, are generally sufficient.\nLet’s have a look at the diagnostic plots for the final model. Here we use the check_model() function from the performance 📦.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(performance)\ncheck_model(model_poly2)\n\n\n\nConditions d’application du modèle model_poly2\n\n\n\n\n\n\nAlternatively it can be done with the classic method\n\n\n\n\n\n\nCode\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(model_poly2)\n\n\n\nConditions d’application du modèle model_poly2\n\n\n\n\n\n\nEverything looks about right here. For the skeptic, let’s run the formal tests.\n\nshapiro.test(residuals(model_poly2))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(model_poly2)\nW = 0.9837, p-value = 0.9278\n\n\nThe residuals do not deviate from normality. Good.\n\nlibrary(lmtest)\nbptest(model_poly2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model_poly2\nBP = 3.8415, df = 4, p-value = 0.4279\n\n\nNo deviation from homoscedasticity either. Good.\n\ndwtest(model_poly2)\n\n\n    Durbin-Watson test\n\ndata:  model_poly2\nDW = 1.725, p-value = 0.2095\nalternative hypothesis: true autocorrelation is greater than 0\n\n\nNo serial correlation in the residuals, so no evidence of non-independence.\n\nresettest(model_poly2, type = \"regressor\", data = mydata)\n\n\n    RESET test\n\ndata:  model_poly2\nRESET = 0.9823, df1 = 8, df2 = 15, p-value = 0.4859\n\n\nAnd no significant deviation from linearity. So it seems that all is fine.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#visualizing-effect-size",
    "href": "07-reg_mult.html#visualizing-effect-size",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.9 Visualizing effect size",
    "text": "7.9 Visualizing effect size\nHow about effect size? How is that measured or viewed? The regression coefficients can be used to measure effect size, although it may be better to standardize them so that they become independent of measurement units. But a graph is often useful as well. In this context, some of the most useful graphs are called partial residual plots (or component + residual plots). These plots show how the dependent variable, corrected for other variables in the model, varies with each individual variable. Let’s have a look:\n\n# Evaluate visually linearity and effect size\n# component + residual plot\ncrPlots(model_poly2)\n\n\n\nGraphiques de résidus partiels du modèle model_poly2\n\n\n\nNote that the vertical scale varies among plots. For thtden, the dependent variable (log10(herptile richness)) varies by about 0.4 units over the range of thtden in the sample. For logarea, the variation is about 0.6 log units. For swamp, it is a bit tricky since there are two terms and they have opposite effect (leading to a peaked relationship), so the plots are less informative. However, there is no deviation from linearity to be seen.\nTo illustrate what these graphs would look like if there was deviation from linearity, let’s drop swamp2 term and produce the graphs and run the RESET test\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel_nopoly &lt;- lm(\n  logherp ~ logarea + thtden + swamp,\n  data = mydata\n)\ncrPlots(model_nopoly)\n\n\n\nGraphiques de résidus partiels du modèle model_nopoly\n\n\n\n\n\n\nThe lack of linearity along the gradient of swamp becomes obvious. The RESET test also detects a violation from linearity:\n\nresettest(model_nopoly, type = \"regressor\")\n\n\n    RESET test\n\ndata:  model_nopoly\nRESET = 6.7588, df1 = 6, df2 = 18, p-value = 0.0007066",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#testing-for-interactions",
    "href": "07-reg_mult.html#testing-for-interactions",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.10 Testing for interactions",
    "text": "7.10 Testing for interactions\nWhen there are multiple independent variables one should always be ready to assess interactions. In most multiple regression contexts this is somewhat difficult because adding interaction terms increases overall multicollinearity and because in many cases there are not enough observations to test all interactions, or the observations are not well balanced to make powerful tests for interactions. Going back to our final model, see what happens if one tries to fit the fully saturated model with all interactions:\n\nfullmodel_withinteractions &lt;- lm(\n  logherp ~ logarea * cpfor2 * thtden * swamp * I(swamp^2),\n  data = mydata\n)\nsummary(fullmodel_withinteractions)\n\n\nCall:\nlm(formula = logherp ~ logarea * cpfor2 * thtden * swamp * I(swamp^2), \n    data = mydata)\n\nResiduals:\nALL 28 residuals are 0: no residual degrees of freedom!\n\nCoefficients: (4 not defined because of singularities)\n                                         Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                            -5.948e+03        NaN     NaN      NaN\nlogarea                                 3.293e+03        NaN     NaN      NaN\ncpfor2                                  7.080e+01        NaN     NaN      NaN\nthtden                                  9.223e+02        NaN     NaN      NaN\nswamp                                   1.176e+02        NaN     NaN      NaN\nI(swamp^2)                             -3.517e-01        NaN     NaN      NaN\nlogarea:cpfor2                         -3.771e+01        NaN     NaN      NaN\nlogarea:thtden                         -4.781e+02        NaN     NaN      NaN\ncpfor2:thtden                          -1.115e+01        NaN     NaN      NaN\nlogarea:swamp                          -7.876e+01        NaN     NaN      NaN\ncpfor2:swamp                           -1.401e+00        NaN     NaN      NaN\nthtden:swamp                           -1.920e+01        NaN     NaN      NaN\nlogarea:I(swamp^2)                      5.105e-01        NaN     NaN      NaN\ncpfor2:I(swamp^2)                       3.825e-03        NaN     NaN      NaN\nthtden:I(swamp^2)                       7.826e-02        NaN     NaN      NaN\nswamp:I(swamp^2)                       -2.455e-03        NaN     NaN      NaN\nlogarea:cpfor2:thtden                   5.359e+00        NaN     NaN      NaN\nlogarea:cpfor2:swamp                    8.743e-01        NaN     NaN      NaN\nlogarea:thtden:swamp                    1.080e+01        NaN     NaN      NaN\ncpfor2:thtden:swamp                     2.620e-01        NaN     NaN      NaN\nlogarea:cpfor2:I(swamp^2)              -5.065e-03        NaN     NaN      NaN\nlogarea:thtden:I(swamp^2)              -6.125e-02        NaN     NaN      NaN\ncpfor2:thtden:I(swamp^2)               -1.551e-03        NaN     NaN      NaN\nlogarea:swamp:I(swamp^2)               -4.640e-04        NaN     NaN      NaN\ncpfor2:swamp:I(swamp^2)                 3.352e-05        NaN     NaN      NaN\nthtden:swamp:I(swamp^2)                 2.439e-04        NaN     NaN      NaN\nlogarea:cpfor2:thtden:swamp            -1.235e-01        NaN     NaN      NaN\nlogarea:cpfor2:thtden:I(swamp^2)        7.166e-04        NaN     NaN      NaN\nlogarea:cpfor2:swamp:I(swamp^2)                NA         NA      NA       NA\nlogarea:thtden:swamp:I(swamp^2)                NA         NA      NA       NA\ncpfor2:thtden:swamp:I(swamp^2)                 NA         NA      NA       NA\nlogarea:cpfor2:thtden:swamp:I(swamp^2)         NA         NA      NA       NA\n\nResidual standard error: NaN on 0 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 27 and 0 DF,  p-value: NA\n\n\nIndeed, it is not possible to include all 32 terms with only 28 observations. There are not enough data points, R square is one, and the model perfectly overfits the data.\nIf you try to use an automated routine to “pick” the best model out of this soup, R complains:\n\nstep(fullmodel_withinteractions)\n\nError in step(fullmodel_withinteractions): AIC is -infinity for this model, so 'step' cannot proceed\n\n\nDoes this mean you can forget about potential interactions and simply accept the final model without a thought? No. You simply do not have enough data to test for all interactions. But there is a compromise worth attempting, comparing the final model to a model with a subset of the interactions, say all second order interactions, to check whether the inclusion of these interactions improves substantially the fit:\n\nfull_model_2ndinteractions &lt;- lm(\n  logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2)\n    + logarea:cpfor2\n    + logarea:thtden\n    + logarea:swamp\n    + cpfor2:thtden\n    + cpfor2:swamp\n    + thtden:swamp,\n  data = mydata\n)\nsummary(full_model_2ndinteractions)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + \n    logarea:cpfor2 + logarea:thtden + logarea:swamp + cpfor2:thtden + \n    cpfor2:swamp + thtden:swamp, data = mydata)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.216880 -0.036534  0.003506  0.042990  0.175490 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     4.339e-01  6.325e-01   0.686 0.502581    \nlogarea        -1.254e-01  2.684e-01  -0.467 0.646654    \ncpfor2         -9.344e-03  7.205e-03  -1.297 0.213032    \nthtden         -1.833e-01  9.035e-02  -2.028 0.059504 .  \nswamp           3.569e-02  7.861e-03   4.540 0.000334 ***\nI(swamp^2)     -3.090e-04  7.109e-05  -4.347 0.000500 ***\nlogarea:cpfor2  2.582e-03  2.577e-03   1.002 0.331132    \nlogarea:thtden  7.017e-02  3.359e-02   2.089 0.053036 .  \nlogarea:swamp  -5.290e-04  2.249e-03  -0.235 0.816981    \ncpfor2:thtden  -2.095e-04  6.120e-04  -0.342 0.736544    \ncpfor2:swamp    4.651e-05  5.431e-05   0.856 0.404390    \nthtden:swamp    2.248e-04  4.764e-04   0.472 0.643336    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.108 on 16 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.8658,    Adjusted R-squared:  0.7735 \nF-statistic: 9.382 on 11 and 16 DF,  p-value: 4.829e-05\n\n\nThis model fits the data slightly better than the “final” model (it explains 86.6% of the variance in logherp, compared to 81.2% for the “final” model without interactions), but has twice as many parameters.\nIf you look at the individual coefficients, some weird things happen: for example, the sign for logarea has changed. This is one of the symptoms of multicollinearity. Let’s look at the variance inflation factors:\n\nvif(full_model_2ndinteractions)\n\nthere are higher-order terms (interactions) in this model\nconsider setting type = 'predictor'; see ?vif\n\n\n       logarea         cpfor2         thtden          swamp     I(swamp^2) \n      49.86060       78.49622      101.42437       90.47389      115.08457 \nlogarea:cpfor2 logarea:thtden  logarea:swamp  cpfor2:thtden   cpfor2:swamp \n      66.97792       71.69894       67.27034       14.66814       29.41422 \n  thtden:swamp \n      20.04410 \n\n\nOuch. All VIF are above 5, not only the ones involving the swamp terms. This model is not very satisfying it seems. Indeed the AIC for the two models indicate that the model with interactions has less information than the full model (remember, models with the lowest AIC value are to be preferred):\n\nAIC(model_poly1)\n\n[1] -38.3433\n\nAIC(full_model_2ndinteractions)\n\n[1] -34.86123\n\n\nThe anova() command can be used to test whether the addition of all interaction terms improves the fit significantly:\n\nanova(model_poly1, full_model_2ndinteractions)\n\nAnalysis of Variance Table\n\nModel 1: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2)\nModel 2: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + logarea:cpfor2 + \n    logarea:thtden + logarea:swamp + cpfor2:thtden + cpfor2:swamp + \n    thtden:swamp\n  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)\n1     22 0.25282                           \n2     16 0.18651  6  0.066314 0.9481  0.489\n\n\nThis test indicates that the addition of interaction terms did not reduce significantly the residual variance around the full model. How about a comparison with the final model without cpfor2?\n\nanova(model_poly2, full_model_2ndinteractions)\n\nAnalysis of Variance Table\n\nModel 1: logherp ~ logarea + thtden + swamp + I(swamp^2)\nModel 2: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + logarea:cpfor2 + \n    logarea:thtden + logarea:swamp + cpfor2:thtden + cpfor2:swamp + \n    thtden:swamp\n  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)\n1     23 0.25999                           \n2     16 0.18651  7  0.073486 0.9006 0.5294\n\n\nAnd this comparison suggests that our final model does not make worse predictions than the full model with interactions.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#dredging-and-the-information-theoretical-approach",
    "href": "07-reg_mult.html#dredging-and-the-information-theoretical-approach",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.11 Dredging and the information theoretical approach",
    "text": "7.11 Dredging and the information theoretical approach\nOne of the main critiques of stepwise methods is that the p-values are not strictly correct because of the large number of tests that are actually done. This is the multiple testing problem. In building linear models (multiple regression for example) from a large number of independent variables, and possibly their interactions, there are so many possible combinations that if one were to use Bonferroni type corrections, it would make tests very conservative.\nAn alternative, very elegantly advocated by Burnham and Anderson (2002, Model selection and multimodel inference: a practical information-theoretic approach. 2nd ed), is to use AIC (or better the AICc that is more appropriate for samples where the number of observations is less that about 40 times the number of variables) to rank potential models, and identify the set of models that are the best ones. One can then average the parameters across models, weighting using the probability that it is the best model to obtain coefficients that are more robust and less likely to be unduly affected by multicollinearity.\n\n\n\n\n\n\nTo compare models using AIC, models need to be fitted using the exact same data for each model. You thus need to be careful that there are no missing data when using an AIC based approach to model selection\n\n\n\nThe approach of comparing model fit using AIC was first developed to compare a set of model carefully build and chosen by the person doing the analysis based on a-priori knowledge and biological hypotheses. Some, however, developped an approach that I consider brainless and brutal to fit all potential models and then compare them using AIC. This approach has been implemented in the package MuMIn.\n\n\n\n\n\n\nI do not support the use of stepwise AIC or data dredging which are going against the philosophy of AIC and parsimony. Develop a model based on biological hypothesis and report all the results significant or not without dredging the data.\n\n\n\n\n# redo the model double chekcing there are no \"NA\"\n# specifying na.action\n\nfull_model_2ndinteractions &lt;- update(\n  full_model_2ndinteractions,\n  . ~ .,\n  data = mysub,\n  na.action = \"na.fail\"\n)\n\nlibrary(MuMIn)\ndd &lt;- dredge(full_model_2ndinteractions)\n\nFixed term is \"(Intercept)\"\n\n\nObject dd will contain all possible models using the terms of our full model with 2nd order interactions. Then, we can have a look at the subset of models that have an AICc within 4 units from the lowest AICc model. (Burnham and Anderson suggest that models that deviate by more than 2 AICc units have very little empirical support):\n\n# get models within 4 units of AICc from the best model\ntop_models_1 &lt;- get.models(dd, subset = delta &lt; 4)\navgmodel1 &lt;- model.avg(top_models_1) # compute average parameters\nsummary(avgmodel1) # display averaged model\n\n\nCall:\nmodel.avg(object = top_models_1)\n\nComponent model call: \nlm(formula = logherp ~ &lt;8 unique rhs&gt;, data = mysub, na.action = \n     na.fail)\n\nComponent models: \n       df logLik   AICc delta weight\n23457   7  27.78 -35.95  0.00   0.34\n2345    6  25.78 -35.56  0.39   0.28\n123457  8  28.30 -33.02  2.93   0.08\n234578  8  28.26 -32.95  3.00   0.08\n12345   7  26.17 -32.74  3.21   0.07\n23458   7  26.06 -32.51  3.44   0.06\n234567  8  27.88 -32.17  3.78   0.05\n23456   7  25.79 -31.99  3.97   0.05\n\nTerm codes: \n        cpfor2     I(swamp^2)        logarea          swamp         thtden \n             1              2              3              4              5 \n logarea:swamp logarea:thtden   swamp:thtden \n             6              7              8 \n\nModel-averaged coefficients:  \n(full average) \n                 Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    \n(Intercept)    -2.075e-01  2.484e-01   2.593e-01   0.800    0.424    \nlogarea         1.314e-01  1.185e-01   1.222e-01   1.076    0.282    \nswamp           3.193e-02  6.125e-03   6.438e-03   4.960    7e-07 ***\nI(swamp^2)     -2.676e-04  4.904e-05   5.154e-05   5.193    2e-07 ***\nthtden         -6.843e-02  5.324e-02   5.459e-02   1.254    0.210    \nlogarea:thtden  2.139e-02  2.506e-02   2.565e-02   0.834    0.404    \ncpfor2         -1.202e-04  4.710e-04   4.886e-04   0.246    0.806    \nswamp:thtden   -3.277e-05  1.419e-04   1.475e-04   0.222    0.824    \nlogarea:swamp   4.378e-05  5.378e-04   5.676e-04   0.077    0.939    \n \n(conditional average) \n                 Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    \n(Intercept)    -2.075e-01  2.484e-01   2.593e-01   0.800   0.4236    \nlogarea         1.314e-01  1.185e-01   1.222e-01   1.076   0.2820    \nswamp           3.193e-02  6.125e-03   6.438e-03   4.960    7e-07 ***\nI(swamp^2)     -2.676e-04  4.904e-05   5.154e-05   5.193    2e-07 ***\nthtden         -6.843e-02  5.324e-02   5.459e-02   1.254   0.2100    \nlogarea:thtden  3.924e-02  2.125e-02   2.251e-02   1.743   0.0813 .  \ncpfor2         -8.187e-04  9.692e-04   1.027e-03   0.797   0.4253    \nswamp:thtden   -2.402e-04  3.127e-04   3.313e-04   0.725   0.4684    \nlogarea:swamp   4.462e-04  1.664e-03   1.762e-03   0.253   0.8001    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nconfint(avgmodel1) # display CI for averaged coefficients\n\n                       2.5 %        97.5 %\n(Intercept)    -0.7157333646  0.3007147516\nlogarea        -0.1080048582  0.3708612563\nswamp           0.0193158426  0.0445532538\nI(swamp^2)     -0.0003686653 -0.0001666418\nthtden         -0.1754184849  0.0385545120\nlogarea:thtden -0.0048800385  0.0833595106\ncpfor2         -0.0028313465  0.0011940283\nswamp:thtden   -0.0008894138  0.0004090457\nlogarea:swamp  -0.0030067733  0.0038991294\n\n\n\n\ncomponents models: You first get the list of the models with an AICc within the desired 4 units of the best model. The variables that are included in the model are coded with the key just below.\nFor each model, in addition to the AICc, the Akaike weights are calculated. They represent the relative likelihood of a model, and indicate the relative importance of a model compared to the other models tested.\n\nMode-averaged coefficients: For the subset of models, weighted averages (using Akaike weights) for model parameters are calculated, with 95% CI. Note that, by default, terms missing from a model are assumed to have a coefficient of 0.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#bootstrapping-multiple-regression",
    "href": "07-reg_mult.html#bootstrapping-multiple-regression",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.12 Bootstrapping multiple regression",
    "text": "7.12 Bootstrapping multiple regression\nWhen data do not meet the assumptions of normality and homoscedasticity and it is not possible to transform the data to meet the assumptions, bootstraping can be used to compute confidence intervals for coefficients. If the distribution of the bootstrapped coefficients is symmetrical and approximately Gaussian, then empirical percentiles can be used to estimate the confidence limits.\nThe following code, using the simpleboot 📦 has been designed to be easily modifiable and will compute CI using empirical percentiles. Following this is an easier approach using the library boot that will calculate several different bootstrap confidence limits.\n\n############################################################\n#######\n# Bootstrap analysis the simple way with library simpleboot\n# Define model to be bootstrapped and the data source used\nmymodel &lt;- lm(logherp ~ logarea + thtden + swamp + I(swamp^2), data = mydata)\n# Set the number of bootstrap iterations\nnboot &lt;- 1000\nlibrary(simpleboot)\n# R is the number of bootstrap iterations\n# Setting rows to FALSE indicates resampling of residuals\nmysimpleboot &lt;- lm.boot(mymodel, R = nboot, rows = FALSE)\n# Extract bootstrap coefficients\nmyresults &lt;- sapply(mysimpleboot$boot.list, function(x) x$coef)\n# Transpose matrix so that lines are bootstrap iterations\n# and columns are coefficients\ntmyresults &lt;- t(myresults)\n\nYou can then plot the results using the follwoing code. When run, it will pause to let you have a look at the distribution for each coefficient in the model by producing plots like:\n\n# Plot histograms of bootstrapped coefficients\nncoefs &lt;- length(data.frame(tmyresults))\npar(mfrow = c(1, 2), mai = c(0.5, 0.5, 0.5, 0.5), ask = TRUE)\nfor (i in 1:ncoefs) {\n  lab &lt;- colnames(tmyresults)[i]\n  x &lt;- tmyresults[, i]\n  plot(density(x), main = lab, xlab = \"\")\n  abline(v = mymodel$coef[i], col = \"red\")\n  abline(v = quantile(x, c(0.025, 0.975)))\n  hist(x, main = lab, xlab = \"\")\n  abline(v = quantile(x, c(0.025, 0.975)))\n  abline(v = mymodel$coef[i], col = \"red\")\n}\n\n\n\n\n\nDistribution of bootstrapped estimates for logarea\n\n\n\nThe top plot is the probability density function and the bottom one is the histogram of the bootstrap estimates for the coefficient. On these plots, the red line indicate the value of the parameter in the ordinary analysis, and the two vertical black lines mark the limits of the 95% confidence interval. Here the CI does not include 0 and one can conclude that the effect of logarea on logherp is significantly positive.\nPrecise values for the limits can be obtained by:\n\n# Display empirical bootstrap quantiles (not corrected for bias)\np &lt;- c(0.005, 0.01, 0.025, 0.05, 0.95, 0.975, 0.99, 0.995)\napply(tmyresults, 2, quantile, p)\n\n      (Intercept)   logarea       thtden      swamp    I(swamp^2)\n0.5%  -0.72679727 0.1376047 -0.047954069 0.01607917 -0.0003441977\n1%    -0.68171336 0.1411605 -0.045913835 0.01874510 -0.0003408076\n2.5%  -0.64581754 0.1539950 -0.042326679 0.02003365 -0.0003293126\n5%    -0.59520707 0.1644156 -0.039291206 0.02141624 -0.0003137650\n95%   -0.06739058 0.2792547 -0.012401452 0.03783277 -0.0001845163\n97.5% -0.02370053 0.2915589 -0.009592377 0.03944599 -0.0001752037\n99%    0.02576749 0.3020975 -0.006487548 0.04113196 -0.0001590565\n99.5%  0.05180197 0.3137713 -0.002286535 0.04170117 -0.0001469197\n\n\nThese confidence limits are not reliable when the distribution of the bootstrap estimates deviate from Gaussian. If they do,, then it is preferable to compute so-called bias-corrected accelerated (BCa) confidence limits. The following code does just that:\n\n################################################\n# Bootstrap analysis in multiple regression with BCa confidence intervals\n# Preferable when parameter distribution is far from normal\n# Bootstrap 95% BCa CI for regression coefficients\n\nlibrary(boot)\n# function to obtain regression coefficients for each iteration\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ] # allows boot to select sample\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n# bootstrapping with 1000 replications\nresults &lt;- boot(\n  data = mydata, statistic = bs, R = 1000,\n  formula = logherp ~ logarea + thtden + swamp + I(swamp^2)\n)\n# view results\n\nTo get teh results, the following code will produce the standard graph for each coefficient and the resulting BCa interval.\n\nplot(results, index = 1) # intercept\nplot(results, index = 2) # logarea\nplot(results, index = 3) # thtden\nplot(results, index = 4) # swamp\nplot(results, index = 5) # swamp2\n\n# get 95% confidence intervals\nboot.ci(results, type = \"bca\", index = 1)\nboot.ci(results, type = \"bca\", index = 2)\nboot.ci(results, type = \"bca\", index = 3)\nboot.ci(results, type = \"bca\", index = 4)\nboot.ci(results, type = \"bca\", index = 5)\n\nFor logarea, we get:\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"bca\", index = 2)\n\nIntervals : \nLevel       BCa          \n95%   ( 0.1066,  0.3161 )  \nCalculations and Intervals on Original Scale\n\n\n\n\n\n\n\n\nNote that the BCa interval is from 0.12 to 0.32, whereas the simpler percentile interval is 0.16 to 0.29. BCa interval here is longer on the low side, and shorter on the high side, which it should be given the distribution of bootstrap estimates.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "07-reg_mult.html#permutation-test",
    "href": "07-reg_mult.html#permutation-test",
    "title": "\n7  Multiple regression\n",
    "section": "\n7.13 Permutation test",
    "text": "7.13 Permutation test\nPermutation tests are more rarely performed in multiple regression contexts than bootstrap. But here is code to do it.\n\n############################################################\n##########\n# Permutation in multiple regression\n#\n# using lmperm library\nlibrary(lmPerm)\n# Fit desired model on the desired dataframe\nmy_model &lt;- lm(logherp ~ logarea + thtden + swamp + I(swamp^2),\n  data = mydata\n)\nmy_model_prob &lt;- lmp(\n  logherp ~ logarea + thtden + swamp + I(swamp^2),\n  data = mydata, perm = \"Prob\"\n)\nsummary(my_model)\nsummary(my_model_prob)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "08-ancova_glm.html",
    "href": "08-ancova_glm.html",
    "title": "\n8  ANCOVA and general linear model\n",
    "section": "",
    "text": "8.1 R packages and data\nThis laboratory requires the following:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ANCOVA and general linear model</span>"
    ]
  },
  {
    "objectID": "08-ancova_glm.html#set-anco",
    "href": "08-ancova_glm.html#set-anco",
    "title": "\n8  ANCOVA and general linear model\n",
    "section": "",
    "text": "R packages:\n\nggplot2\ncar\nlmtest\n\n\ndata files\n\nanc1dat.csv\nanc3dat.csv",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ANCOVA and general linear model</span>"
    ]
  },
  {
    "objectID": "08-ancova_glm.html#linear-models",
    "href": "08-ancova_glm.html#linear-models",
    "title": "\n8  ANCOVA and general linear model\n",
    "section": "\n8.2 Linear models",
    "text": "8.2 Linear models\nGLM sometimes stands for General Linear Model, however, it is much more frequently used for Generalized linear models. Thus I always rather talk about Linear models or LMs instead of General linear models to avoid confusion in the acronym. LMs are statistical models that can be written as \\(Y = XB + E\\), where Y is a vector (or matrix) containing the dependent variable, X is a matrix of independent variables, B is a matrix of estimated parameters, and E is the vector (or matrix) of independent, normally distributed and homoscedastic residuals. All tests we have seen to date (t-test, simple linear regression, One-Way ANOVA, Multiway ANOVA, and multiple regression) are LMs. Note that all models we have encountered until now contain only one type of variable (either continuous or categorical) as independent variables. In this laboratory exercise, you will fit models that have both type of independent variables. These models are also LMs.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ANCOVA and general linear model</span>"
    ]
  },
  {
    "objectID": "08-ancova_glm.html#ancova",
    "href": "08-ancova_glm.html#ancova",
    "title": "\n8  ANCOVA and general linear model\n",
    "section": "\n8.3 ANCOVA",
    "text": "8.3 ANCOVA\nANCOVA stands for Analysis of Covariance. It is a type of LM where there is one (or more) continuous independent variable (sometimes called a covariate) and one (or more) categorical independent variable. In the traditional treatment of ANCOVA in biostatistical textbooks, the ANCOVA model does not contain interaction terms between the continuous and categorical independent variables. Hence, the traditional ANCOVA analysis assumes that there is no interaction, and is preceeded by a test of significance of interactions, equivalent to testing that the slopes (coefficients for the continuous independent variables) do not differ among level of the categorical independent variables (a test for homogeneity of slopes). Some people, me included, use the term ANCOVA a bit more loosely for any LM that involves both continuous and categorical variables. Be aware that, depending on the author, ANCOVA may refer to a model with or without interaction terms.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ANCOVA and general linear model</span>"
    ]
  },
  {
    "objectID": "08-ancova_glm.html#homogeneity-of-slopes",
    "href": "08-ancova_glm.html#homogeneity-of-slopes",
    "title": "\n8  ANCOVA and general linear model\n",
    "section": "\n8.4 Homogeneity of slopes",
    "text": "8.4 Homogeneity of slopes\nIn many biological problems, a question arises as to whether the slopes of two or more regression lines are significantly different; for example, whether two different insecticides differ in their efficacy, whether males and females differ in their growth curves, etc. These problems call for direct comparisons of slopes. GLMs (ANCOVAs) can test for equality of slopes (homogeneity of slopes).\nRemember that there are two parameters that describe a regression line, the intercept and the slope. The ANCOVA model (sensu stricto) tests for homogeneity of intercepts, but the starting point for the analysis is a test for homogeneity of slopes. This test can be performed by fitting a model with main effects for both the categorical and continuous independent variables, plus the interaction term(s), and testing for significance of the addition of the interaction terms.\n\n8.4.1 Case 1 - Size as a function of age (equal slopes example)\n\n\n\n\n\n\nExercise\n\n\n\nUsing the file anc1dat.csv , test the hypothesis that female and male sturgeon at The Pas over the years 1978-1980 have the same observed growth rate, defined as the slope of the regression of log10 of fork length, lfkl , on the log10 age, lage .\n\n\nFirst, let’s have a look at the data. It would help to draw the regression line and a lowess trace to better assess linearity. Being fancy, one could also use more of R magic to spruce up the axis legends (note the use of expression() to get subscripts):\n\nanc1dat &lt;- read.csv(\"data/anc1dat.csv\")\nanc1dat$sex &lt;- as.factor(anc1dat$sex)\nmyplot &lt;- ggplot(data = anc1dat, aes(x = lage, y = log10(fklngth))) +\n  facet_grid(. ~ sex) +\n  geom_point()\nmyplot &lt;- myplot +\n  stat_smooth(method = lm, se = FALSE) +\n  stat_smooth(se = FALSE, color = \"red\") +\n  labs(\n    y = expression(log[10] ~ (Fork ~ length)),\n    x = expression(log[10] ~ (Age))\n  )\nmyplot\n\n\n\nSturgeon length as a function of age\n\n\n\nThe log-log transformation makes the relationship linear and, at first glance, there is no issues with assumptions of LMs (although this should be confirmed by appropriate examination of the residuals). Let’s fit the full model with both main effects and the interaction:\n\nmodel.full1 &lt;- lm(lfkl ~ sex + lage + sex:lage, data = anc1dat)\nAnova(model.full1, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.64444  1 794.8182 &lt; 2.2e-16 ***\nsex         0.00041  1   0.5043    0.4795    \nlage        0.07259  1  89.5312 4.588e-15 ***\nsex:lage    0.00027  1   0.3367    0.5632    \nResiduals   0.07135 88                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn the previous output, on line 4, 0.5632277 is the probability of observing an lage:sex interaction this strong or stronger under the null hypothesis that slope of the relationship between fork length and age does not vary between the sexes, or equivalently that the difference in fork length between males and females (if it exists) does not vary with age (and providing the assumptions of the analysis have been met).\n\n\n\n\n\n\nNote that I used the Anova() function with an uppercase “a” (from the car library) instead of the “built in” anova() (with a lowercase “a”) command to get the results using Type III sums of squares. The type III (partial) sums of squares are calculated as if each variable was the last entered in the model and correspond to the difference in explained SS between the full model and a reduced model where only that variable is excluded. The standard anova() function returns Type I (sequential) SS, calculated as each variable is added sequentially to a null model with only an intercept. In rare cases, the type I and type III SS are equal (when the design is perfectly balanced and there is no multicolinearity). In the vast majority of cases, they will differ, and I recommend that you always use the Type III SS in your analyses.\n\n\n\nOn the basis of this analysis, we would accept the null hypotheses that:\n\nthe slope of the regression of log(fork length) on log(age) is the same for males and females (the interaction term is not significant)\nthat the intercepts are also the same for the two sexes (the sex term is also not significant).\n\nBut before accepting these conclusions, we should test the assumptions in the usual way\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(model.full1)\n\n\n\nModel assumptions for model.full1\n\n\n\n\n\n\nWith respect to normality, things look O.K., although there are several points in the top right corner that appear to lie off the line. We could also run a Wilk-Shapiro normality test and find W = 0.9764, p = 0.09329, also suggesting this assumption is valid. Homoscedasticity seems fine too, but if you want further evidence of this, you can run one of the tests. Here I use the Breusch-Pagan test, which is appropriate when some of the independent variables are continuous (Levene’s test is for categorical independent variables only):\n\nbptest(model.full1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model.full1\nBP = 0.99979, df = 3, p-value = 0.8013\n\n\nSince the null is that the residuals are homoscedastic, and p is rather large, the test confirm the visual assessment.\nFurther, there is no obvious pattern in the residuals, which implies there is no problem with the assumption of linearity. This too can be formally tested:\n\nresettest(model.full1, power = 2:3, type = \"regressor\", data = anc1dat)\n\n\n    RESET test\n\ndata:  model.full1\nRESET = 0.59861, df1 = 2, df2 = 86, p-value = 0.5519\n\n\nThe last assumption in this sort of analysis is that the covariate (in this case, lage ) has no measurement error. We really have no way of knowing whether this assumption is justified, although multiple aging of fish by several different investigators usually gives ages that are within 1-2 years of each other, which is within the 10% considered by most to be the maximum for Type I modelling. Note that there is no “test” that you can do with the data to determine what the error is, at least in this case. If we had replicate ages for individual fish, it could be estimated quantitatively\n\n\n\n\n\n\nExercise\n\n\n\nYou will notice that there is one datum with a large studentized residual, i.e. an outlier (case 49). Eliminate this datum from your data file and rerun the analysis. Do your conclusions change?\n\n\n\n\n\n\n\n\n\nmodel.full.no49 &lt;- lm(lfkl ~ sex + lage + sex:lage, data = anc1dat[c(-49), ])\nAnova(model.full.no49, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value Pr(&gt;F)    \n(Intercept) 0.64255  1 895.9394 &lt;2e-16 ***\nsex         0.00038  1   0.5273 0.4697    \nlage        0.07378  1 102.8746 &lt;2e-16 ***\nsex:lage    0.00022  1   0.3135 0.5770    \nResiduals   0.06239 87                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nSo the conclusion does not change if the outlier is deleted (not surprising as Cook’s distance is low for this point reflecting its low leverage). Since there is no good reason to delete this data point, and since (at least qualitatively) our conclusions do not change, it is probably best to go with the full data set. A test of the assumptions for the refit model (with the outlier removed) shows that all are met, and no more outliers are detected. (I won’t report these analyses, but you can and should do them just to assure yourself that everything is O.K.)\n\n8.4.2 Case 2 - Size as a function of age (different slopes example)\n\n\n\n\n\n\nExercise\n\n\n\nThe file anc3dat.csv records data on male sturgeon collected at two locations ( locate) , Lake of the Woods, in northwestern Ontario, and the Churchill River in northern Manitoba. Using the same procedure as outlined above (with locate as the categorical variable instead of sex ), test the null hypothesis that the slope of the regression of lfkl on lage is the same in the two locations. What do you conclude?\n\n\n\nanc3dat &lt;- read.csv(\"data/anc3dat.csv\")\nmyplot &lt;- ggplot(data = anc3dat, aes(x = lage, y = log10(fklngth))) +\n  facet_grid(. ~ locate) +\n  geom_point() +\n  stat_smooth(method = lm, se = FALSE) +\n  stat_smooth(se = FALSE, color = \"red\") +\n  labs(\n    y = expression(log[10] ~ (Fork ~ length)),\n    x = expression(log[10] ~ (Age))\n  )\nmyplot\n\n\n\nLongueur des esturgeons en fonction de l’age d’après anc3dat\n\n\nmodel.full2 &lt;- lm(lfkl ~ lage + locate + lage:locate, data = anc3dat)\nAnova(model.full2, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.62951  1 1078.632 &lt; 2.2e-16 ***\nlage        0.07773  1  133.185 &lt; 2.2e-16 ***\nlocate      0.00968  1   16.591 0.0001012 ***\nlage:locate 0.00909  1   15.575 0.0001592 ***\nResiduals   0.05136 88                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn this case, we reject the null hypotheses that (1) the slopes of the regressions are the same in the two locations; and (2) that the intercepts are the same in the two locations. In other words, if we want to predict the fork length of a sturgeon of a particular age (accurately) we need to know from which location it came. The fact that we reject the null hypothesis that the slopes of the lfkl - lage regressions are the same in both locations means that we should be doing individual regressions for each location separately (that is in fact what the full model is fitting). But we are jumping the gun here. Before you can trust these p values, you need to confirm that assumptions are met:\n\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(model.full2)\n\n\n\nConditions d’applications du modèle model.full2\n\n\n\n\n\n\nIf you analyze the residuals (in the way described above), you will find that there is no problem with the linearity assumption, nor the homoscedasticity assumption (BP = 1.2267, p = 0.268). However, Wilk-Shapiro test of normality of residuals is suspicious (W=0.97, p = 0.03). Given the relatively large sample size (\\(N = 92\\)), this normality test has high power and the magnitude of deviation from normality does not appear to be large. Considering the robustness of GLM to non-normality with large samples, we should not be overly concerned with this violation.\nGiven that the assumptions appear sufficiently met, we can accept the results as calculated by R. All terms in the model are significant (location, lage, and the interaction). This full model is equivalent to fitting separate regressions for each location. To get the coefficients of these regression, one can either fit the two regressions on data subsets for each location, or extract the fitted coefficients from the full model:\n\nmodel.full2\n\n\nCall:\nlm(formula = lfkl ~ lage + locate + lage:locate, data = anc3dat)\n\nCoefficients:\n            (Intercept)                     lage       locateNELSON        \n                 1.2284                   0.3253                   0.2207  \nlage:locateNELSON        \n                -0.1656  \n\n\nBy default, the variable locate in the model is internally encoded as 0 for the location that comes first alphabetically (LofW) and 1 for the other (Nelson). So the regression equations for each location become:\nFor LofW: \\[\\begin{aligned}\nlfkl &= 1.2284 + 0.3253 \\times lage + 0.2207 \\times 0 - 0.1656 \\times 0 \\times lage \\\\\n&= 1.2284 + 0.3253 \\times lage\n\\end{aligned}\\]\nFor Nelson: \\[\\begin{aligned}\nlfkl &= 1.2284 + 0.3253 \\times lage + 0.2207 \\times 1 - 0.1656 \\times 1 \\times lage \\\\\n&= 1.4491 + 0.1597 \\times lage\n\\end{aligned}\\]\nYou can convince youself that this is the same as fitting 2 regressions separately.\n\nby(anc3dat, anc3dat$locate, function(x) lm(lfkl ~ lage, data = x))\n\nanc3dat$locate: LOFW        \n\nCall:\nlm(formula = lfkl ~ lage, data = x)\n\nCoefficients:\n(Intercept)         lage  \n     1.2284       0.3253  \n\n------------------------------------------------------------ \nanc3dat$locate: NELSON      \n\nCall:\nlm(formula = lfkl ~ lage, data = x)\n\nCoefficients:\n(Intercept)         lage  \n     1.4491       0.1597",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ANCOVA and general linear model</span>"
    ]
  },
  {
    "objectID": "08-ancova_glm.html#the-ancova-model",
    "href": "08-ancova_glm.html#the-ancova-model",
    "title": "\n8  ANCOVA and general linear model\n",
    "section": "\n8.5 The ANCOVA model",
    "text": "8.5 The ANCOVA model\nIf the test for homogeneity of slopes indicates that the two or more slopes are not significantly different, i.e. there is no significant interaction between the categorical and continuous variable, then a single slope parameter can be fit. How about the intercepts? Do they differ among levels of the categorical variable? There are two school of thoughts on how to proceed to test for equality of intercepts when slopes are equal:\n\nThe old school fits a reduced model, with the categorical and continuous variables, but no interactions (this is the ANCOVA model, sensus stricto) and uses the partitioned sums of squares to test for significance, say with the Anova() function. This approach is the one presented in many statistical textbooks.\nOthers simply use the full model results, and test significance of each term from the partial sums of squares. This approach has the advantage of being faster as only one model needs to be fitted to make all inferences. However, this approach is less powerful.\n\nIn most practical cases, it does not matter unless one has very complex models with a large number of terms and higher level interactions and that many of these terms are not significant. My suggestion is that you use the faster approach first, and use the traditional approach only when you accept the null hypothesis for equal intercepts. Why? Since the faster approach is less powerful, if you nevertheless reject H0, then this conclusion will not be changed, only reinforced, by using the traditional approach.\nHere I will compare the old school and the other approach. Recall that we want to assess equality of intercepts once we determined that slopes are equal. Test for equality of intercepts when slopes differ (or, if you prefer, when there is a significant interaction) are rarely directly meaningful, are often misinterpreted, and should rarely be conducted.\nGoing back to anc1dat.csv, comparing the relationships between lfkl and lage among sexes, we obtained the following results for the full model with interactions\n\nAnova(model.full1, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.64444  1 794.8182 &lt; 2.2e-16 ***\nsex         0.00041  1   0.5043    0.4795    \nlage        0.07259  1  89.5312 4.588e-15 ***\nsex:lage    0.00027  1   0.3367    0.5632    \nResiduals   0.07135 88                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe already concluded that the slope of the regression for males and females does not differ (the interaction sex:lage is not significant). Note that the p-values associated with sex (0.4795) is not significant either.\nFor the old-school approach, one would fit a reduced model (the sensus stricto ANCOVA model):\n\nmodel.ancova &lt;- lm(lfkl ~ sex + lage, data = anc1dat)\nAnova(model.ancova, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df   F value Pr(&gt;F)    \n(Intercept) 1.13480  1 1410.1232 &lt;2e-16 ***\nsex         0.00149  1    1.8513 0.1771    \nlage        0.14338  1  178.1627 &lt;2e-16 ***\nResiduals   0.07162 89                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(model.ancova)\n\n\nCall:\nlm(formula = lfkl ~ sex + lage, data = anc1dat)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.093992 -0.018457 -0.000876  0.022491  0.081161 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      1.225533   0.032636  37.552   &lt;2e-16 ***\nsexMALE         -0.008473   0.006228  -1.361    0.177    \nlage             0.327253   0.024517  13.348   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02837 on 89 degrees of freedom\nMultiple R-squared:  0.696, Adjusted R-squared:  0.6892 \nF-statistic: 101.9 on 2 and 89 DF,  p-value: &lt; 2.2e-16\n\n\nAccording to this test, sex is not significant and therefore we can conclude that the intercept does not vary significantly between males and females. Note that the p-value is lower this time (0.1771 vs 0.4795), reflecting the higher power of this old-school approach. However, the conclusion remains qualitatively the same: intercepts do not differ.\nSo we accept the null hypothesis that the intercepts are the same for the two sexes. Running the residual diagnostics, we find no problems with linearity, independence, homogeneity of variances, and normality.\n\n\n\n\n\n\nExercise\n\n\n\nYou will notice, in the above analysis that the residuals plots flag three data points (cases 19, 49, and 50) as having high residuals. These points are a bit worrisome, and may be having a disproportionate effect on your analysis. Eliminate these “outliers” and re-run the analysis. Now what do you conclude?\n\n\n\nmodel.ancova.nooutliers &lt;- lm(lfkl ~ sex + lage, data = anc1dat[c(-49, -50, -19), ])\nAnova(model.ancova.nooutliers, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df   F value  Pr(&gt;F)    \n(Intercept) 1.09160  1 1896.5204 &lt; 2e-16 ***\nsex         0.00232  1    4.0374 0.04764 *  \nlage        0.13992  1  243.0946 &lt; 2e-16 ***\nResiduals   0.04950 86                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(model.ancova.nooutliers)\n\n\nCall:\nlm(formula = lfkl ~ sex + lage, data = anc1dat[c(-49, -50, -19), \n    ])\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.058397 -0.018469 -0.000976  0.020696  0.040288 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      1.224000   0.028106  43.549   &lt;2e-16 ***\nsexMALE         -0.010823   0.005386  -2.009   0.0476 *  \nlage             0.328604   0.021076  15.591   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02399 on 86 degrees of freedom\nMultiple R-squared:  0.7706,    Adjusted R-squared:  0.7653 \nF-statistic: 144.4 on 2 and 86 DF,  p-value: &lt; 2.2e-16\n\n\nWell, well. Now we would, according to convention, reject the null hypothesis, and conclude that in fact, the intercepts of the regressions for the two sexes are different! This is a qualitatively different result from that obtained using all the data. Why? There are two possible reasons:\n\nthe “outliers” have significant impacts on the fitted regression lines, so that the intercepts of the lines change depending on whether the “outliers” are included (or not);\nthe exclusion of the outliers increases the precision, i.e. reduces the standard error of the intercept estimates, and therefore increases the likelihood that the two intercepts will in fact be “statistically” different.\n\n\nis unlikely, since none of the outliers had high leverage (hence Cook’s distances were not large), so (2) is more likely, and you can verify this by fitting separate regressions for each sex with and without these three outliers. If you do, you will notice that the estimated intercepts for each sex do not change very much, but the standard errors of these intercepts change quite a lot.\n\n\n\n\n\n\n\nExercise\n\n\n\nFit separate regresssions by sex with vs. without the outliers. Pay attention to the intercepts.\n\n\nIncluding all data.\n\nby(\n  anc1dat,\n  anc1dat[, \"sex\"],\n  function(x) {\n    summary(lm(lfkl ~ lage, data = x))\n  }\n)\n\nanc1dat[, \"sex\"]: FEMALE      \n\nCall:\nlm(formula = lfkl ~ lage, data = x)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.093728 -0.020510 -0.000618  0.024066  0.078844 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.24264    0.04660  26.664  &lt; 2e-16 ***\nlage         0.31431    0.03512   8.949 4.16e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03011 on 52 degrees of freedom\nMultiple R-squared:  0.6063,    Adjusted R-squared:  0.5987 \nF-statistic: 80.09 on 1 and 52 DF,  p-value: 4.16e-12\n\n------------------------------------------------------------ \nanc1dat[, \"sex\"]: MALE        \n\nCall:\nlm(formula = lfkl ~ lage, data = x)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.046663 -0.014875 -0.004275  0.013489  0.078910 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.19730    0.04209   28.45  &lt; 2e-16 ***\nlage         0.34300    0.03337   10.28 2.97e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02594 on 36 degrees of freedom\nMultiple R-squared:  0.7458,    Adjusted R-squared:  0.7388 \nF-statistic: 105.6 on 1 and 36 DF,  p-value: 2.972e-12\n\n\nDifference in intercept is indeed really small. Now let’s have a look when we exclude outliers.\n\nby(\n  anc1dat,\n  anc1dat[, \"sex\"],\n  function(x) {\n    summary(lm(lfkl ~ lage, data = x[c(-49, -50, -19), ]))\n  }\n)\n\nanc1dat[, \"sex\"]: FEMALE      \n\nCall:\nlm(formula = lfkl ~ lage, data = x[c(-49, -50, -19), ])\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.092746 -0.020176 -0.000078  0.023779  0.079995 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.24029    0.04815  25.760  &lt; 2e-16 ***\nlage         0.31533    0.03614   8.724 1.53e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03021 on 49 degrees of freedom\nMultiple R-squared:  0.6083,    Adjusted R-squared:  0.6003 \nF-statistic: 76.11 on 1 and 49 DF,  p-value: 1.526e-11\n\n------------------------------------------------------------ \nanc1dat[, \"sex\"]: MALE        \n\nCall:\nlm(formula = lfkl ~ lage, data = x[c(-49, -50, -19), ])\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.047429 -0.012818 -0.005274  0.013495  0.077538 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.19361    0.04188   28.50  &lt; 2e-16 ***\nlage         0.34662    0.03325   10.42 2.83e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02574 on 35 degrees of freedom\nMultiple R-squared:  0.7563,    Adjusted R-squared:  0.7494 \nF-statistic: 108.6 on 1 and 35 DF,  p-value: 2.835e-12\n\n\nDifferences in intercepts are really small and similar than in previous models but now the precision (i.e. standard error) is much smaller for the models without outliers.\n\n\n\n\n\n\nIt is often the case that by eliminating outliers, new outliers appear. This is simply because the “outlier” designation is usually based on a standardized residual: if you eliminate a couple of outliers, then the residual sums of squares decreases, i.e. the “average” (absolute) residual decreases. Thus, points which were not “far from the average” when the original average residual was comparatively large (i.e. were not “outliers”), may now become so because the average residual has been decreased. Remember also that as you eliminate outliers, N decreases, and the increase in R2 may be more than compensated for by decreased power. So be wary of eliminating outliers!",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ANCOVA and general linear model</span>"
    ]
  },
  {
    "objectID": "08-ancova_glm.html#comparing-model-fits",
    "href": "08-ancova_glm.html#comparing-model-fits",
    "title": "\n8  ANCOVA and general linear model\n",
    "section": "\n8.6 Comparing model fits",
    "text": "8.6 Comparing model fits\nAs we have just seen, the process of fitting models to data is usually an iterative one. That is, there are, more often than not, several competing models that may be used to fit the data and it is left to the analyst to decide which model best balances goodness of fit (which we are usually trying to maximize) and complexity (which we are usually trying to minimize). In general, the strategy to use in regression and anova is to choose a simpler model when doing so does not reduce the goodness-of-fit by a significant amount. R can compute an F-statistic to compare the fit of two models. The null hypothesis in this situation is that there is no difference in goodness of fit between the models.\n\n\n\n\n\n\nExercise\n\n\n\nWorking with the Anc1dat data set, compare the fit of the ANCOVA and common simple regression models::\n\n\n\nmodel.linear &lt;- lm(lfkl ~ lage, data = anc1dat)\nanova(model.ancova, model.linear)\n\nAnalysis of Variance Table\n\nModel 1: lfkl ~ sex + lage\nModel 2: lfkl ~ lage\n  Res.Df      RSS Df  Sum of Sq      F Pr(&gt;F)\n1     89 0.071623                            \n2     90 0.073113 -1 -0.0014899 1.8513 0.1771\n\n\nThe anova() function can compare the differences in sum of squares and degrees of freedom between the simpler and more complex models, takes the ratio of these two values to generate a mean square, and divides this by the mean square of the more complex model to generate an F-statistic. In the above case, there is insufficient evidence to reject the null hypothesis and we conclude that the simpler model, which is the simple linear regression, is the best model for these data. (Because these models differ by only the presence vs. absence of a single factor (sex), the P-value is the same as the p-value for sex in model 1.)\n\n\n\n\n\n\nExercise\n\n\n\nRepeat the above procedure with the ANC3DAT data, rerunning the full ANCOVA with interaction ( lfkl ~ lage + locate + lage:locate ) and without interaction ( lfkl ~ lage + locate ), saving the model objects as you did above. Compare the fits of the two models. What do you conclude?\n\n\n\nmodel.full.anc3dat &lt;- lm(lfkl ~ lage + locate + lage:locate, data = anc3dat)\nmodel.ancova.anc3dat &lt;- lm(lfkl ~ lage + locate, data = anc3dat)\nanova(model.full.anc3dat, model.ancova.anc3dat)\n\nAnalysis of Variance Table\n\nModel 1: lfkl ~ lage + locate + lage:locate\nModel 2: lfkl ~ lage + locate\n  Res.Df      RSS Df  Sum of Sq      F    Pr(&gt;F)    \n1     88 0.051358                                   \n2     89 0.060448 -1 -0.0090901 15.575 0.0001592 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn this case there is sufficient evidence to reject the null hypothesis and conclude that the full model with interaction is the best model to fit to the Anc3dat data. This is as we expected, given the fact that we found the interaction to be significant the in original analysis of the data. While no new information is gain from this model comparison in this case, this approach can be more usefully employed to compared nested models that differ in more than one term.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ANCOVA and general linear model</span>"
    ]
  },
  {
    "objectID": "08-ancova_glm.html#bootstrap",
    "href": "08-ancova_glm.html#bootstrap",
    "title": "\n8  ANCOVA and general linear model\n",
    "section": "\n8.7 Bootstrap",
    "text": "8.7 Bootstrap\n\n############################################################\n######\n# Bootstrap analysis\n#\n# Bootstrap analysis BCa confidence intervals\n# Preferable when parameter distribution is far from normal\n# Bootstrap 95% BCa CI for regression coefficients\nlibrary(boot)\n\n# To simplify future modifications of the code in this file,\n# copy the data to a generic mydata dataframe\nmydata &lt;- anc3dat\n\n# create a myformula variable containing the formula for the model to be fitted\nmyformula &lt;- as.formula(lfkl ~ lage + locate + lage:locate)\n\n# function to obtain regression coefficients for each iteration\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ]\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n# bootstrapping with 1000 replications\nresults &lt;- boot(data = mydata, statistic = bs, R = 1000, formula = myformula)\n\n# view results\nresults\nboot_res &lt;- summary(results)\nrownames(boot_res) &lt;- names(results$t0)\nboot_res\n\nop &lt;- par(ask = TRUE)\nfor (i in 1:length(results$t0)) {\n  plot(results, index = i)\n  title(names(results$t0)[i])\n}\npar(op)\n\n# get 95% confidence intervals\nfor (i in 1:length(results$t0)) {\n  cat(\"\\n\", names(results$t0)[i], \"\\n\")\n  print(boot.ci(results, type = \"bca\", index = i))\n}",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ANCOVA and general linear model</span>"
    ]
  },
  {
    "objectID": "08-ancova_glm.html#permutation-test",
    "href": "08-ancova_glm.html#permutation-test",
    "title": "\n8  ANCOVA and general linear model\n",
    "section": "\n8.8 Permutation test",
    "text": "8.8 Permutation test\n\n############################################################\n##########\n# Permutation test\n#\n# using lmperm library\n# To simplify future modifications of the code in this file,\n# copy the data to a generic mydata dataframe\nmydata &lt;- anc3dat\n# create a myformula variable containing the formula for the\n# model to be fitted\nmyformula &lt;- as.formula(lfkl ~ lage + locate + lage:locate)\nrequire(lmPerm2)\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(myformula, data = mydata)\n# Calculate p-values for each term by permutation\n# Note that lmp centers numeric variable by default, so to\n# get results that are\n# consistent with standard models, it is necessary to set\n# center=FALSE\nmymodelProb &lt;- lmp(myformula,\n  data = mydata, center = FALSE,\n  perm = \"Prob\"\n)\nsummary(mymodel)\nsummary(mymodelProb)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ANCOVA and general linear model</span>"
    ]
  },
  {
    "objectID": "99-references.html",
    "href": "99-references.html",
    "title": "References",
    "section": "",
    "text": "R packages used in this book\nThis book was produced using all the following\nPackage\nVersion\nCitation\n\n\n\nabind\n1.4.5\nPlate and Heiberger (2016)\n\n\narrayhelpers\n1.1.0\nBeleites (2020)\n\n\naskpass\n1.2.0\nOoms (2023a)\n\n\nbackports\n1.4.1\nLang and R Core Team (2021)\n\n\nbase\n4.3.2\nR Core Team (2023)\n\n\nbase64enc\n0.1.3\nUrbanek (2015)\n\n\nbayesplot\n1.10.0\n\nGabry et al. (2019); Gabry and Mahr (2022)\n\n\n\nbayestestR\n0.13.1\nMakowski et al. (2019)\n\n\nbit\n4.0.5\nOehlschlägel and Ripley (2022)\n\n\nbit64\n4.0.5\nOehlschlägel and Silvestri (2020)\n\n\nblob\n1.2.4\nWickham (2023a)\n\n\nbookdown\n0.37\n\nXie (2016); Xie (2023a)\n\n\n\nbrio\n1.1.4\nHester and Csárdi (2023)\n\n\nbslib\n0.6.1\nSievert et al. (2023)\n\n\nca\n0.71.1\nNenadic and Greenacre (2007)\n\n\ncachem\n1.0.8\nChang (2023a)\n\n\ncallr\n3.7.3\nCsárdi and Chang (2022)\n\n\ncar\n3.1.2\nFox and Weisberg (2019a)\n\n\ncarData\n3.0.5\nFox et al. (2022)\n\n\ncellranger\n1.1.0\nBryan (2016)\n\n\ncheckmate\n2.3.1\nLang (2017)\n\n\nclassInt\n0.4.10\nBivand (2023)\n\n\nclipr\n0.8.0\nLincoln (2022)\n\n\ncoda\n0.19.4\nPlummer et al. (2006)\n\n\ncolorspace\n2.1.0\n\nZeileis et al. (2009); Stauffer et al. (2009); Zeileis et al. (2020a)\n\n\n\ncommonmark\n1.9.0\nOoms (2023b)\n\n\ncorrplot\n0.92\nWei and Simko (2021)\n\n\ncowplot\n1.1.2\nWilke (2023a)\n\n\ncpp11\n0.4.7\nVaughan et al. (2023)\n\n\ncrayon\n1.5.2\nCsárdi (2022)\n\n\ncrosstalk\n1.2.1\nCheng and Sievert (2023)\n\n\ncurl\n5.2.0\nOoms (2023c)\n\n\ndata.table\n1.14.10\nBarrett et al. (2023)\n\n\ndatawizard\n0.9.1\nPatil et al. (2022)\n\n\nDBI\n1.2.1\nR Special Interest Group on Databases (R-SIG-DB) et al. (2024)\n\n\ndendextend\n1.17.1\nGalili (2015)\n\n\ndesc\n1.4.3\nCsárdi et al. (2023b)\n\n\ndiffobj\n0.3.5\nGaslam (2021)\n\n\ndigest\n0.6.34\nAntoine Lucas et al. (2024)\n\n\ndistributional\n0.3.2\nO’Hara-Wild et al. (2023)\n\n\nDT\n0.31\nXie et al. (2023)\n\n\ne1071\n1.7.14\nMeyer et al. (2023a)\n\n\neffects\n4.2.2\n\nFox (2003); Fox and Hong (2009); Fox and Weisberg (2018); Fox and Weisberg (2019b)\n\n\n\nellipse\n0.5.0\nMurdoch and Chow (2023)\n\n\nellipsis\n0.3.2\nWickham (2021)\n\n\nemmeans\n1.9.0\nLenth (2023)\n\n\nemo\n0.0.0.9000\nWickham et al. (2023b)\n\n\nestimability\n1.4.1\nLenth (2022)\n\n\nevaluate\n0.23\nWickham and Xie (2023)\n\n\nfactoextra\n1.0.7\nKassambara and Mundt (2020)\n\n\nFactoMineR\n2.9\nLê et al. (2008)\n\n\nfansi\n1.0.6\nGaslam (2023)\n\n\nfarver\n2.1.1\nPedersen et al. (2022)\n\n\nfastmap\n1.1.1\nChang (2023b)\n\n\nflashClust\n1.1.2\nLangfelder and Horvath (2012)\n\n\nfontawesome\n0.5.2\nIannone (2023)\n\n\nfs\n1.6.3\nHester et al. (2023b)\n\n\ngargle\n1.5.2\nBryan et al. (2023)\n\n\ngenerics\n0.1.3\nWickham et al. (2022a)\n\n\nggdist\n3.3.1\n\nKay (2023a); Kay (2024)\n\n\n\nggpubr\n0.6.0\nKassambara (2023a)\n\n\nggrepel\n0.9.5\nSlowikowski (2024)\n\n\nggridges\n0.5.5\nWilke (2023b)\n\n\nggsci\n3.0.0\nXiao (2023)\n\n\nggsignif\n0.6.4\nConstantin and Patil (2021)\n\n\nglue\n1.7.0\nHester and Bryan (2024)\n\n\ngnm\n1.1.5\nTurner and Firth (2023)\n\n\ngridExtra\n2.3\nAuguie (2017)\n\n\ngtable\n0.3.4\nWickham and Pedersen (2023)\n\n\nhere\n1.0.1\nMüller (2020)\n\n\nhighr\n0.10\nXie and Qiu (2022)\n\n\nhtmltools\n0.5.7\nCheng et al. (2023c)\n\n\nhtmlwidgets\n1.6.4\nVaidyanathan et al. (2023)\n\n\nhttpuv\n1.6.13\nCheng et al. (2023a)\n\n\nids\n1.0.1\nFitzJohn (2017)\n\n\ninsight\n0.19.7\nLüdecke et al. (2019)\n\n\nisoband\n0.2.7\nWickham et al. (2022b)\n\n\njquerylib\n0.1.4\nSievert and Cheng (2021)\n\n\nknitr\n1.45\n\nXie (2014); Xie (2015); Xie (2023b)\n\n\n\nlabeling\n0.4.3\nJustin Talbot (2023)\n\n\nlabelled\n2.12.0\nLarmarange (2023)\n\n\nlater\n1.3.2\nChang and Cheng (2023)\n\n\nlazyeval\n0.2.2\nWickham (2019)\n\n\nleaps\n3.1\nFortran code by Alan Miller (2020)\n\n\nlifecycle\n1.0.4\nHenry and Wickham (2023)\n\n\nlme4\n1.1.35.1\nBates et al. (2015)\n\n\nlmPerm\n2.1.0\nWheeler and Torchiano (2016)\n\n\nlmtest\n0.9.40\nZeileis and Hothorn (2002)\n\n\nMatrixModels\n0.5.3\nBates and Maechler (2023)\n\n\nmatrixStats\n1.2.0\nBengtsson (2023a)\n\n\nmemoise\n2.0.1\nWickham et al. (2021)\n\n\nmime\n0.12\nXie (2021)\n\n\nminiUI\n0.1.1.1\nCheng (2018)\n\n\nminqa\n1.2.6\nBates et al. (2023)\n\n\nmitools\n2.4\nLumley (2019)\n\n\nmultcomp\n1.4.25\nHothorn et al. (2008)\n\n\nmultcompView\n0.1.9\nGraves et al. (2023)\n\n\nMuMIn\n1.47.5\nBartoń (2023)\n\n\nmunsell\n0.5.0\nWickham (2018)\n\n\nmvtnorm\n1.2.4\nGenz and Bretz (2009)\n\n\nnloptr\n2.0.3\nJohnson (?)\n\n\nnumDeriv\n2016.8.1.1\nGilbert and Varadhan (2019)\n\n\nopenssl\n2.1.1\nOoms (2023d)\n\n\npalmerpenguins\n0.1.1\nHorst et al. (2020)\n\n\npatchwork\n1.2.0\nPedersen (2024)\n\n\npbkrtest\n0.5.2\nHalekoh and Højsgaard (2014)\n\n\nperformance\n0.10.8\nLüdecke et al. (2021)\n\n\npkgbuild\n1.4.3\nWickham et al. (2023e)\n\n\npkgconfig\n2.0.3\nCsárdi (2019)\n\n\npkgload\n1.3.3\nWickham et al. (2023a)\n\n\nplyr\n1.8.9\nWickham (2011a)\n\n\npolynom\n1.4.1\nVenables et al. (2022)\n\n\nposterior\n1.5.0\n\nVehtari et al. (2021); Bürkner et al. (2023)\n\n\n\npraise\n1.0.0\nCsardi and Sorhus (2015)\n\n\nprettyunits\n1.2.0\nCsardi (2023a)\n\n\nprocessx\n3.8.3\nCsárdi and Chang (2023)\n\n\nprogress\n1.2.3\nCsárdi and FitzJohn (2023)\n\n\npromises\n1.2.1\nCheng (2023)\n\n\nproxy\n0.4.27\nMeyer and Buchta (2022)\n\n\nps\n1.7.5\nLoden et al. (2023)\n\n\npwr\n1.3.0\nChampely (2020)\n\n\nquadprog\n1.5.8\nBerwin A. Turlach R port by Andreas Weingessel &lt;Andreas.Weingessel@ci.tuwien.ac.at&gt; Fortran contributions from Cleve Moler dpodi/LINPACK) (2019)\n\n\nquantreg\n5.97\nKoenker (2023)\n\n\nquestionr\n0.7.8\nBarnier et al. (2023)\n\n\nqvcalc\n1.0.3\nFirth (2023)\n\n\nR.cache\n0.16.0\nBengtsson (2022)\n\n\nR.methodsS3\n1.8.2\nBengtsson (2003a)\n\n\nR.oo\n1.25.0\nBengtsson (2003b)\n\n\nR.utils\n2.12.3\nBengtsson (2023b)\n\n\nR6\n2.5.1\nChang (2021)\n\n\nrappdirs\n0.3.3\nRatnakumar et al. (2021)\n\n\nRColorBrewer\n1.1.3\nNeuwirth (2022)\n\n\nRcpp\n1.0.12\n\nEddelbuettel and François (2011); Eddelbuettel (2013); Eddelbuettel and Balamuta (2018); Eddelbuettel et al. (2024)\n\n\n\nRcppEigen\n0.3.3.9.4\nBates and Eddelbuettel (2013)\n\n\nrelimp\n1.0.5\nHeather Turner and Fox (2016)\n\n\nrematch\n2.0.0\nCsardi (2023b)\n\n\nrematch2\n2.1.2\nCsárdi (2020)\n\n\nremotes\n2.4.2.1\nCsárdi et al. (2023a)\n\n\nrenv\n1.0.3\nUshey and Wickham (2023)\n\n\nreshape2\n1.4.4\nWickham (2007)\n\n\nrmarkdown\n2.25\n\nXie et al. (2018); Xie et al. (2020); Allaire et al. (2023)\n\n\n\nrprojroot\n2.0.4\nMüller (2023)\n\n\nrstatix\n0.7.2\nKassambara (2023b)\n\n\nsandwich\n3.1.0\n\nZeileis (2004); Zeileis (2006); Zeileis et al. (2020b)\n\n\n\nsass\n0.4.8\nCheng et al. (2023b)\n\n\nscales\n1.3.0\nWickham et al. (2023f)\n\n\nscatterplot3d\n0.3.44\nLigges and Mächler (2003)\n\n\nselectr\n0.4.2\nPotter (2012)\n\n\nshiny\n1.8.0\nChang et al. (2023)\n\n\nsimpleboot\n1.1.7\nPeng (2019)\n\n\nsourcetools\n0.1.7.1\nUshey (2023)\n\n\nSparseM\n1.81\nKoenker (2021)\n\n\nstringi\n1.8.3\nGagolewski (2022)\n\n\nstyler\n1.10.2\nMüller and Walthert (2023)\n\n\nsurvey\n4.2.1\n\nLumley (2004); Lumley (2010); Lumley (2023)\n\n\n\nsvglite\n2.1.3\nWickham et al. (2023c)\n\n\nsvUnit\n1.0.6\nGrosjean (2023)\n\n\nsys\n3.4.2\nOoms (2023e)\n\n\nsystemfonts\n1.0.5\nPedersen et al. (2023)\n\n\ntensorA\n0.36.2.1\nvan den Boogaart (2023)\n\n\ntestthat\n3.2.1\nWickham (2011b)\n\n\ntextshaping\n0.3.7\nPedersen (2023)\n\n\nTH.data\n1.1.2\nHothorn (2023)\n\n\ntidybayes\n3.0.6\nKay (2023b)\n\n\ntidyselect\n1.2.0\nHenry and Wickham (2022)\n\n\ntidyverse\n2.0.0\nWickham et al. (2019)\n\n\ntimechange\n0.2.0\nSpinu (2023)\n\n\ntinytex\n0.49\n\nXie (2019); Xie (2023c)\n\n\n\ntzdb\n0.4.0\nVaughan (2023)\n\n\nutf8\n1.2.4\nPerry (2023)\n\n\nuuid\n1.1.1\nUrbanek and Ts’o (2023)\n\n\nvcd\n1.4.12\n\nMeyer et al. (2006); Zeileis et al. (2007); Meyer et al. (2023b)\n\n\n\nvcdExtra\n0.8.5\nFriendly (2023)\n\n\nvctrs\n0.6.5\nWickham et al. (2023d)\n\n\nviridis\n0.6.4\nGarnier et al. (2023a)\n\n\nviridisLite\n0.4.2\nGarnier et al. (2023b)\n\n\nvroom\n1.6.5\nHester et al. (2023a)\n\n\nwaldo\n0.5.2\nWickham (2023b)\n\n\nwithr\n3.0.0\nHester et al. (2024)\n\n\nxfun\n0.41\nXie (2023d)\n\n\nxtable\n1.8.4\nDahl et al. (2019)\n\n\nyaml\n2.3.8\nGarbett et al. (2023)\n\n\nzoo\n1.8.12\nZeileis and Grothendieck (2005)",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "99-references.html#r-packages-used-in-this-book",
    "href": "99-references.html#r-packages-used-in-this-book",
    "title": "References",
    "section": "",
    "text": "Bibliography\n\n\nAllaire, J., Y. Xie, C. Dervieux, J. McPherson, J. Luraschi, K. Ushey,\nA. Atkins, H. Wickham, J. Cheng, W. Chang, and R. Iannone. 2023. rmarkdown: Dynamic documents for r.\n\n\nAntoine Lucas, D. E. with contributions by, J. Tuszynski, H. Bengtsson,\nS. Urbanek, M. Frasca, B. Lewis, M. Stokely, H. Muehleisen, D. Murdoch,\nJ. Hester, W. Wu, Q. Kou, T. Onkelinx, M. Lang, V. Simko, K. Hornik, R.\nNeal, K. Bell, M. de Queljoe, I. Suruceanu, B. Denney, D. Schumacher, W.\nChang, D. Attali, and M. Chirico. 2024. digest: Create compact hash digests of r\nobjects.\n\n\nAuguie, B. 2017. gridExtra: Miscellaneous functions for\n“Grid” graphics.\n\n\nBarnier, J., F. Briatte, and J. Larmarange. 2023. questionr: Functions to make surveys processing\neasier.\n\n\nBarrett, T., M. Dowle, and A. Srinivasan. 2023. data.table: Extension of “data.frame”.\n\n\nBartoń, K. 2023. MuMIn:\nMulti-model inference.\n\n\nBates, D., and D. Eddelbuettel. 2013. Fast and elegant numerical\nlinear algebra using the RcppEigen package. Journal of\nStatistical Software 52:1–24.\n\n\nBates, D., M. Mächler, B. Bolker, and S. Walker. 2015. Fitting linear\nmixed-effects models using lme4. Journal\nof Statistical Software 67:1–48.\n\n\nBates, D., and M. Maechler. 2023. MatrixModels:\nModelling with sparse and dense matrices.\n\n\nBates, D., K. M. Mullen, J. C. Nash, and R. Varadhan. 2023. minqa: Derivative-free optimization algorithms by\nquadratic approximation.\n\n\nBeleites, C. 2020. arrayhelpers: Convenience functions for\narrays.\n\n\nBengtsson, H. 2003a. The\nR.oo package - object-oriented programming\nwith references using standard R code. in K.\nHornik, F. Leisch, and A. Zeileis, editors. Proceedings of the 3rd\ninternational workshop on distributed statistical computing (DSC 2003).\nhttps://www.r-project.org/conferences/DSC-2003/Proceedings/, Vienna,\nAustria.\n\n\nBengtsson, H. 2003b. The\nR.oo package - object-oriented programming\nwith references using standard R code. in K.\nHornik, F. Leisch, and A. Zeileis, editors. Proceedings of the 3rd\ninternational workshop on distributed statistical computing (DSC 2003).\nhttps://www.r-project.org/conferences/DSC-2003/Proceedings/, Vienna,\nAustria.\n\n\nBengtsson, H. 2022. R.cache: Fast and light-weight caching\n(memoization) of objects and results to speed up computations.\n\n\nBengtsson, H. 2023b. matrixStats: Functions that apply to rows and\ncolumns of matrices (and to vectors).\n\n\nBengtsson, H. 2023a. R.utils: Various programming utilities.\n\n\nBerwin A. Turlach R port by Andreas Weingessel\n&lt;Andreas.Weingessel@ci.tuwien.ac.at&gt; Fortran contributions from\nCleve Moler dpodi/LINPACK), S. original by. 2019. quadprog: Functions to solve quadratic programming\nproblems.\n\n\nBivand, R. 2023. classInt: Choose univariate class intervals.\n\n\nBryan, J. 2016. cellranger: Translate spreadsheet cell ranges to\nrows and columns.\n\n\nBryan, J., C. Citro, and H. Wickham. 2023. gargle: Utilities for working with google\nAPIs.\n\n\nBürkner, P.-C., J. Gabry, M. Kay, and A. Vehtari. 2023. posterior: Tools for working with posterior\ndistributions.\n\n\nChampely, S. 2020. pwr: Basic functions for power analysis.\n\n\nChang, W. 2021. R6:\nEncapsulated classes with reference semantics.\n\n\nChang, W. 2023a. cachem: Cache r objects with automatic\npruning.\n\n\nChang, W. 2023b. fastmap: Fast data structures.\n\n\nChang, W., and J. Cheng. 2023. later: Utilities for scheduling functions to\nexecute later with event loops.\n\n\nChang, W., J. Cheng, J. Allaire, C. Sievert, B. Schloerke, Y. Xie, J.\nAllen, J. McPherson, A. Dipert, and B. Borges. 2023. shiny: Web application framework for r.\n\n\nCheng, J. 2018. miniUI: Shiny UI widgets for small screens.\n\n\nCheng, J. 2023. promises: Abstractions for promise-based\nasynchronous programming.\n\n\nCheng, J., W. Chang, S. Reid, J. Brown, B. Trower, and A. Peslyak.\n2023a. httpuv: HTTP and WebSocket server library.\n\n\nCheng, J., T. Mastny, R. Iannone, B. Schloerke, and C. Sievert. 2023b.\nsass: Syntactically awesome style sheets\n(“Sass”).\n\n\nCheng, J., and C. Sievert. 2023. crosstalk: Inter-widget interactivity for HTML\nwidgets.\n\n\nCheng, J., C. Sievert, B. Schloerke, W. Chang, Y. Xie, and J. Allen.\n2023c. htmltools: Tools for HTML.\n\n\nConstantin, A.-E., and I. Patil. 2021. ggsignif: R package for displaying significance\nbrackets for “ggplot2”. PsyArxiv.\n\n\nCsardi, G. 2023a. prettyunits: Pretty, human readable formatting of\nquantities.\n\n\nCsardi, G. 2023b. rematch: Match regular expressions with a nicer\n“API”.\n\n\nCsardi, G., and S. Sorhus. 2015. praise: Praise users.\n\n\nCsárdi, G. 2019. pkgconfig: Private configuration for\n“R” packages.\n\n\nCsárdi, G. 2020. rematch2: Tidy output\nfrom regular expression matching.\n\n\nCsárdi, G. 2022. crayon: Colored terminal output.\n\n\nCsárdi, G., and W. Chang. 2022. callr: Call r from r.\n\n\nCsárdi, G., and W. Chang. 2023. processx: Execute and control system\nprocesses.\n\n\nCsárdi, G., and R. FitzJohn. 2023. progress: Terminal progress bars.\n\n\nCsárdi, G., J. Hester, H. Wickham, W. Chang, M. Morgan, and D.\nTenenbaum. 2023a. remotes: R package installation from remote\nrepositories, including “GitHub”.\n\n\nCsárdi, G., K. Müller, and J. Hester. 2023b. desc: Manipulate DESCRIPTION files.\n\n\nDahl, D. B., D. Scott, C. Roosen, A. Magnusson, and J. Swinton. 2019. xtable: Export tables to LaTeX or HTML.\n\n\nEddelbuettel, D. 2013. Seamless R\nand C++ integration with Rcpp. Springer,\nNew York.\n\n\nEddelbuettel, D., and J. J. Balamuta. 2018. Extending R with C++: A Brief\nIntroduction to Rcpp. The American Statistician\n72:28–36.\n\n\nEddelbuettel, D., R. Francois, J. Allaire, K. Ushey, Q. Kou, N. Russell,\nI. Ucar, D. Bates, and J. Chambers. 2024. Rcpp:\nSeamless r and c++ integration.\n\n\nEddelbuettel, D., and R. François. 2011. Rcpp: Seamless\nR and C++ integration. Journal of\nStatistical Software 40:1–18.\n\n\nFirth, D. 2023. qvcalc: Quasi variances for factor effects in\nstatistical models.\n\n\nFitzJohn, R. 2017. ids: Generate random identifiers.\n\n\nFortran code by Alan Miller, T. L. based on. 2020. leaps: Regression subset selection.\n\n\nFox, J. 2003. Effect\ndisplays in R for generalised linear models. Journal of\nStatistical Software 8:1–27.\n\n\nFox, J., and J. Hong. 2009. Effect displays in\nR for multinomial and proportional-odds logit models:\nExtensions to the effects package.\nJournal of Statistical Software 32:1–24.\n\n\nFox, J., and S. Weisberg. 2018. Visualizing fit and lack of\nfit in complex regression models with predictor effect plots and partial\nresiduals. Journal of Statistical Software 87:1–27.\n\n\nFox, J., and S. Weisberg. 2019a. An\nR companion to applied regression. Third. Sage,\nThousand Oaks CA.\n\n\nFox, J., and S. Weisberg. 2019b. An\nr companion to applied regression. 3rd edition. Sage, Thousand Oaks\nCA.\n\n\nFox, J., S. Weisberg, and B. Price. 2022. carData: Companion to applied regression data\nsets.\n\n\nFriendly, M. 2023. vcdExtra: “vcd” extensions and additions.\n\n\nGabry, J., and T. Mahr. 2022. bayesplot: Plotting for bayesian models.\n\n\nGabry, J., D. Simpson, A. Vehtari, M. Betancourt, and A. Gelman. 2019.\nVisualization in bayesian\nworkflow. J. R. Stat. Soc. A 182:389–402.\n\n\nGagolewski, M. 2022. stringi: Fast and portable character\nstring processing in R. Journal of Statistical Software\n103:1–59.\n\n\nGalili, T. 2015. dendextend: An r package for visualizing,\nadjusting, and comparing trees of hierarchical clustering.\nBioinformatics.\n\n\nGarbett, S. P., J. Stephens, K. Simonov, Y. Xie, Z. Dong, H. Wickham, J.\nHorner, reikoch, W. Beasley, B. O’Connor, G. R. Warnes, M. Quinn, and Z.\nN. Kamvar. 2023. yaml: Methods to convert r data to YAML and\nback.\n\n\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, A. Pedro, Sciaini,\nMarco, Scherer, and Cédric. 2023a. viridis(Lite) - colorblind-friendly color maps for\nr.\n\n\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, A. Pedro, Sciaini,\nMarco, Scherer, and Cédric. 2023b. viridis(Lite) - colorblind-friendly color maps for\nr.\n\n\nGaslam, B. 2021. diffobj: Diffs for r objects.\n\n\nGaslam, B. 2023. fansi: ANSI control sequence aware string\nfunctions.\n\n\nGenz, A., and F. Bretz. 2009. Computation of multivariate normal and t\nprobabilities. Springer-Verlag, Heidelberg.\n\n\nGilbert, P., and R. Varadhan. 2019. numDeriv: Accurate numerical derivatives.\n\n\nGraves, S., H.-P. Piepho, and L. S. with help from Sundar Dorai-Raj.\n2023. multcompView: Visualizations of paired\ncomparisons.\n\n\nGrosjean, P. 2023. SciViews-r. UMONS, MONS,\nBelgium.\n\n\nHalekoh, U., and S. Højsgaard. 2014. A kenward-roger approximation\nand parametric bootstrap methods for tests in linear mixed models – the\nR package pbkrtest. Journal\nof Statistical Software 59:1–30.\n\n\nHeather Turner, D. F. with contributions from, and J. Fox. 2016. relimp: Relative contribution of effects in a\nregression model.\n\n\nHenry, L., and H. Wickham. 2022. tidyselect: Select from a set of strings.\n\n\nHenry, L., and H. Wickham. 2023. lifecycle: Manage the life cycle of your package\nfunctions.\n\n\nHester, J., and J. Bryan. 2024. glue: Interpreted string literals.\n\n\nHester, J., and G. Csárdi. 2023. brio: Basic r input output.\n\n\nHester, J., L. Henry, K. Müller, K. Ushey, H. Wickham, and W. Chang.\n2024. withr: Run code “With”\ntemporarily modified global state.\n\n\nHester, J., H. Wickham, and J. Bryan. 2023a. vroom: Read and write rectangular text data\nquickly.\n\n\nHester, J., H. Wickham, and G. Csárdi. 2023b. fs: Cross-platform file system operations based on\n“libuv”.\n\n\nHorst, A. M., A. P. Hill, and K. B. Gorman. 2020. palmerpenguins: Palmer archipelago (antarctica)\npenguin data.\n\n\nHothorn, T. 2023. TH.data: TH’s data archive.\n\n\nHothorn, T., F. Bretz, and P. Westfall. 2008. Simultaneous inference in\ngeneral parametric models. Biometrical Journal 50:346–363.\n\n\nIannone, R. 2023. fontawesome: Easily work with “Font\nAwesome” icons.\n\n\nJohnson, S. G. ? The NLopt nonlinear-optimization package. ? ?\n\n\nJustin Talbot. 2023. labeling: Axis labeling.\n\n\nKassambara, A. 2023a. ggpubr: “ggplot2” based publication ready plots.\n\n\nKassambara, A. 2023b. rstatix: Pipe-friendly framework for basic\nstatistical tests.\n\n\nKassambara, A., and F. Mundt. 2020. factoextra: Extract and visualize the results of\nmultivariate data analyses.\n\n\nKay, M. 2023a. ggdist: Visualizations of distributions and\nuncertainty.\n\n\nKay, M. 2023b. tidybayes: Tidy data and geoms for\nBayesian models.\n\n\nKay, M. 2024. ggdist: Visualizations of distributions and\nuncertainty in the grammar of graphics. IEEE Transactions on\nVisualization and Computer Graphics:1–11.\n\n\nKoenker, R. 2021. SparseM:\nSparse linear algebra.\n\n\nKoenker, R. 2023. quantreg: Quantile regression.\n\n\nLang, M. 2017. checkmate: Fast argument checks for defensive\nR programming. The R Journal 9:437–445.\n\n\nLang, M., and R Core Team. 2021. backports: Reimplementations of functions\nintroduced since r-3.0.0.\n\n\nLangfelder, P., and S. Horvath. 2012. Fast R functions\nfor robust correlations and hierarchical clustering. Journal of\nStatistical Software 46:1–17.\n\n\nLarmarange, J. 2023. labelled: Manipulating labelled data.\n\n\nLê, S., J. Josse, and F. Husson. 2008. FactoMineR: A\npackage for multivariate analysis. Journal of Statistical Software\n25:1–18.\n\n\nLenth, R. 2022. estimability: Tools for assessing estimability of\nlinear predictions.\n\n\nLenth, R. V. 2023. emmeans: Estimated marginal means, aka\nleast-squares means.\n\n\nLigges, U., and M. Mächler. 2003. Scatterplot3d - an r\npackage for visualizing multivariate data. Journal of Statistical\nSoftware 8:1–20.\n\n\nLincoln, M. 2022. clipr: Read and write from the system\nclipboard.\n\n\nLoden, J., D. Daeschler, G. Rodola’, and G. Csárdi. 2023. ps: List, query, manipulate system processes.\n\n\nLüdecke, D., M. S. Ben-Shachar, I. Patil, P. Waggoner, and D. Makowski.\n2021. performance: An R package for\nassessment, comparison and testing of statistical models. Journal of\nOpen Source Software 6:3139.\n\n\nLüdecke, D., P. Waggoner, and D. Makowski. 2019. insight: A unified interface to access information\nfrom model objects in R. Journal of Open Source\nSoftware 4:1412.\n\n\nLumley, T. 2004. Analysis of complex survey samples. Journal of\nStatistical Software 9:1–19.\n\n\nLumley, T. 2010. Complex surveys: A guide to analysis using r: A guide\nto analysis using r. John Wiley; Sons.\n\n\nLumley, T. 2019. mitools: Tools for multiple imputation of missing\ndata.\n\n\nLumley, T. 2023. survey: Analysis of complex\nsurvey samples.\n\n\nMakowski, D., M. S. Ben-Shachar, and D. Lüdecke. 2019. bayestestR: Describing effects and their\nuncertainty, existence and significance within the bayesian\nframework. Journal of Open Source Software 4:1541.\n\n\nMeyer, D., and C. Buchta. 2022. proxy: Distance and similarity measures.\n\n\nMeyer, D., E. Dimitriadou, K. Hornik, A. Weingessel, and F. Leisch.\n2023a. e1071: Misc\nfunctions of the department of statistics, probability theory group\n(formerly: E1071), TU wien.\n\n\nMeyer, D., A. Zeileis, and K. Hornik. 2006. The strucplot framework:\nVisualizing multi-way contingency tables with vcd. Journal of\nStatistical Software 17:1–48.\n\n\nMeyer, D., A. Zeileis, K. Hornik, and M. Friendly. 2023b. vcd: Visualizing categorical data.\n\n\nMüller, K. 2020. here: A simpler way to find your files.\n\n\nMüller, K. 2023. rprojroot: Finding files in project\nsubdirectories.\n\n\nMüller, K., and L. Walthert. 2023. styler: Non-invasive pretty printing of r\ncode.\n\n\nMurdoch, D., and E. D. Chow. 2023. ellipse: Functions for drawing ellipses and\nellipse-like confidence regions.\n\n\nNenadic, O., and M. Greenacre. 2007. Correspondence analysis in r, with two-\nand three-dimensional graphics: The ca package. Journal of\nStatistical Software 20:1–13.\n\n\nNeuwirth, E. 2022. RColorBrewer:\nColorBrewer palettes.\n\n\nO’Hara-Wild, M., M. Kay, and A. Hayes. 2023. distributional: Vectorised probability\ndistributions.\n\n\nOehlschlägel, J., and B. Ripley. 2022. bit: Classes and methods for fast memory-efficient\nboolean selections.\n\n\nOehlschlägel, J., and L. Silvestri. 2020. bit64: A S3 class for\nvectors of 64bit integers.\n\n\nOoms, J. 2023a. askpass: Password entry utilities for r, git, and\nSSH.\n\n\nOoms, J. 2023b. commonmark: High performance CommonMark and github\nmarkdown rendering in r.\n\n\nOoms, J. 2023c. curl: A modern and flexible web client for r.\n\n\nOoms, J. 2023d. openssl: Toolkit for encryption, signatures and\ncertificates based on OpenSSL.\n\n\nOoms, J. 2023e. sys: Powerful and reliable tools for running\nsystem commands in r.\n\n\nPatil, I., D. Makowski, M. S. Ben-Shachar, B. M. Wiernik, E. Bacher, and\nD. Lüdecke. 2022. datawizard: An R package for easy\ndata preparation and statistical transformations. Journal of Open\nSource Software 7:4684.\n\n\nPedersen, T. L. 2023. textshaping: Bindings to the\n“HarfBuzz” and\n“Fribidi” libraries for text shaping.\n\n\nPedersen, T. L. 2024. patchwork: The composer of plots.\n\n\nPedersen, T. L., B. Nicolae, and R. François. 2022. farver: High performance colour space\nmanipulation.\n\n\nPedersen, T. L., J. Ooms, and D. Govett. 2023. systemfonts: System native font finding.\n\n\nPeng, R. D. 2019. simpleboot: Simple bootstrap routines.\n\n\nPerry, P. O. 2023. utf8: Unicode text\nprocessing.\n\n\nPlate, T., and R. Heiberger. 2016. abind: Combine multidimensional arrays.\n\n\nPlummer, M., N. Best, K. Cowles, and K. Vines. 2006. CODA:\nConvergence diagnosis and output analysis for MCMC. R News 6:7–11.\n\n\nPotter, S. 2012. Introducing\nthe selectr package. The University of Auckland, Auckland, New\nZealand.\n\n\nR Core Team. 2023. R:\nA language and environment for statistical computing. R Foundation\nfor Statistical Computing, Vienna, Austria.\n\n\nR Special Interest Group on Databases (R-SIG-DB), H. Wickham, and K.\nMüller. 2024. DBI: R\ndatabase interface.\n\n\nRatnakumar, S., T. Mick, and T. Davis. 2021. rappdirs: Application directories: Determine where\nto save data, caches, and logs.\n\n\nSievert, C., and J. Cheng. 2021. jquerylib: Obtain “jQuery” as an HTML dependency object.\n\n\nSievert, C., J. Cheng, and G. Aden-Buie. 2023. bslib: Custom\n“Bootstrap” “Sass”\nthemes for “shiny” and\n“rmarkdown”.\n\n\nSlowikowski, K. 2024. ggrepel: Automatically position non-overlapping\ntext labels with “ggplot2”.\n\n\nSpinu, V. 2023. timechange: Efficient manipulation of\ndate-times.\n\n\nStauffer, R., G. J. Mayr, M. Dabernig, and A. Zeileis. 2009. Somewhere over the\nrainbow: How to make effective use of colors in meteorological\nvisualizations. Bulletin of the American Meteorological Society\n96:203–216.\n\n\nTurner, H., and D. Firth. 2023. gnm: Generalized nonlinear models.\n\n\nUrbanek, S. 2015. base64enc: Tools for\nbase64 encoding.\n\n\nUrbanek, S., and T. Ts’o. 2023. uuid: Tools for generating and handling of\nUUIDs.\n\n\nUshey, K. 2023. sourcetools: Tools for reading, tokenizing and\nparsing r code.\n\n\nUshey, K., and H. Wickham. 2023. renv: Project environments.\n\n\nVaidyanathan, R., Y. Xie, J. Allaire, J. Cheng, C. Sievert, and K.\nRussell. 2023. htmlwidgets: HTML widgets for r.\n\n\nvan den Boogaart, K. G. 2023. tensorA: Advanced tensor arithmetic with named\nindices.\n\n\nVaughan, D. 2023. tzdb: Time zone database information.\n\n\nVaughan, D., J. Hester, and R. François. 2023. cpp11: A c++11 interface\nfor r’s c interface.\n\n\nVehtari, A., A. Gelman, D. Simpson, B. Carpenter, and P.-C. Bürkner.\n2021. Rank-normalization, folding, and localization: An improved rhat\nfor assessing convergence of MCMC (with discussion). Bayesian Analysis.\n\n\nVenables, B., K. Hornik, and M. Maechler. 2022. polynom: A collection of functions to implement a\nclass for univariate polynomial manipulations.\n\n\nWei, T., and V. Simko. 2021. R package “corrplot”: Visualization of a correlation\nmatrix.\n\n\nWheeler, B., and M. Torchiano. 2016. lmPerm: Permutation tests for linear models.\n\n\nWickham, C. 2018. munsell: Utilities for using munsell colours.\n\n\nWickham, H. 2007. Reshaping\ndata with the reshape package. Journal\nof Statistical Software 21:1–20.\n\n\nWickham, H. 2011a. The\nsplit-apply-combine strategy for data analysis. Journal of\nStatistical Software 40:1–29.\n\n\nWickham, H. 2011b. testthat: Get started with testing. The R\nJournal 3:5–10.\n\n\nWickham, H. 2019. lazyeval: Lazy (non-standard) evaluation.\n\n\nWickham, H. 2021. ellipsis: Tools for working with ...\n\n\nWickham, H. 2023a. blob: A simple S3 class for representing vectors\nof binary data (“BLOBS”).\n\n\nWickham, H. 2023b. waldo: Find differences between r objects.\n\n\nWickham, H., M. Averick, J. Bryan, W. Chang, L. D. McGowan, R. François,\nG. Grolemund, A. Hayes, L. Henry, J. Hester, M. Kuhn, T. L. Pedersen, E.\nMiller, S. M. Bache, K. Müller, J. Ooms, D. Robinson, D. P. Seidel, V.\nSpinu, K. Takahashi, D. Vaughan, C. Wilke, K. Woo, and H. Yutani. 2019.\nWelcome to the tidyverse. Journal of Open Source Software\n4:1686.\n\n\nWickham, H., W. Chang, J. Hester, and L. Henry. 2023a. pkgload: Simulate package installation and\nattach.\n\n\nWickham, H., R. François, and L. D’Agostino McGowan. 2023b. emo:\nEasily insert “Emoji”.\n\n\nWickham, H., L. Henry, T. L. Pedersen, T. J. Luciani, M. Decorde, and V.\nLise. 2023c. svglite: An “SVG”\ngraphics device.\n\n\nWickham, H., L. Henry, and D. Vaughan. 2023d. vctrs: Vector helpers.\n\n\nWickham, H., J. Hester, W. Chang, K. Müller, and D. Cook. 2021. memoise: “Memoisation”\nof functions.\n\n\nWickham, H., J. Hester, and G. Csárdi. 2023e. pkgbuild: Find tools needed to build r\npackages.\n\n\nWickham, H., M. Kuhn, and D. Vaughan. 2022a. generics: Common S3 generics not provided by base\nr methods related to model fitting.\n\n\nWickham, H., and T. L. Pedersen. 2023. gtable: Arrange “Grobs”\nin tables.\n\n\nWickham, H., T. L. Pedersen, and D. Seidel. 2023f. scales: Scale functions for visualization.\n\n\nWickham, H., C. O. Wilke, and T. L. Pedersen. 2022b. isoband: Generate isolines and isobands from\nregularly spaced elevation grids.\n\n\nWickham, H., and Y. Xie. 2023. evaluate: Parsing and evaluation tools that\nprovide more details than the default.\n\n\nWilke, C. O. 2023a. cowplot: Streamlined plot theme and plot\nannotations for “ggplot2”.\n\n\nWilke, C. O. 2023b. ggridges: Ridgeline plots in “ggplot2”.\n\n\nXiao, N. 2023. ggsci: Scientific journal and sci-fi themed color\npalettes for “ggplot2”.\n\n\nXie, Y. 2014. knitr: A comprehensive tool\nfor reproducible research in R. in V. Stodden, F.\nLeisch, and R. D. Peng, editors. Implementing reproducible computational\nresearch. Chapman; Hall/CRC.\n\n\nXie, Y. 2015b. Dynamic documents with\nR and knitr. 2nd edition. Chapman; Hall/CRC, Boca\nRaton, Florida.\n\n\nXie, Y. 2015a. Dynamic documents with\nR and knitr. 2nd edition. Chapman; Hall/CRC, Boca\nRaton, Florida.\n\n\nXie, Y. 2016. bookdown: Authoring books and technical documents\nwith R markdown. Chapman; Hall/CRC, Boca Raton,\nFlorida.\n\n\nXie, Y. 2019. TinyTeX:\nA lightweight, cross-platform, and easy-to-maintain LaTeX distribution\nbased on TeX live. TUGboat 40:30–32.\n\n\nXie, Y. 2021. mime: Map filenames to MIME types.\n\n\nXie, Y. 2023a. bookdown: Authoring books and technical documents\nwith r markdown.\n\n\nXie, Y. 2023b. knitr: A general-purpose package for dynamic\nreport generation in r.\n\n\nXie, Y. 2023c. tinytex: Helper functions to install and maintain\nTeX live, and compile LaTeX documents.\n\n\nXie, Y. 2023d. xfun: Supporting functions for packages maintained\nby “Yihui Xie”.\n\n\nXie, Y., J. J. Allaire, and G. Grolemund. 2018. R markdown: The definitive\nguide. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nXie, Y., J. Cheng, and X. Tan. 2023. DT: A wrapper\nof the JavaScript library “DataTables”.\n\n\nXie, Y., C. Dervieux, and E. Riederer. 2020. R markdown\ncookbook. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nXie, Y., and Y. Qiu. 2022. highr: Syntax highlighting for r source code.\n\n\nZeileis, A. 2004. Econometric computing with\nHC and HAC covariance matrix estimators.\nJournal of Statistical Software 11:1–17.\n\n\nZeileis, A. 2006. Object-oriented computation\nof sandwich estimators. Journal of Statistical Software 16:1–16.\n\n\nZeileis, A., J. C. Fisher, K. Hornik, R. Ihaka, C. D. McWhite, P.\nMurrell, R. Stauffer, and C. O. Wilke. 2020a. colorspace: A toolbox for manipulating and\nassessing colors and palettes. Journal of Statistical Software\n96:1–49.\n\n\nZeileis, A., and G. Grothendieck. 2005. zoo: S3 infrastructure for regular and irregular\ntime series. Journal of Statistical Software 14:1–27.\n\n\nZeileis, A., K. Hornik, and P. Murrell. 2009. Escaping\nRGBland: Selecting colors for statistical graphics.\nComputational Statistics & Data Analysis 53:3259–3270.\n\n\nZeileis, A., and T. Hothorn. 2002. Diagnostic checking in\nregression relationships. R News 2:7–10.\n\n\nZeileis, A., S. Köll, and N. Graham. 2020b. Various versatile\nvariances: An object-oriented implementation of clustered covariances in\nR. Journal of Statistical Software 95:1–36.\n\n\nZeileis, A., D. Meyer, and K. Hornik. 2007. Residual-based shadings\nfor visualizing (conditional) independence. Journal of Computational\nand Graphical Statistics 16:507–525.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "10-software.html",
    "href": "10-software.html",
    "title": "Appendix A — Software Tools",
    "section": "",
    "text": "A.1 R and R packages\nR can be downloaded and installed from any CRAN (the Comprehensive R Archive Network) mirrors, e.g., https://cran.rstudio.com. Please note that there will be a few new releases of R every year, and you may want to upgrade R occasionally.\nTo install the bookdown package, you can type this in R:\ninstall.packages(\"bookdown\")\nThis installs all required R packages. You can also choose to install all optional packages as well, if you do not care too much about whether these packages will actually be used to compile your book (such as htmlwidgets):\ninstall.packages(\"bookdown\", dependencies = TRUE)\nIf you want to test the development version of bookdown on GitHub, you need to install devtools first:\nif (!requireNamespace(\"devtools\")) install.packages(\"devtools\")\ndevtools::install_github(\"rstudio/bookdown\")\nR packages are also often constantly updated on CRAN or GitHub, so you may want to update them once in a while:\nupdate.packages(ask = FALSE)\nAlthough it is not required, the RStudio IDE can make a lot of things much easier when you work on R-related projects. The RStudio IDE can be downloaded from https://www.rstudio.com.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Software Tools</span>"
    ]
  },
  {
    "objectID": "10-software.html#pandoc",
    "href": "10-software.html#pandoc",
    "title": "Appendix A — Software Tools",
    "section": "\nA.2 Pandoc",
    "text": "A.2 Pandoc\nAn R Markdown document (*.Rmd) is first compiled to Markdown (*.md) through the knitr package, and then Markdown is compiled to other output formats (such as LaTeX or HTML) through Pandoc. This process is automated by the rmarkdown package. You do not need to install knitr or rmarkdown separately, because they are the required packages of bookdown and will be automatically installed when you install bookdown. However, Pandoc is not an R package, so it will not be automatically installed when you install bookdown. You can follow the installation instructions on the Pandoc homepage (http://pandoc.org) to install Pandoc, but if you use the RStudio IDE, you do not really need to install Pandoc separately, because RStudio includes a copy of Pandoc. The Pandoc version number can be obtained via:\n\nrmarkdown::pandoc_version()\n## [1] '3.1.11.1'\n\nIf you find this version too low and there are Pandoc features only in a later version, you can install the later version of Pandoc, and rmarkdown will call the newer version instead of its built-in version.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Software Tools</span>"
    ]
  },
  {
    "objectID": "10-software.html#latex",
    "href": "10-software.html#latex",
    "title": "Appendix A — Software Tools",
    "section": "\nA.3 LaTeX",
    "text": "A.3 LaTeX\nLaTeX is required only if you want to convert your book to PDF. You may see https://www.latex-project.org/get/ for more information about LaTeX and its installation, but we strongly recommend that you install the lightweight and cross-platform LaTeX distribution named TinyTeX and based on TeX Live. TinyTeX can be easily installed through the R package tinytex (which should be automatically installed when you install bookdown):\n\ntinytex::install_tinytex()\n\nWith TinyTeX, you should never see error messages like this:\n! LaTeX Error: File `titling.sty' not found.\n\nType X to quit or &lt;RETURN&gt; to proceed,\nor enter new name. (Default extension: sty)\n\nEnter file name:\n! Emergency stop.\n&lt;read *&gt;\n\nl.107 ^^M\n\npandoc: Error producing PDF\nError: pandoc document conversion failed with error 43\nExecution halted\nThe above error means you used a package that contains titling.sty, but it was not installed. LaTeX package names are often the same as the *.sty filenames, so in this case, you can try to install the titling package. If you use TinyTeX with R Markdown, missing LaTeX packages will be installed automatically, so you never need to worry about such problems.\nLaTeX distributions and packages are also updated from time to time, and you may consider updating them especially when you run into LaTeX problems. You can find out the version of your LaTeX distribution by:\n\nsystem(\"pdflatex --version\")\n## pdfTeX 3.141592653-2.6-1.40.22 (TeX Live 2022/dev/Debian)\n## kpathsea version 6.3.4/dev\n## Copyright 2021 Han The Thanh (pdfTeX) et al.\n## There is NO warranty.  Redistribution of this software is\n## covered by the terms of both the pdfTeX copyright and\n## the Lesser GNU General Public License.\n## For more information about these matters, see the file\n## named COPYING and the pdfTeX source.\n## Primary author of pdfTeX: Han The Thanh (pdfTeX) et al.\n## Compiled with libpng 1.6.37; using libpng 1.6.37\n## Compiled with zlib 1.2.11; using zlib 1.2.11\n## Compiled with xpdf version 4.03\n\nTo update TinyTeX, you may run:\n\ntinytex::tlmgr_update()\n\nFrom year to year, you may need to upgrade TinyTeX, too (otherwise you cannot install or update any LaTeX packages), in which case you may reinstall TinyTeX:\n\ntinytex::reinstall_tinytex()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Software Tools</span>"
    ]
  }
]